{
	"nodes":[
		{"id":"fbc1ef28f3589012","type":"text","text":"# L1\n\nDefinizioni:\n\n- h_i history of process i = tutti gli eventi sulla sua timeline.\n- H = collezione delle storie\n- prefix of h_i sono i primi k eventi di h_i\n- local state = dopo k eventi, il processo i si trova nello stato $\\sigma_i^k$.\n- global state = collezione dei local states al tempo k\n- run k' = reordering of events such that internal order of every process il preserved. sono diverse sequenze di computazione.\n- Cut C is collection of prefix of every process. so it's a set of events. a process may not have events before the cut, it's alright\n\t- it is also a global state. for every C there is a GS\n- consistent cut = se e avviene prima di e' ed e' $\\in C$ allora $e\\in C$.\n\t- da cui segue la definizione di consistent run, ovvero una run in cui qualsiasi C è consistente","x":-440,"y":-380,"width":640,"height":460},
		{"id":"e6fd42bc1097166e","type":"text","text":"exam\n\nmidterm 3 esercizi (+ altro?)\n\nesempio ex\n\n$C_1$ e $C_2$ sono due CC. Show that $C_1\\cap C_2$ is consistent.\n\n$C_1\\cap C_2 \\subseteq C_1$, which is consistent.\n\ndevi usare la definizione per cui un consistent cut è \"se e precede e', ovvero $e \\to e'$ ecc...\n\nanche l'unione è consistente.","x":-940,"y":-380,"width":430,"height":540},
		{"id":"eead1953cd38ffd8","type":"text","text":"# L2 (Lamport)\n\nMettiamo processi da 0 a 3. Ogni volta che su un processo da 1 a 3 avviene un e, questo lo notifica a $p_0$, il quale può ricostruire la run (è un osservatore). visto che non so quanto ci mettono i singoli messaggi ad arrivare a p_o, potrei avere delle inconsistenze! Non solo potrebbe non essere consistente, ma potrebbe non essere nemmeno una run!! come risolvo? Con un canale FIFO! weak assumption, very easy to implement. ma questo canale è per ogni coppia $(i;0)$ non mi dice niente sull'ordine dei diversi processi. Quindi così è una run, ma non necessariamente consistente. what if i give you a global clock (aka Real Clock RC), assume every process can use it. very strong assumption, cause no god gives us a clock, but i can use it to build a consistent run.\n\ndiciamo che $\\delta$ è un upper bound per il tempo impiegato da ogni canale per deliverare il messaggio a p_0. Ogni messaggio ha un timestamp, e p_0 ha una finestra di osservazione larga $\\delta$. entro questa finestra ha un buffer in cui aspetta di essere sicuro di ricevere tutti i messaggi di quella finestra.\n\n(what if I let p_0 put things in timeline in whatever order and run a sorting algorithm on the window $\\delta$?   -A)\n\n$e\\to e' \\Rightarrow RC(e)<RC(e')$. **Clock condition**. Non serve RC, basta qualsiasi clock con questa proprietà. LA freccia non è al contrario! $e\\to e'$ implica una necessità di ordine, che non è necessaria per **eventi concorrenti** (segnati con una freccia sul grafico, i singoli punti sono eventi indipendenti)\n\nDefiniamo un sapienza clock SC local to every p. se $e_1^1\\to e_2^1$ e il primo ha timestamp 1, il secondo deve avere timestamp maggiore, quindi sarà 2. dopodiché procedo con gli eventi in ordine, finché 7 sulla linea 2 non manda un messaggio alla linea 1. a qualsiasi numero sono arrivato sulla linea 1, ricevere un messaggio da 2 deve avere timestamp maggiore sia della linea 2 che di quella 1.\n\n- se 1 era arrivata a 5, il massimo +1 è 8;\n- se era a 12, è 13.\n\nQuesta roba è il **Lamport (or logical) Clock**\n\nora, sul singolo canale FIFO sono sicuro di avere i timestamp in ordine. ma prima di aggiungere $e_2^3$ devo aspettare tutti gli eventi precedenti? Non proprio, solo quelli che precedono logicamente. vedi grafico. e come entra $\\delta$ in tutto questo? se ricevo $e_2^3$ con timestamp 4, allora devo aspettare tutti gli eventi degli altri processi con timestamp fino a 4. this might make me wait. e se p_3 non ha nessun evento per un bel po'? ...boh si è dimenticato?...\n\n","x":-440,"y":140,"width":640,"height":1180},
		{"id":"941a38f0264b5e2e","type":"text","text":"# Lamport vettoriale (vector clock)\n\nse ci sono eventi concorrenti (quindi non c'è un ordine tra loro). i loro timestamp non possono essere numeri. allora posso modificare un po' la definizione dei timestamp, e renderli non numeri ma con la loro history. in questo modo$$e\\to e' \\Leftrightarrow TS(e)\\subseteq TS(e')$$\nin questo modo due eventi senza freccia sono semplicemente due eventi le cui storie non sono una un sottoinsieme dell'altra. ma la history di tutta la run! è un vettore. ad esempio, la timestamp di $e_2^3$ è $[1,4,2]$, ovvero il vettore dei lamport clock di ogni processo, così non pesa 5 terabyte dopo un'ora.\n\nvedi secondo grafico.\n\np_0 riceve $[141]$, quindi sa che deve ricevere prima una notifica da 1, 3 da 2 (ma di questo sono sicuro, perché il singolo canale è FIFO) e 1 da 3. nota che così non serve $\\delta$.\n\nquindi la condizione di correlazione $e_i\\to e_j$ è $$\\forall\\,k VC(e_i)[k] \\leq VC(e_j)[k]\\quad\\wedge\\quad\\exists\\,k': VC(e_i)[k'] < VC(e_j)[k']$$se non metto la seconda condizione potrebbero essere lo stesso evento. ovviamente se so che i due eventi appartengono a processi differenti non serve la seconda condizione, anzi, basta confrontare il clock associato ad un singolo processo $k$ (e.g. \\[310\\] sul processo 1 avviene prima di \\[240\\] sul processo 2. controllando NON SONO CONVINTO DI QUESTA ROBA)\n\nvector clock usato nei DB distribuiti. così vediamo anche i deadlock (how?)\n\nreachable = run at some point is equal to the cut","x":328,"y":140,"width":572,"height":923},
		{"id":"dd46627802841779","type":"text","text":"# L3\n\nesempio foto\n\ndefiniamo $|\\Theta(e_i)|=\\sum_k VC(e_i)[k]$, ovvero la \"misura\" del vector clock.\n\nvoglio sapere se esiste $e_k$ t.c. $e_k$ NON è avvenuto prima di $e_i$, ma è avvenuto prima di $e_j$. In pratica voglio sapere se esiste un evento $e_k$ tra $e_i$ e $e_j$ (non letteralmente nel diagramma spaziotempo, basta che sia vero nella run). A livello di VC lo traduco come? $VC(e_i)[k]$ è il numero di eventi del processo $k$ che sono avvenuti prima dell'evento $e_i$, quindi$$VC(e_i)[k] < VC(e_j)[k]$$\n\nora, inizio a registrare. Se mi arriva $[001]$ posso registrarlo? Sì, perché sono sicuro che non può arrivare un messaggio che sia avvenuto prima di questo. e se poi arriva $[232]$? Ovviamente non posso registrarlo. Cosa discrimina tra i due casi, intuizione a parte? posso deliverare solo se una delle componenti dell'incoming message è esattamente +1 rispetto a quello che ho salvato (nel qual caso la aggiorno). riguardati come funziona il VC, funziona. Nota che è facilitato dal fatto che il singolo canale è FIFO, ma non è strettamente necessario che lo sia.\n\nesiste un modo più leggero rispetto a notificare a $p_0$ di ogni evento?\n\n- Se è $p_0$ che requesta i local states, non è detto che riesca a ricostruire un global state coerente (i messaggi arrivano ai processi in momenti diversi)\n- potremmo fare che quando il processo $p_i$ riceve la request fa broadcast su tutti gli altri processi. se un processo riceve lo snapshot del local state da un altro processo, fa partire il suo broadcast senza aspettare la notifica di $p_0$.\n- il Cut sui punti in cui i processi fanno broadcast è consistente. questo perché i canali sono FIFO, quindi una qualsiasi freccia che implica una relazione $e_i\\to\\ e_j$ avviene prima della comunicazione broadcast. vabbè lo dimostra per contraddizione con la definizione.\n- sta roba si chiama protocollo chandy-lamport\n- se fai così non ci stanno deadlock (continua ad accennarlo senza entrare nel dettaglio)\n\nTutta questa era la fase 1, poi passeremo agli atomic commit (blockchain e cose varie)","x":1560,"y":140,"width":780,"height":923},
		{"id":"120f425563a323e0","type":"text","text":"run = ogni possibile esecuzione degli eventi in modo che l'ordine del singolo processo sia rispettato\n\ntopological order = consistent run?\n\ncioè tipo che su un grafo in generale non c'è topological order perché ci possono essere cicli (qui proviamo che non possono esserci cicli perché sono diagrammi space-time)","x":1160,"y":1124,"width":328,"height":393},
		{"id":"b2214078d2cc0c48","type":"text","text":"# L4 (Two Phase Commits)\n\nCINECA?\nnello schemino in cui (nome, voto) viene splittato in (nome) e (voto) su 3 computer diversi serve ovviamente che ci siano protocolli locali tipo login e rollback localmente su ognuno di essi, ma è un sistema distribuito in cui le operazioni {splitta nomevoto, salva nome, salva voto, cancella nomevoto} deve essere atomico, cioè o tutto o niente. Se non implemento nessun protocollo per assicurarmi di ciò, rischio un'inconsistenza (e.g. il nome viene perso, posso votare di nuovo).\n\nquesta roba si realizza con two phase commit: quando parte la transazione, o tutti i siti la fanno o non la fa nessuno.\n\nassumiamo che i processi siano either crash fail, crash stop or crash recovery. sistema asincrono, no byzantine nodes (?).\n\n- A1 - if processes reach a decision (either commit or abort) it must be the same for all of them;\n\t- versione alternativa scritta sul libro: all processes that reach a decision, reach the same one\n- A2 - A process cannot reverse its decision after reaching one;\n- A3 - The commit decision can be reached only if all processes voted `yes`.\n\t- non dico iff perché voglio lasciarmi aperta la pista di abortire anche se tutti hanno votato `yes`.\n\nnota che anche un protocollo che non fa letteralmente nulla soddisfa queste proprietà, quindi mi servono condizioni aggiuntive.\n\n- safety propriety - nothing bad should happen\n- liveness property - \"ok, but do something\"\n\nse hai solo safety è ok se non fai nulla (e.g. A1 2 3), se sei pazzo sei liveness. tipicamente richiediamo di essere safe ma essere as live as you can.\n\n- A4 - ***If there are no failures*** and all processes voted `yes` then decision is `commit`.\n\nin un processo del genere solitamente c'è un coordinatore e dei partecipanti. questi ultimi votano, il primo no (oppure sì, not a problem if coordinator is also participant). quindi: sistema distribuito è così\n\n- coordinatore C manda `voteRequest` ai partecipanti P\n- i quali decidono `yes` or `no`\n\t- se votano `no` fanno `abort`, e ciò è safe.\n- e mandano il voto a C\n\t- e se il messaggio si perde o è molto lento? C deve essere sicuro di avere tutti i voti `yes` per, in caso, fare commit. Quindi è safe.\n- se C riceve TUTTI `yes`, allora può decidere di fare commit. sta di fatto che qualcosa decide\n- allora manda la decisione a tutti, i quali eseguono.\n\nse il protocollo non ha failures e sincrono (i.e. i messaggi arrivano in tempi utili) è perfetto. In una situazione reale non è così.\n\nma posso mai aspettare per sempre? ovviamente no, metto un timeout al termine del quale mando a tutti una decisione di abort.\n","x":-440,"y":1800,"width":660,"height":1370},
		{"id":"ae64a718f65ccd25","type":"text","text":"to do exercises don't use notion of topological order","x":2188,"y":1202,"width":250,"height":60},
		{"id":"be570a1920f04449","type":"text","text":"# Failures\n\n- se si perde `voteRequest`?\n\t- la prima volta al partecipante scade il timeout e chiede a C di mandare `voteRequest`\n\t- la seconda fa un `abort`.\n- se si perde il voto?\n\t- C manda di nuovo la request\n\t- la seconda volta che scade il timeout decido di abortire.\n\t\t- eh ma magari arriva un attimo dopo ed erano tutti `yes`. \"eh, such is life\"\n- se si perde la decisione che C manda a P?\n\t- se ho votato no, easy, tanto ho già abortito\n\t- se ho votato yes non è per niente safe abortire, quindi mi tocca aspettare. magari gli rimando un \"`aoo sta decisione??`\" sperando che arrivi. e magari lo chiedo tante volte e nessuno mi risponde. eh. magari C è morto. allora magari chiedo agli altri P se hanno ricevuto la decisione (assumo che non mentano). gli altri P possono rispondere in due modi\n\t\t- ho ricevuto la decisione, fine\n\t\t- non l'ho ricevuta, e\n\t\t\t- ho votato no - P fa un `abort`\n\t\t\t- ho votato `yes`. cazzo. chiedo a un altro. se chiedo a tutti e TUTTI hanno votato `yes` e NESSUNO ha ricevuto la decisione, tutti fanno `abort`.\n\nin sostanza, two-phase commit è safe ma non live. scopriremo che nessun protocollo è sia safe che live. c'è un teorema di impossibilità di avere entrambe. per questo chiediamo protocolli safe e as live as can be. è anche un cooperative protocol\n\n# Log\n\ntutto questo ha senso se i processi sono fail-stop. e se sono fail-recover? quando recoverano perdono memoria! Tranne? Il ***LOG*** (sulla singola macchina. ovviamente puoi farlo sul DS ma servirebbe un TPC per il log condiviso, il che significa provare a risolvere il problema con il problema).\n\n\"eh ma il log sta su disco, può fallire\". Ho capito, ma mica puoi risolvere tutto. magari fai più dischi ma muoiono tutti. non solo. quando chiamo una syscall per scrivere su disco, magari questa scrive in RAM. allora devo forzare a scrivere su disco (tipo con una `flush`, su linux si chiama `fsync`?). ma magari il disco ha un buffer e salta la corrente, perdo il buffer. si usa un disco solo per il log e lo configuro in modo che non usi il buffer. (ha fatto un commento su journaled filesystem? non ho sentito!).\n\nil punto di tutto sto pippone è che mi serve assumere che il log sia safe in modo che quando recovero leggo il log.\n\ndetto questo. è meglio scrivere sul log e poi mandare il messaggio o viceversa? in entrambi i casi potrei morire nel mezzo! ma è meglio la seconda scelta. se rivivo e leggo sul log che ho mandato il messaggio non lo manderò mai. meglio mandare e loggare, alla peggio mando messaggi duplicati. però puoi ricevere voti di una request che non sai di aver mandato. tu nel dubbio vedi sta roba e dici `nono che è sta roba, abortite tutti`. mi sa che posso scegliere entrambi a seconda delle necessità\n\nstesso problema per P. mando il voto e loggo o viceversa?\n- voto e loggo, morendo in mezzo - quando rivivo non so che ho votato. né posso rimandare il voto, perché potrebbe essere diverso. \n- viceversa - quando rivivo penso di aver mandato il messaggio, ma non posso essere sicuro, quindi nel dubbio lo rimando.\nquindi se ho votato no abort, altrimenti aspetto.\n\ncapiamo che in pratica se voto no non cambia niente, se voto `yes` è meglio log e poi send, alla peggio mando lo stesso messaggio due volte perché so qual è.\n\nStesso problema per C quando manda la decisione. prima safety, quindi\n- log then send is ok, if you die in the middle you see the decision, not sure if has been sent, send it again\n- send then log - safe only if it's an abort.\n\nse quando vedi la decisione presa la rimandi, se non vedi nulla mandi un abort.\n\nyou should be very careful what you log and when.","x":520,"y":1800,"width":700,"height":1804},
		{"id":"23a2f6367ee648bd","type":"text","text":"è anche possibile che C faili mentre manda i messaggi, tipo che lo dice a qualcuno e poi crasha. legge il log e rimanda a tutti.","x":1316,"y":2602,"width":345,"height":201},
		{"id":"0351c84f97899850","x":1950,"y":1800,"width":850,"height":1800,"type":"text","text":"# L5\n\nconsesus problema dell'agreement (in questo caso commit o abort). stessa cosa risolta nella blockchain (devi sapere se è accettata o no). Two-phase commit è il primo step verso ***paxos*** (perché basta un solo nodo offline e tutto muore). paxos è il nome di una possibile isola greca (in realtà esiste, ma lamport non lo sapeva) perché racconta sta storia di sti tizi greci con un piccolo parlamento di non professionisti. lo manda così e glielo rifiutano. alla fine dopo lunghe lotte lo accettano ma aggiungono delle note esplicative (le fa Keith Marzullo). nessuno lo capisce, allora pubblica un articolo chiamato \"paxos made easy\". nessuno lo capisce. poi ci sta \"paxos for dummies\".\n\nogni nodo ha un DB. in google filesystem every file is replicated in 5 different places. replication system, paxos is a replication system. se tutto viene fatto in parallelo tra 5 server, ognuno di essi deve avere una copia coerente. sui google doc possono lavorare più persone! quindi serve consenso sull'ordine delle singole operazioni.\n\n- serve consenso non sulla serie di valori, ma sul singolo valore. dobbiamo tollerare i crash failures. sistema asincrono con n processi.\n\nci sono n processi più importanti, detti acceptors. nella storia di lamport sono i membri del parlamento\n\npoi ci sono i proposers. \n\nha senso chiedere che tutti gli acceptor debbano votare su ogni singolo valore perché questo sia accettato, ma così torno al two-phase con i relativi problemi. allora facciamo che serve la maggioranza (perché se così non fosse due proposte opposte possono essere approvate contemporaneamente). se serve maggioranza e ci sono due proposte parallele almeno un computer sarà in entrambe le commissioni, e permetterà coerenza. tolerates $floor({n-1\\over2})$ errors?\n\n- primo messaggio - un proposer manda la proposta con un messaggio di `prepare`. perché non è una `voteRequest`? perché che ne so se mi sono appena svegliato e gli altri proposer hanno proposto altro?\n\t- visto che non abbiamo un orologio usiamo il round. ad ogni processo è preassociato un set di numeri che sono i round in cui può iniziare la conversazione. sono statici e mai condivisi (e.g. se il processo 1 ha il round 1, nessun altro ha il round 1).\n\t- a questo punto capiamo che la `prepare` è una `prepare(3)`, cioè `preparati al round 3`\n- l'acceptor risponde con una `promise(3, lastroundvoted?, value)` in cui comunicano al processo che ha mandato la `prepare`\n\t- cosa hanno votato l'ultima volta\n\t- ?? value c'è solo se quello prima è `yes`? no, quello in mezzo è il numero dell'ultimo round per cui ho votato. posso rispondere `null null` se non ho ancora votato\n\t- perché si chiama promise? perché significa `from now on i will never partecipate to a round smaller than 3`\n- Se il proposer riceve n messaggi in risposta, ha un quadro chiaro della situazione. se la maggioranza risponde di aver votato $5$, è inutile che io proponga $7$, tanto non vincerà mai! (Paxos è per il singolo valore!!).\n\t- anche se volevo proporre 7, propongo 5, o in generale x.\n- mando una `accept(3, x)`, cioè al round 3 dico agli acceptors che ho accettato x\n- gli acceptors mandano un `learn(3, x)` a tutti gli altri (che di base è il loro ***voto***). Se un learner riceve una maggioranza di voti per quel round (altrimenti no?)\n\t- se sono all'inizio e nessuno ha votato parto con una `accept`.\n\nse dopo il round 3 parte il round 1, gli acceptors non rispondono. allora magari il processo prova con il prossimo numero nel suo array statico, che magari è 4 (se sono 3 processi)\n\nse al round 2 c'era la maggioranza (3/5) ma uno degli acceptors muore, arrivano solo 4 promises, magari 2 voti e due nulli. che faccio? non blocco il protocollo, ma non accetto il nuovo valore.\n\nnon è importante che il processo faccia approvare il proprio valore, ma che tutti concordino.\n\nsta dicendo una cosa circa il fatto che non è possibile cambiare il voto una volta che una maggioranza ha preso una decisione\n\nè possibile che nel round 2 qualcuno voti x ma poi nel round 3 la maggioranza vota y. se la minoranza ha votato x ma al round dopo le loro promise si perdono, il nuovo proposer riceve solo dei \"non ho votato\". è totalmente safe fare accept y.\n\nse le accept ci mettono troppo, il prossimo round comincia. gli acceptor promettono di non partecipare a round inferiori. quando le accept arrivano, vengono rifiutate.\n\nnon è live, ma tanto è impossibile esserlo essendo safe. in pratica lo è, nel senso che quando lo implementi i segnali di norma non rallentano tutti insieme, o simili.\n\nnon tollera malicious activities, quindi non usato nelle blockchain.\n\nfino a qualche centinaio di acceptor paxos va bene, ma blockchain ne ha migliaia."},
		{"id":"bab53e10c3a7bbde","x":2941,"y":2407,"width":399,"height":233,"type":"text","text":"choosing the value x (per l'accept?)\n\n- take the promise with the largest \"last time I voted\" j;\n- the value x is the one associated with that promise"}
	],
	"edges":[
		{"id":"40550efc7af07698","fromNode":"fbc1ef28f3589012","fromSide":"bottom","toNode":"eead1953cd38ffd8","toSide":"top"},
		{"id":"e0e074485452ef04","fromNode":"eead1953cd38ffd8","fromSide":"right","toNode":"941a38f0264b5e2e","toSide":"left"},
		{"id":"1469fe0ead3f985f","fromNode":"941a38f0264b5e2e","fromSide":"right","toNode":"dd46627802841779","toSide":"left"},
		{"id":"14a53fc6831b9a25","fromNode":"b2214078d2cc0c48","fromSide":"right","toNode":"be570a1920f04449","toSide":"left"},
		{"id":"313f73befec0f227","fromNode":"be570a1920f04449","fromSide":"right","toNode":"23a2f6367ee648bd","toSide":"left"}
	]
}