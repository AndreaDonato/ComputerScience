{
	"nodes":[
		{"id":"1e3fd2b7a4b6a7cc","type":"text","text":"# HowTo Build IoT Networks\n\nPur essendo molto diversi fra loro, tutti i sistemi IoT poggiano sulla stessa architettura:\n\n- ***Cloud*** - Il cervellone che ha il quadro completo della situazione e sa cosa fare si trova su Internet. Per raggiungere i dispositivi deve passare attraverso il loro Gateway;\n\t- Se il sistema √® complesso, pu√≤ distribuirsi sul territorio tramite i ***fog nodes***.\n- ***Gateway*** - Comunica con il Cloud tramite protocolli Internet (TCP/IP), e con i dispositivi tramite protocolli locali (e.g. BLE, ZigBee, WiFi, 6LoWPAN);\n\t- Nota che il Gateway tendenzialmente non √® il router domestico, piuttosto un hub che accede ad Internet tramite esso e poi si interfaccia con i dispositivi.\n- ***Embedded Devices*** - I dispositivi veri e propri (***Things***).\n\nNel complesso, possiamo individuare una ***stack protocollare*** propria delle reti IoT.","x":-1760,"y":-1000,"width":759,"height":387,"color":"6"},
		{"id":"ff3b9035a56b4e9e","type":"text","text":"# Things\n\nUna Thing ha bisogno di fare essenzialmente tre cose:\n\n1. ***Percepire l‚Äôambiente*** - Un ***sensore*** sfrutta un fenomeno fisico (e.g. una resistenza che varia in funzione del calore) per convertire la misura da prendere in un segnale EM. Successivamente, un ADC converte il segnale da analogico a digitale, e tramite un *protocollo/architettura* ad-hoc i dati vengono inviati al processore;\n\t- Li chiamo *protocolli/architetture* perch√© non definiscono solo cose tipo \"`prima di mandare il segnale successivo aspetta il colpo di clock`\", ma anche il numero e lo scopo dei fili utilizzati per farlo. Questo significa che per parlare la lingua di un certo protocollo, il microcontrollore deve avere l'HW adatto!\n\t\t- ... o quasi. Esistono modi per emulare il comportamento di un protocollo via SW, motivo per cui si chiamano \"protocolli\" e non \"*protocolli/architetture*\".\n\t- Tra i pi√π noti citiamo ***SPI*** (**Serial Peripheral Interface**, velocissimo ma richiede tanti fili), ***I2C*** (**Inter-Integrated Circuit**, lento ma ne richiede meno) e ***UART*** (**Universal Asynchronous Receiver-Transmitter**, come dice il nome si usa per la compatibilit√†).\n2. ***Interagire fisicamente*** - Un ***attuatore*** funziona intuitivamente al contrario: riceve un segnale dal processore (per come descritto sopra), eventualmente converte in segnale analogico con un DAC e passa il risultato al motore, che si muove di conseguenza;\n\t- Dico \"eventualmente\" perch√© non tutti i motori funzionano con segnali analogici. √à un attuatore anche uno switch che modifica un circuito elettrico;\n\t- I requisiti vanno dalla reattivit√† real-time alla robustezza a condizioni atmosferiche.\n3. ***Elaborare dati e prendere decisioni locali*** - Il cuore di un sistema informatico √® sempre il processore. Qui distinguiamo tra due tipi di architetture:\n    - ***MCU*** (***Microcontroller Unit***) - Un singolo chip che contiene CPU, memorie e periferiche (e.g. SPI, I2C). Consuma poco ed √® ottimizzato per task specifici (i.e. esegue un singolo programma, senza SO). Ne √® un esempio ***ESP32***, utilizzato per le lampadine smart, ma anche ***Arduino***;\n    - ***MPU*** (***Microprocessor Unit***) - Letteralmente la CPU che metti nel tuo computer, che deve appoggiarsi ad una MoBo e che quindi √® in grado di reggere roba complessa come un SO Linux. Ovvio che in IoT la MoBo deve essere piccolissima: meglio parlare di ***System-on-Chip*** (***SoC***), che differisce da una classica MoBo perch√© non √® affatto scalabile o espandibile (... √® letteralmente un chip gi√† saldato). Ovviamente si usa RISC, e un esempio tipico √® il ***Raspberry Pi***.","x":-1760,"y":120,"width":759,"height":911,"color":"4"},
		{"id":"617bc5508509a069","type":"text","text":"# Microcontrollori CortexM\n\nQuesta famiglia di microcontrollori ha dato una bella spinta allo sviluppo di IoT dal 2004.\n\nSono tutti basati su architettura `ARM` a `32 bit`, dal pi√π semplice e meno energivoro `M0` ai pi√π avanzati `M7`, che contengono supporto per **Digital Signal Processing** (**DSP**, che serve per l'elaborazione *real time* di immagini, audio e controlli di attuatori robotici) e `float`.\n\nTutti hanno in comune la gestione dei registri (`r0`$\\to$`r15`, di cui gli ultimi tre sono `Stack Pointer`, `Link Register`, che sarebbe `Return Address`, e `Program Counter`), e della memoria (in sequenza, `Flash`, `SRAM`, `Periferiche` e `Registri`). Alcuni implementano `User/Kernel Mode` e conseguente `Memory Protection Unit` (`MPU`) per impedire l'accesso all'area riservata al `Kernel`.\n\ncio√® un microcontroller pu√≤ avere RAM, ROM, Flash, EEPROM, NVRAM (RAM per operazioni temporanee. Flash ROM o EEPROM per firmware e dati persistenti)\n\nci stanno anche le porte I/O...\n\nse hai voglia, slides 3_2 n 23+\n\nUn‚Äôinterruzione √® un evento (es. un sensore che invia un segnale) che forza la CPU a:\n\n1. **Sospendere l‚Äôesecuzione attuale**\n2. **Passare in Kernel Mode**\n3. **Eseguire un Interrupt Service Routine (ISR)**\n4. **Riprendere il programma precedente**\nLe interruzioni hanno 3 stati:\n- **Inattivo:** Nessun evento\n- **Pending:** L‚Äôinterruzione √® avvenuta, ma la CPU non l‚Äôha ancora gestita\n- **Attivo:** Il codice ISR sta risolvendo l‚Äôinterruzione\nEsempi di sorgenti di interrupt:\n- **Hardware:** ADC, Timer, GPIO\n- **Software:** divisioni per zero, errori di memoria\n\nTutte le interruzioni sono associate a un indirizzo specifico memorizzato in una **IVT (Interrupt Vector Table)**, che mappa le interruzioni ai loro handler.\n\n**Gestione della priorit√†:** Se due interrupt arrivano contemporaneamente, quello con priorit√† pi√π alta viene gestito per primo.","x":-751,"y":120,"width":759,"height":911,"color":"3"},
		{"id":"03e26affba62b324","type":"text","text":"# Esempi di MCU Cortex-Based\n\n\nNonostante siano un po' datati, restano ad oggi un punto di riferimento per applicazioni che richiedono basso consumo energetico. Esempi di configurazioni sono\n\n- ***Atmel SAM4L (Cortex-M4)*** - Consuma $4.3 \\text{ mA @ }48 \\text{ MHz}$ (i.e. alla velocit√† massima di $48\\times10^3$ colpi al secondo assorbe $4.3\\text{ mA}$) e supporta USB, SPI, I2C, UART e 15 canali di DMA (i.e. mette una CPU potente e ne ottimizza l'uso permettendo alle periferiche di bypassarla con un accesso diretto a memoria, se il suo intervento non √® necessario);\n\t- Possiamo risalire all'assorbimento di corrente per ciclo di clock:$$I_C={4.3 \\cdot 10^{-3}\\text{ A/s}\\over48 \\cdot 10^6\\text{ Cycle/s}}\\simeq0.09\\,\\mu\\text{A/Cycle}$$\n\t- S√¨, la gente in Computer Science non sa usare le dimensioni.\n- ***Nordic nRF51 (Cortex-M0 + BLE)*** - CPU meno potente ($\\sim 2.6 \\text{ mA/s @ }16 \\text{ MHz}$) che per√≤ va usata pi√π spesso. Inoltre, abbiamo un sistema di trasmissione BLE che usa fino a $16 \\text{ mA @ TX}$ (i.e. $16 \\text{ mA}$ per trasmissione).\n\t- Questa CPU ha un costo pi√π alto per ciclo di clock, ma va pi√π lenta:$$I_C={2.6\\cdot 10^{-3}\\text{ A/s}\\over16 \\cdot 10^6\\text{ Cycle/s}}\\simeq0.16\\,\\mu\\text{A/Cycle}$$\n\t- Perch√© mai realizzare un processore che consuma pi√π corrente per ciclo e poi mettergli un clock pi√π lento? L'`M0` √® realizzato usando meno transistor rispetto all'`M4`. Se da un lato questo lo rende meno ottimizzato (√® costretto a fare le stesse operazioni in pi√π cicli), dall'altro questo riduce le ***leakage currents*** (i.e. quelle micro-correnti che determinano il consumo quando il processore √® in ***sleep mode***, che sono proporzionali al numero di transistor). In pratica, l'`M0` √® ottimale se va usato poco, cosa che accade se il focus √® su BLE;\n\t\t- Nota che questo effetto di leak in sleep mode √® tanto pi√π presente quanto pi√π riduciamo le dimensioni dei transistor, per effetto del tunneling quantistico.\n\t- Piccolo ***focus su BLE***: trasmette pacchetti di dimensione fissa, e tipicamente non lo fa in modo continuativo. Ogni trasmissione dura di norma $\\sim 1\\text{ ms}$, e se ad esempio trasmettesse una volta al secondo (i.e. ***duty cycle*** di ${1\\text{ ms}/1\\text{ s}}=0.001$) avremmo qui (e sottolineo qui, perch√© quel $16 \\text{ mA @ TX}$ dipende dall'HW e dalla configurazione) un consumo di $16 \\text{ mA}\\times0.001 = 16\\,\\mu\\text{A}$.","x":258,"y":120,"width":759,"height":911,"color":"4"},
		{"id":"c39cda918518baad","type":"text","text":"# Sleep Mode\n\nIn ***Sleep Mode*** il processore attua una serie di comportamenti per ridurre i consumi:\n\n- ***Clock Gating*** - Disattiva il clock su alcune unit√†, che smettono quindi di assorbire corrente (e.g. se non serve il DAC, evito di farlo girare a vuoto);\n- ***Power Gating*** - Stacca l'alimentazione da alcune unit√† (e.g. in una CPU multi-core, pu√≤ non essere sempre necessaria tutta la potenza computazionale parallela);\n- ***Dynamic Voltage and Frequency Scaling*** (***DVFS***) - Se non devo effettuare calcoli complessi, posso ridurre la tensione e la frequenza di clock (e.g. smartphones).\n\nTutto questo viene implementato in modo massiccio su ***MPU***, mentre su MCU il discorso √® pi√π complesso. Intanto tocca complicare l'HW (e non √® scontato poterlo fare). Inoltre, un MCU ha bisogno di reagire in tempo reale agli interrupt dei sensori, evitando latenze dovute a lenti processi di risveglio (***wakeup latency***). Spesso gli MCU implementano direttamente il ***Deep Sleep*** (riduce le attivit√† sia della CPU che della RAM) o l'***Ibernazione*** (salva lo stato su memoria non volatile e spegne tutto).\n\nIl fatto che su MCU ci sia meno margine per entrare in Sleep Mode non deve ingannare: essendo dispositivi ottimizzati, sono comunque loro che consumano di meno!\n\nOvviamente il consumo energetico non si azzera in Sleep Mode, per diversi motivi:\n\n- Anche se faccio Clock Gating, gli elementi circuitali esclusi sono comunque alimentati da una tensione (posso staccarla facendo Power Gating, ma in quel caso cancello tutti i bit!), che per effetti quantistici sulle giunzioni dei transistor continua a far scorrere una piccola ***leakage current*** (la quale aumenta esponenzialmente con la temperatura);\n- Anche il Power Gating pu√≤ avere perdite minime sul transistor \"ponte\", che serve a staccare/riattaccare la corrente alla zona in sleep;\n- In ogni caso, non potrei mai spegnere completamente tutto il processore: ho sempre bisogno di qualcosa di attivo che riattivi gli elementi in sleep.","x":-751,"y":1280,"width":759,"height":773,"color":"4"},
		{"id":"4c794fe5a6070164","type":"file","file":"SAM4L_Modes.png","x":258,"y":1266,"width":759,"height":304},
		{"id":"a94d060ea349fc00","type":"text","text":"# Efficienza Energetica\n\nMolti dispositivi IoT sono alimentati a batteria, ed ogni milliwatt risparmiato prolunga la durata operativa. Questo costituisce sempre un trade-off tra il consumo e la precisione dei sensori (se devo spegnerli ogni `tot` per ridurne il consumo rischio di perdere dati utili, ma per risparmiare posso anche ridurre i bit di precisione o la frequenza di campionamento).\n\nSi rende efficiente un sistema embedded implementando la Sleep Mode e ottimizzando il codice, l'uso dei sensori e delle strategie di comunicazione.","x":-1760,"y":1536,"width":759,"height":261,"color":"6"},
		{"id":"d11ebd7b1efd8ff7","type":"text","text":"# Ottimizzazione del Codice e Riferimenti\n\nChiaro che √® il codice a decidere quando andare in Sleep Mode e quando trasmettere. Questo si traduce nell'ottimizzare i periodi di ***idle*** (i.e. quando conviene disattivare cosa) e quelli di ***tempo attivo*** (i.e. se sono sveglio, allora devo fare pi√π cose possibile).\n\n- ***Parallelismo*** - Riduce il tempo attivo eseguendo operazioni in parallelo;\n- ***Batching*** - Aspetto di avere tante cose da fare prima di attivarmi. Questo ottimizza i costi di accensione/spegnimento, riducendo la frequenza delle transizioni di stato (i.e. `ON`, `IDLE` e `HIGH DUTY`, e.g. un protocollo come BLE preferisce inviare 10 pacchetti ogni secondo piuttosto che 1 ogni decimo di secondo). Questo di fatto ottimizza il ***Duty Cycle***: il dispositivo non misura/attua/invia/riceve costantemente, ma a intervalli regolari diluiti nel tempo;\n- ***Event-Driven Sampling*** - I sensori si attivano o comunicano dati solo in risposta ad un cambiamento significativo (e.g. uno smartphone accende il giroscopio solo se l'accelerometro rileva una forte accelerazione, o un termostato comunica con il gateway solo se ci sono variazioni di temperatura).\n\nAbbiamo poi due branche che si occupano di ridurre l'overhead di comunicazione:\n\n- ***Compressione dati*** - Trasmettere meno dati per trasmissione significa meno energia spesa per la comunicazione (cfr. ***Teoria dell'Informazione***);\n- ***Edge Computing*** - Ottimizza il numero di trasmissioni sulla rete (cfr. ***Fog Computing***).","x":-2769,"y":1280,"width":759,"height":773,"color":"4"},
		{"id":"43767a936de8e8b1","type":"text","text":"# Da dove prendo l'Energia?\n\nPotrei farlo da diverse fonti. Partiamo con l'escludere il caso in cui riesco a connettermi direttamente alla rete elettrica, perch√© √® banale: posso permettermi alti consumi, quindi verosimilmente uso un MPU. Restano due scenari principali, in cui si usano gli MCU:\n\n- ***Batterie*** - Soluzione alla quale si cerca con sempre pi√π forza di trovare un'alternativa. Hanno capacit√† limitata, e il loro sviluppo in termini di potenza erogata su dimensioni non sta dietro all'esponenziale evoluzione dei dispositivi embedded. Si cerca quindi di ridurre i consumi energetici a tutti i costi, ma questo si traduce in minore potenza di calcolo e velocit√† di trasmissione;\n- ***Energy Harvesting*** - Idea in via di sviluppo che prevede di raccogliere l'energia dall'ambiente in cui il dispositivo √® immerso.\n\t- Questo pu√≤, a seconda dell'architettura,\n\t\t- eliminare l'uso delle batterie. Parliamo di uno schema ***Harvest-Use***, i.e. uso in diretta l'energia che raccolgo, se non ce n'√® abbastanza mi spengo;\n\t\t- limitare l'uso delle batterie. Schema ***Harvest-Store-Use***, i.e. accumulo energia anche quando non sono attivo per usarla successivamente (in pratica √® una batteria ricaricabile).\n\t- Il concetto di fonte di energia va dal fotovoltaico/termoelettrico/eolico al calore e al movimento corporeo.","x":-1760,"y":2288,"width":759,"height":565,"color":"4"},
		{"id":"cc865f4cd6000ab4","type":"text","text":"# ARM (Architettura degli Elaboratori)\n\nArchitettura poco energivora, quindi particolarmente adatta a smartphone e tablet (√® infatti utilizzata da praticamente tutti i produttori, da Apple a **Samsung** e **Huawei**), come pure a smartwatch, dispositivi *embedded* e di tipo *Internet of Things* (come *Raspberry Pi*).\n\nARM ha sviluppato nel tempo diverse ISA, volte principalmente a migliorare l'efficienza del codice e il consumo di memoria, ma soprattutto nel 2011 ha rilasciato la propria estensione a 64 bit, **ARMv8**, dando un forte impulso all'industria dei dispositivi portatili.","x":-751,"y":-376,"width":759,"height":261,"color":"4"},
		{"id":"c7e2f44140b2cd8e","type":"text","text":"   ### **2.2. Network Layer (Comunicazione e Trasporto Dati)**\n   \n- **Particolarit√†:** A differenza di TCP/IP classico, qui il livello di rete pu√≤ **conservare dati** (data storage).\n\n### **2.4. Application Layer (Analisi e Automazione)**\n\n- **Causa:** I dati aggregati devono essere interpretati e usati per prendere decisioni.\n- **Effetto:** Si utilizzano protocolli di comunicazione applicativa come MQTT (publish-subscribe) o CoAP (REST).\n\n**CAUSA:** Un singolo dispositivo √® inutile senza un‚Äôinfrastruttura di comunicazione.\n**EFFETTO:** Servono protocolli di rete e standard per la trasmissione dati.\n\n- **Connettivit√†**: BLE consuma meno energia di WiFi, ma ha un range pi√π corto.\n    \n\n## 5. Protocolli di comunicazione\n\nI dispositivi IoT devono scambiarsi dati in modo efficiente. I protocolli sono scelti in base a **consumo energetico, latenza, scalabilit√† e sicurezza**.\n\n### Principali protocolli\n\n- **MQTT**: Leggero, basato su publish/subscribe, perfetto per connessioni instabili.\n- **CoAP**: Simile a HTTP ma ottimizzato per dispositivi a basso consumo.    \n- **Zigbee e LoRa**: Utilizzati per reti mesh e lungo raggio.\n    \n\n### Causa-effetto nella scelta del protocollo\n\n- **MQTT vs. HTTP**: HTTP √® pesante e non adatto a IoT, mentre MQTT √® ottimizzato per reti intermittenti.    \n- **Zigbee vs. WiFi**: Zigbee √® ottimo per dispositivi a basso consumo ma con throughput ridotto.\n\n\n1. **CAUSA:** L‚ÄôIoT richiede comunicazioni leggere ed efficienti, spesso su reti con poca banda.\n2. **EFFETTO:** MQTT (Message Queuing Telemetry Transport) usa un modello publisher/subscriber per trasmettere dati in modo efficiente.\n\n- Un \"publisher\" (es. un sensore) invia dati a un \"broker\".\n- I \"subscriber\" (es. altri dispositivi o server) ricevono solo i dati di loro interesse\n- Questo riduce il traffico di rete e il consumo energetico.\n\n### **4. Comunicazione e consumo energetico**\n\nQuando un dispositivo trasmette dati (WiFi, Bluetooth, LoRa, ZigBee...), consuma energia. La trasmissione RF √® spesso uno dei principali colli di bottiglia energetici.\n\n- **WiFi:** Alta potenza, ma alta velocit√†\n    \n- **BLE (Bluetooth Low Energy):** Ottimizzato per consumi ridotti, ma a corto raggio\n    \n- **LoRa:** Ideale per lunghe distanze e consumi bassissimi, ma bassa velocit√†\n    \n\nStrategie per ridurre il consumo:\n\n- Trasmettere meno spesso\n- Usare protocolli a basso consumo (MQTT, CoAP)\n- Ridurre la potenza del segnale se non serve lungo raggio\n\n","x":-4540,"y":-1560,"width":930,"height":1358},
		{"id":"2d43e95958d0e621","type":"text","text":"# Stack Protocollare IoT\n\nL'Internet serve alle Things per comunicare comandi e dati raccolti. Come?\n\nLa stack protocollare TCP/IP √® un po' un'overkill per questo tipo di applicazione. Ne usiamo una semplificata che specchia l'architettura di base, che consta di\n\n- ***Sensor/Perception Layer*** (***Edge***) - Il layer delle Things vere e proprie. Qui di norma vengono impacchettati un botto di dati da inviare al gateway;\n\t- Per via della limitata potenza delle Things, √® difficile fare preprocessing a livello di Edge Computing. Al pi√π, i sensori provano a mandare i dati solo quando servono (i.e. provano a fare ***Batching***, cfr. ***Efficienza Energetica***).\n- ***Gateway/Network Layer*** (***Fog***) - Qua si fondono il DLL e il Network Layer di TCP/IP, perch√© ***IPv6*** unifica MAC e IPv4. La logica resta quella di un ***gateway*** che media l'accesso ad Internet per conto delle Things, ma solo perch√© queste non sono abbastanza potenti da gestire una connessione completa;\n\t- Qui si alleggerisce il carico del Cloud tramite ***Fog Computing*** (i.e. preprocessing in vista dell'arrivo al Cloud). Questa architettura mira a garantire la scalabilit√† del sistema. Tipicamente un gateway √® anche un ***fog node***;\n\t- I protocolli includono roba come ***Wi-Fi*** e ***BLE***, su IPv6. Cito questi perch√© essendo standard garantiscono compatibilit√†, ma in generale posso costruirne a piacimento: la scelta del protocollo di Network √® dettata dalla specifica applicazione, perch√© √® sempre un ***trade-off tra potenza e portata*** (stando ovviamente attenti alla complessit√† di comunicazione).\n- ***Application Layer*** (***Cloud***) - Come l'omonimo TCP/IP, qui troviamo i protocolli di alto livello. L'idea cardine di questo layer in versione IoT √® che un protocollo come `HTTP` √® troppo pesante e non tollera disconnessioni frequenti (cosa che invece qui accade). Abbiamo quindi un paio di sue varianti:\n\t- ***MQTT*** (**Message Queuing Telemetry Transport**)\n\t- ***CoAP*** (**Constrained Application Protocol**)\n\n<span style=\"color:rgb(236, 155, 14)\">Queste ultime sembrano basarsi su TCP/UDP, ma qui non ci sta il transport layer!! Che succede?</span>\n","x":-3278,"y":-1227,"width":759,"height":842,"color":"4"},
		{"id":"1f0970b33a4cb76f","type":"file","file":"NetworkProtocols.png","x":-3278,"y":-1937,"width":758,"height":408},
		{"id":"469a1094f676e542","type":"text","text":"# Sicurezza\n\nI dispositivi IoT, in quanto dispositivi connessi alla rete, sono vulnerabili a cyber-attacchi e manipolazioni fisiche. Questo rende necessario implementate misure di sicurezza HW e SW.\n\nChiaro, ma cosa c'√® di nuovo? Il fatto √® che questi dispositivi sono poco potenti, quindi devo limitarmi a protocolli leggeri ed efficienti.\n\n#### TPM (Trusted Platform Module) (HW)\n1. **CAUSA:** Un attaccante pu√≤ tentare di modificare il software di un dispositivo per prenderne il controllo.\n2. **EFFETTO:** TPM immagazzina chiavi crittografiche in hardware per proteggere l‚Äôintegrit√† del dispositivo.\n\n- TPM genera e protegge chiavi di crittografia.\n- Pu√≤ autenticare l‚Äôhardware impedendo modifiche non autorizzate.\n   \n##### Secure Boot (HW/SW)\n1. **CAUSA:** Un firmware modificato pu√≤ compromettere l‚Äôintero sistema.\n2. **EFFETTO:** Secure Boot verifica la firma digitale del firmware prima di avviarlo.\n   \n**Motivi per aggiornare il firmware:**\n\n- Correggere vulnerabilit√† di sicurezza.\n- Aggiungere nuove funzionalit√† senza sostituire l‚Äôhardware.\n\n#### Autenticazione e controllo accessi\n1. **CAUSA:** Senza autenticazione, chiunque potrebbe accedere ai dispositivi IoT.\n2. **EFFETTO:** Si usano metodi come password, certificati digitali e autenticazione a due fattori.\n   \n- Un termostato smart richiede autenticazione prima di essere controllato da remoto.\n- Un sistema di videosorveglianza cifra i dati per impedire accessi non autorizzati.\n\n\n\n## 6. Sicurezza nei dispositivi IoT\n\nLa sicurezza √® un problema critico: un dispositivo IoT vulnerabile pu√≤ compromettere un‚Äôintera rete.\n\n### Strategie di sicurezza\n\n- **Secure Boot**: Impedisce che firmware malevoli vengano eseguiti ‚Üí fondamentale perch√© molti dispositivi IoT devono aggiornarsi da remoto (OTA updates).\n    \n- **Trusted Platform Module (TPM)**: Hardware dedicato alla crittografia e protezione delle chiavi ‚Üí essenziale per autenticazione sicura.\n    \n- **Autenticazione e controllo accessi**: Limitare chi pu√≤ accedere ai dispositivi per prevenire attacchi.\n    \n\n### Causa-effetto nella sicurezza\n\n- **Un firmware non autenticato pu√≤ compromettere l‚Äôintera rete** ‚Üí Secure Boot impedisce esecuzione di codice non verificato.\n    \n- **Un dispositivo compromesso pu√≤ diffondere malware** ‚Üí TPM protegge chiavi crittografiche.\n    \n- **L‚Äôuso di password deboli facilita attacchi** ‚Üí Autenticazione forte e aggiornamenti regolari.\n    ","x":-3449,"y":-202,"width":1360,"height":1287},
		{"id":"24e729d51fa94980","type":"text","text":"\nil NL √® un po' diverso da quello di TCP/IP, pu√≤ fare addirittura data storage. BLE e WiFi sono considerati protocolli di questo layer\n\n\n### **4.2. Standardizzazione e Interoperabilit√†**\n\n- **Causa:** Ogni produttore usa formati di dati e protocolli diversi.\n    \n- **Effetto:** Si cerca di definire standard unificati (es. Open Connectivity Foundation, MQTT, CoAP).\n    \n\n### **4.3. Adattabilit√† ai Cambiamenti Ambientali**\n\n- **Causa:** I nodi fog possono spegnersi, cambiare posizione o avere variazioni di capacit√†.\n    \n- **Effetto:** I sistemi devono essere **dinamici** e adattarsi ai cambiamenti in tempo reale.\n    ","x":-4200,"y":-2340,"width":643,"height":540},
		{"id":"9b1a993fbf97aa5e","type":"text","text":"# Energy Harvesting come MDP\n\nSe hai voglia, pacco di slides 3_3_1\n\nRiferimenti:\n\n- CdM in generale: cfr. ***Computer Network Performance***;\n- MDP e Q-Learning: cfr. ***Autonomous Networking***.","x":-1760,"y":3040,"width":759,"height":227,"color":"1"},
		{"id":"2ce83f8e9814f3bc","type":"file","file":"IoT_Architecture.png","x":-751,"y":-1465,"width":759,"height":465},
		{"id":"d700a52cca1cdc2a","type":"text","text":"# Fog Computing\n\nIl Cloud, seppur potente, √® costoso e lontano (nonch√© potenzialmente offline, in caso di guasti). Alcune applicazioni potrebbero richiedere decisioni rapide (e.g. un sensore di caduta per persone anziane √® costretto a decidere rapidamente se mandare l'allarme), in altre bisogna considerare che una rete IoT pu√≤ essere usata per gli obiettivi pi√π disparati, e che per questo sia HW che SW sono fortemente specifici dell'applicazione.\n\nViene quindi naturale capire che in una rete IoT vanno elaborati dati ***eterogenei***, sia nel senso che diversi sensori producono diversi formati di output (i.e. i ***dati*** nel complesso sono ***non-strutturati***) sia che diverse informazioni hanno diverse ***priorit√†***. √à scomodo far gravare tutto il peso di un'analisi dati fortemente diversificata su un unico server centrale.\n\nQuesto problema viene mitigato con i ***fog nodes***, i.e. distribuisco il server di analisi dati. Il ***Fog Computing*** √® in pratica una via di mezzo tra l'Edge Computing e il Cloud Computing, in cui sono i ***gateway*** stessi a pre-processare i dati prima di inviarli al Cloud (o addirittura a decidere cosa vale la pena mandargli e cosa no!).\n\nTutto molto bello, ma c'√® un problema: ogni sensore genera un carico di lavoro variabile, e i fog nodes hanno capacit√† limitate (sia in termini di `FLOPs` che di memoria). Tradotto, bisogna trovare un algoritmo per assegnare dinamicamente le richieste dei sensori al fog node ottimale per evitare colli di bottiglia (l'assegnazione viene tipicamente svolta da un ***dispatcher*** che si trova tra le Things e i fog nodes).\n\nQuesto √® un ***Bin Packing Problem*** (o `0-1 Knapsack Problem`), pertanto $\\NPC$. Per piccole/medie dimensioni esistono algoritmi di ottimizzazione che forniscono soluzioni esatte, ma diventano esponenzialmente pi√π lenti al crescere dell'input (cfr. ***Gurobi***). Si cercano quindi euristiche ed algoritmi approssimanti.\n\n","x":-1760,"y":-2428,"width":759,"height":695,"color":"4"},
		{"id":"c8f665ef67bbc260","type":"text","text":"# `0-1 Knapsack` & Bin Packing Problem\n\nHai uno zaino con una ***capacit√† massima*** (e.g. 7 kg). Davanti a te hai un mucchio di oggetti. Ognuno ha un ***peso*** e un ***valore*** (quanto ti serve o quanto √® prezioso). Puoi prendere ogni oggetto una sola volta (0 o 1 volte). La sfida √®: quali oggetti scegli per massimizzare il valore totale nello zaino, senza superare il peso massimo? Esempio:\n\n- Laptop - 3 kg, 2000‚Ç¨;\n- Bottiglia d‚Äôacqua - 2 kg, 10‚Ç¨;\n- Oro - 5 kg, 3000‚Ç¨;\n- Libro - 4 kg, 100‚Ç¨\n\nNon puoi prendere \"mezzo oro\" o \"mezzo laptop\". Devi decidere: o lo prendi tutto, o niente. Con tanti oggetti, le possibili combinazioni esplodono e rendono il problema $\\NPC$. Serve una strategia intelligente, perch√© il brute force non funzioner√†.\n\nTra le possibili strategie:\n\n- ***Algoritmi Greedy*** - Prendi gli oggetti col miglior rapporto valore/peso;\n- ***Programmazione dinamica*** - Costruisci una tabella che ti dice il valore massimo ottenibile per ogni sottopeso;\n- ***Branch & bound*** - Esplori l‚Äôalbero delle soluzioni tagliando i rami inutili.\n\nTutto questo vale per uno zaino e prende il nome di `0-1 Knapsack Problem`. Se fossero $F$, avremmo il ***Bin Packing Problem*** (cfr. ***Fog Node Assignment Problem***).\n\nEsistono varianti di questo problema, e.g. **Fractional knapsack** (i.e. puoi prendere frazioni di oggetti, diventa pi√π facilmente risolvibile in modo greedy).","x":-751,"y":-2428,"width":759,"height":695,"color":"4"},
		{"id":"ea6c2db0218bf20e","type":"text","text":"# Fog Node Assignment Problem\n\nPrendiamo l'esempio del *fall detector*. Ogni sensore invia una task (e.g. `questi sono i dati che ho raccolto, puoi fare i tuoi potenti calcoli e dirmi se vogliono dire che nonna √® caduta?`) a un ***dispatcher***, che decide a quale fog node inoltrarlo.\n\nTraduciamo questa roba in matematica. Abbiamo:\n\n- $N$ sensori $s_i$, a cui corrispondono risorse richieste $r_i$ (i.e. se il sensore $s_i$ invia le proprie task ad un fog node, questo consumer√† $_i$ per risolverle, e.g. in termini di `FLOPs`);\n- $F$ fog nodes $f_j$ che per funzionare richiedono risorse $g_j$ (e di conseguenza costi $c_j$). Tipicamente $N\\gg F$ (altrimenti il problema sarebbe molto semplice!);\n- Un dispatcher $D$ che raccoglie i dati e li smista ai vari fog nodes. $D$ conosce i $c_i$ di ciascun $f_i$, ed √® a lui che spetta il compito di ottimizzare l'assegnazione.\n\n Definiamo due grandezze binarie:\n \n- $y_j=1 \\iff f_j$ viene utilizzato;\n- $x_{ij}=1 \\iff$  una task di $s_i$ √® assegnata ad $f_j$.\n\nA questo punto il compito di $D$ √® trovare la soluzione di$$\\min_y\\sum_jy_j\\,c_j$$il che ovviamente minimizza il costo complessivo. Mancano i constraints, perch√© cos√¨ com'√® la soluzione migliore √® scegliere $y$ identicamente nullo. Allora mettiamo$$\\sum_jx_{ij}=1\\quad \\forall\\,i$$i.e. voglio che tutti i task siano eseguiti (altrimenti pu√≤ essere che nonna cade e l'allarme non parte). Inoltre non posso eccedere la capacit√† totale di ciascun fog node, i.e.$$\\sum_ix_{ij}\\,r_i\\le g_j\\,y_j\\quad \\forall\\,j$$Abbiamo ufficialmente formulato il problema come ***ILP***. Questa roba √® pi√π generale rispetto ad un ***Bin Packing Problem***, perch√© (contrariamente ai fog nodes) gli zaini (bin) non hanno un costo associato e le loro capacit√† sono tutte uguali.","x":-1760,"y":-3565,"width":759,"height":902,"color":"4"},
		{"id":"1d4c9d197fab6065","type":"text","text":"# Gurobi\n\nVedi codice colab. Esegui, gioca. C'√® un problema di ottimizzazione su classroom\n\ngurobi cerca soluzioni esatte, non √® approssimante \n\npoi ha fatto una roba sull'ottimizzazione lineare in generale\n\n\n\nottimizzazione lineare in N dimensioni: $\\min_x c^Tx = \\min_x \\sum_i c_ix_i$ con constraints$$Ax\\le b\\quad A_ex=b_e\\quad x\\in D$$\nnel problema di prima questi constraints (credo siano restrizioni di dominio e condizioni al contorno) diventano$$\\sum_ix_ir_i\\le g\\quad \\sum_{i\\ne j}x_{ij}=1\\quad x\\in\\Z$$\nho scritto \"copia tablet\" ma non trovo questi fantomatici appunti a riguardo.","x":-751,"y":-3565,"width":759,"height":902},
		{"id":"796fa6183e62d341","type":"text","text":"# Breve Storia della Teoria dell'Informazione\n\nGi√† durante gli anni '20 ***Nyquist*** e ***Hartley*** avevano pubblicato studi circa la trasmissione di informazioni, giungendo a forme funzionali del tipo $A = \\log B$. L'informazione veniva definita come la ***capacit√† del ricevitore di distinguere una sequenza di simboli da qualsiasi altra***.\n\n Durante il suo lavoro come crittografo nel corso della WWII, ***Shannon*** comprende che la codifica di messaggi segreti implica di fatto l'aggiunta di rumore ingannevole ai messaggi originali, e che la decodifica consiste nella rimozione di tale rumore. √à forse ripensando a questo che quando gli viene chiesto di ottimizzare la comunicazione su canali rumorosi inizia a pensare ad un'astrazione teorica per modellizzare il problema.\n\nNel ***1948*** compare un suo articolo in cui definisce cos√¨ il processo della comunicazione:\n\n- Dato un insieme di possibili messaggi, una ***sorgente di informazione*** ne seleziona uno; \n- Un ***trasmettitore*** codifica questo messaggio in un ***segnale***;\n- Il segnale viene inviato attraverso un ***canale***, dove pu√≤ essere corrotto dal ***rumore***;\n- Un ***ricevitore*** decodifica quindi il segnale ricevuto per ricostruire il messaggio originale.\n\nLa rivoluzione di questo modello √® l'uso della probabilit√† per modellare sorgente e rumore. Di conseguenza, le grandezze qui definite (e.g. l'***entropia dell'informazione***) trovano facili paralleli con la ***meccanica statistica***, e le applicazioni della teoria nel suo complesso spaziano oggi dalla codifica del DNA umano alle grandi teorie di unificazione in fisica.\n\nL'articolo del 1948 segna convenzionalmente l'inizio dell'***Era dell'Informazione***.","x":508,"y":-2428,"width":759,"height":695,"color":"4"},
		{"id":"54d0a7ecb87b5c26","type":"text","text":"# Internet of Things (IoT)\n\nCon la ***miniaturizzazione dei processori*** che permette di inserire intelligenza praticamente ovunque e ***IPv6*** che permette di assegnare un indirizzo univoco a $O(10^{38})$ dispositivi, √® facile immaginare un mondo in cui qualsiasi oggetto pu√≤ collegarsi ad Internet.\n\n***Internet of Things*** (***IoT***) √® il successore di quello che oggi conosciamo come Internet: se ai nodi aggiungiamo ***sensori*** per monitorare l'ambiente e ***attuatori*** per modificarlo, di fatto estendiamo il concetto di ***servizio*** (e.g. mail, video) a un qualcosa che viene materialmente fatto (in modo automatico e ottimizzato) nel mondo materiale di tutti i giorni (e.g. domotica).\n\nEssendo tanti, l'intelligenza e l'autonomia media di un singolo nodo IoT √® abbastanza bassa. Questo apre a tutta una serie di problemi sulla sicurezza della comunicazione hop-to-hop e sulla necessit√† di protocolli energy-efficient ad hoc (e.g. da ***BLE*** a ***6LoWPAN***).","x":1513,"y":-1000,"width":759,"height":387,"color":"6"},
		{"id":"d51f893becdde7b8","type":"text","text":"# Teoria dell'Informazione\n\nLa Teoria dell'Informazione si occupa dello studio della quantificazione, dell'archiviazione e del trasferimento dell'informazione. Nasce da tre osservazioni sulla comunicazione:\n\n1. Il ***contenuto informativo*** di un messaggio equivale alla ***sorpresa*** che genera;\n2. In ogni ***linguaggio***, le parole di ***uso comune*** sono pi√π corte di quelle non-comuni;\n3. Se ti perdi qualche pezzetto di frase, sei ancora in grado di ***ricostruire il messaggio***.\n\nDa questi tre principi, la modellizzazione matematica tira fuori tre risultati principali:\n\n1. Data una ***sorgente d'informazioni***, l'***Entropia di Shannon*** quantifica il valore atteso della ***sorpresa*** (i.e. del ***contenuto informativo***) del generico ***messaggio*** che essa pu√≤ produrre, definendo il concetto di $\\bit$ informativo come unit√† di misura dell'informazione. Costituisce inoltre il limite inferiore alla ***compressione*** di un messaggio;\n- Dato un ***alfabeto*** di ***simboli*** (i.e. ***eventi*** o ***messaggi***), una ***codifica*** mira a trasformare tali simboli in sequenze di simboli (dette ***codeword***) di un altro alfabeto, detto ***codice***;\n\t- Se sembra non avere senso, considera che ***ASCII*** √® una ***codifica binaria*** che trasforma simboli dell'alfabeto in sequenze di `bit`;\n\t2. Se utilizzo una ***codifica a lunghezza variabile*** posso applicare una ***compressione***, i.e. sfrutto la pdf della sorgente di simboli per assegnare ai messaggi pi√π frequenti una rappresentazione pi√π breve, e di conseguenza ottimizzare la lunghezza media della codeword. Si capisce anche meglio perch√© il suo limite inferiore √® l'entropia: la compressione mira a ***minimizzare il numero di `bit` per ***$\\bit$;\n\t3. Se utilizzo una ***codifica a lunghezza fissa*** posso costruire codici appositamente per essere robusti rispetto al ***rumore***, utile se devo ***trasferire l'informazione***.","x":1513,"y":-2428,"width":759,"height":695,"color":"6"},
		{"id":"bb5a7945372dc391","type":"text","text":"# L5 & L6\n\nSaltate, vedi slides","x":1513,"y":514,"width":759,"height":320},
		{"id":"a8dcb3193cec51a3","type":"text","text":"# L7 & L8\n\nInformation Theory, vedi quaderno","x":1513,"y":871,"width":759,"height":320},
		{"id":"032d9aeb665be7c1","type":"text","text":"\n## **4. Problemi Aperti e Considerazioni Finali**\n\n### **4.1. Sicurezza e Privacy**\n\n- **Causa:** L‚ÄôIoT spesso lavora con dati sensibili (sanit√†, sorveglianza, automobili connesse).\n    \n- **Effetto:** Servono protocolli di sicurezza **leggeri ma efficaci** (es. DTLS, crittografia elliptic curve per dispositivi a bassa potenza).\n    \n\n\n**Approfondimenti consigliati:**\n\n- Ricerca su **Bin Packing Problem** e tecniche di risoluzione (branch-and-cut, metaeuristiche).\n    \n- Studio di protocolli MQTT e CoAP per comprendere le differenze pratiche.\n    \n- Analisi di casi studio reali di fog computing per applicazioni industriali.","x":1513,"y":-420,"width":759,"height":404},
		{"id":"442ecb8952c528e2","type":"text","text":"## cortex (il malvagio)\n\ntutti ARM. Memory Protection Unit fa switch tra  user e kernel mode.\nDMA (vedi sistemi operativi immagino)\nvbb √® tutto un ripassone di cose (+ specifiche processori cortex) fino a slide 27, poi entra in dettaglio sugli interrupt (e.g. int. request (IRQ) - viene dal sensore, √® il pi√π comune) con tutta la parte tecnica (yeee).\nirrisorie differenze in costi diventano gargantuesche se moltiplicate per il numero di things. segue esempio. ma non su questo! sul fatto che tra sleep ed active consumption passa un universo mondo di potenza. poi aggiunge lo stato di transizione tra sleep  ed active (non ditelo a Donald).","x":1513,"y":70,"width":759,"height":315},
		{"id":"713d15910e78e93b","type":"text","text":"## ‚òÅÔ∏è **XaaS: l‚Äôidea alla base del Cloud**\n\nImmagina di avere bisogno di **potenza di calcolo**, **spazio di archiviazione**, o semplicemente di **un'applicazione che funzioni**. Prima dell‚Äôavvento del cloud, significava comprare hardware, installare software, mantenerlo, aggiornarlo, fare backup...\n\nCon il cloud, invece, **tutto questo diventa un servizio a richiesta**. Come l‚Äôacqua o l‚Äôelettricit√†: apri il rubinetto (o l‚ÄôAPI), e arriva.\n\nDa qui il concetto di **‚Äúas a Service‚Äù**: non possiedi le cose, **le affitti**. Ma attenzione: a **diversi livelli di astrazione**.\n\n---\n\n## üß± **I tre pilastri: IaaS, PaaS, SaaS**\n\nImmagina di voler aprire una pizzeria digitale üçï. Hai diverse opzioni, a seconda di quanto vuoi fare tu e quanto vuoi delegare:\n\n---\n\n### üèóÔ∏è 1. **IaaS ‚Äì Infrastructure as a Service**\n\n> Hai il mattone, ma devi costruire la casa.\n\n- Ti affittano **server virtuali**, storage, rete.\n    \n- Tu ci installi sopra OS, database, librerie, codice‚Ä¶\n    \n- Sei responsabile della **gestione**: patch, backup, scaling.\n    \n\nüë®‚Äçüç≥ **Esempio pizzeria**: ti danno un locale vuoto e il forno. Tu porti ingredienti, assumi personale, fai tutto.\n\nüñ•Ô∏è **Esempi reali**:\n\n- Amazon EC2 (server virtuali)\n    \n- Google Compute Engine\n    \n- Microsoft Azure VM\n    \n\nüì¶ **Use case tipico**: hai gi√† un'app custom e vuoi solo non occuparti dell‚Äôhardware fisico.\n\n---\n\n### üõ†Ô∏è 2. **PaaS ‚Äì Platform as a Service**\n\n> Hai la cucina pronta, devi solo cucinare.\n\n- Ti danno un ambiente di sviluppo gi√† configurato: OS, runtime, database, servizi.\n    \n- Tu **ci carichi il codice**.\n    \n- Scalabilit√†, patch, sicurezza... tutto gestito dal provider.\n    \n\nüë®‚Äçüç≥ **Esempio pizzeria**: affitti una cucina con staff base. Tu porti le ricette.\n\nüñ•Ô∏è **Esempi reali**:\n\n- Google App Engine\n    \n- Heroku\n    \n- Azure App Services\n    \n\nüì¶ **Use case tipico**: vuoi solo scrivere codice e testare, senza perdere tempo a configurare ambienti.\n\n---\n\n### üì± 3. **SaaS ‚Äì Software as a Service**\n\n> Ti siedi e mangi.\n\n- L‚Äôapp √® gi√† pronta.\n    \n- Tu ti limiti a **usarla** via web o app.\n    \n- Non gestisci nulla, nemmeno l‚Äôinstallazione.\n    \n\nüë®‚Äçüç≥ **Esempio pizzeria**: ordini su JustEat. Ti arriva la pizza.\n\nüñ•Ô∏è **Esempi reali**:\n\n- Gmail\n    \n- Google Docs\n    \n- Dropbox\n    \n- Salesforce\n    \n\nüì¶ **Use case tipico**: vuoi solo accedere a una funzionalit√† senza curarti del \"come\".\n\n---\n\n## üéØ Schema riassuntivo\n\n|Livello|Chi controlla cosa|Pro|Contro|\n|---|---|---|---|\n|**IaaS**|Tu gestisci quasi tutto|Massima flessibilit√†|Complessit√† gestionale|\n|**PaaS**|Tu gestisci il codice|Rapido sviluppo|Meno controllo|\n|**SaaS**|Usi e basta|Zero gestione|Nessuna personalizzazione|\n\n---\n\n## üîÅ E se andiamo oltre?\n\nCi sono anche altre sigle:\n\n- **FaaS** ‚Äì Function as a Service (serverless: carichi una funzione e parte quando serve)\n    \n- **BaaS** ‚Äì Backend as a Service (es: Firebase, ti d√† DB + auth + API)\n    \n- **DBaaS** ‚Äì Database as a Service\n    \n- **MLaaS** ‚Äì Machine Learning as a Service (es: modelli gi√† pronti da usare)\n    \n\nE infine: **Everything as a Service (XaaS)** ‚Äì √® il futuro, dove ogni componente IT (e non solo) diventa affittabile via API.\n\n---\n\n## üß© Relazione con Fog/Edge\n\nQuesta gerarchia vale **anche nel fog computing**, con una differenza chiave: **la latenza e la localizzazione**.\n\n- Un **fog node** pu√≤ offrire **IaaS** (es: una piccola VM nel router di casa), o **PaaS** (un ambiente gi√† pronto per analisi video), o addirittura **SaaS** (una app embedded nel semaforo che decide il verde).\n    \n- Ma tutto avviene **vicino all‚Äôorigine del dato**.\n    \n\nIl paradigma rimane lo stesso: **a cosa vuoi delegare? e quanto controllo ti serve?**\n\n---\n\nSe vuoi, posso integrarti anche un diagramma a blocchi tipo matrioska (SaaS dentro PaaS dentro IaaS) oppure delle analogie pi√π \"da mondo reale\" (es: trasporto: comprare un'auto, noleggiarla, prendere un taxi). Fammi sapere!","x":-3279,"y":-5342,"width":759,"height":2914},
		{"id":"bc00b250b7b24ec0","type":"text","text":"# Informazione, Sorpresa ed Entropia\n\nL'idea fondamentale alla base di questo modello √® che gli eventi rari ci sorprendono pi√π di quelli frequenti. Prendiamo ad esempio un evento binario i cui outcome hanno probabilit√† $\\P[A]=t$ e $\\P[B]=1-t=q$ e fissiamo $t=0.99$. Non saremo affatto sorpresi se si verifica l'evento $A$. In altri termini, il verificarsi di $A$ non costituisce un'***informazione*** significativa. Se per√≤ viceversa si verifica $B$ (che ha probabilit√† $q=0.01$) le cose cambiano: saremo sorpresi, e in un mare di eventi $A$ il verificarsi di $B$ sar√† un'informazione significativa.\n\nIn particolare, pi√π $q$ si avvicina a $0$ pi√π il verificarsi di $B$ sar√† un evento sorprendente. Viceversa, quando $q\\to1$ la sorpresa va ad annullarsi. Un buon modo per modellizzare a livello matematico questo comportamento √® definire il ***contenuto informativo*** (o ***sorpresa***) di un evento $E$ che si verifica con probabilit√† $\\P[E]$ come$$\\I[E]=-\\log_2\\bigg(\\P[E]\\bigg)=\\log_2\\bigg({1\\over\\P[E]}\\bigg)$$\nIl logaritmo ha senso, quella base $2$ sembra un po' arbitraria ma sar√† chiara a breve. Il punto √® che adesso abbiamo la sorpresa per un evento, vediamo che succede se sommiamo su tutte le possibilit√†. Limitiamoci un attimo ad eventi binari e scriviamo l'***entropia binaria***$$h(t)=t\\log_2\\bigg({1\\over t}\\bigg)+(1-t)\\log_2\\bigg({1\\over 1-t}\\bigg)\\in[0,1]$$dove $t\\in(0,1)$ √® la probabilit√† di uno dei due eventi. Possiamo facilmente estendere per continuit√† a $t\\in[0,1]$ definendo $h(0)=h(1)=0$, e per com'√® scritta ha un massimo in $t=0.5$. Tale massimo vale $1$: la logica della base $2$ del logaritmo √® quindi normalizzare la binary entropy. Essendo un oggetto del tipo \"somma di (sorpresa $\\times$ probabilit√† della sorpresa)\", l'entropia costituisce un ***valore atteso di sorpresa***. Di chi? Della ***sorgente di informazioni***!\n\nQuesto significa che possiamo caratterizzare il grado di imprevedibilit√† (o caos, se ci piace il parallelismo con la fisica) di una sorgente di eventi probabilistici tramite questa funzione: una sorgente √® \"poco sorprendente\" se $t\\sim 0$ o $t\\sim1$ (non ha senso lanciare una moneta se esce sempre testa!), e \"molto sorprendente\" per $t\\sim 0.5$ (massima casualit√†).\n\nNota che in realt√† posso estendere tutto questo anche a sorgenti non binarie. Sia $X$ una random variable (RV) che pu√≤ assumere valori $\\{x_1, ..., x_n\\}$ con probabilit√† $p_i = \\P[X=x_i]$ (i.e. $X$ √® una sorgente di informazioni). L'***entropia di Shannon*** di $X$ √® data da$$H(X)=-\\sum_ip_i\\log_2(p_i)=\\sum_ip_i\\log_2\\bigg({1\\over p_i}\\bigg)\\in[0, \\log_2n]$$che √® massima se la pdf √® piatta (i.e. una moneta truccata ha meno entropia di una \"pulita\").\n\nRiassumendo: la ***sorpresa*** √® legata all'***evento***, l'***entropia*** alla ***distribuzione***.","x":1513,"y":-3693,"width":759,"height":1030,"color":"4"},
		{"id":"953ba1b6df1d2cf5","type":"text","text":"# Compressione (lossless) dell'Informazione\n\nPoniamo di dover comunicare in binario codificando ogni lettera dell'alfabeto (`a, ..., z`). Posto che potrei usare `5 bit` (devo contare fino a pi√π di `16` ma a meno di `32`) scegliendo `a = 00000`, `b = 00001`, `...`, esiste un modo pi√π ottimizzato per scegliere la codifica?\n\nAnzitutto, c'√® un'importante scelta da fare:\n\n- Se non accetto di perdere informazione nel processo (***compressione lossless***) devo trovare una corrispondenza biunivoca tra il messaggio codificato e la sua decodifica. Per fare ci√≤ mi serve una ***binary encoding*** di tipo ***prefix-free***;\n- Se accetto di perdere informazione nel processo (***compressione lossy***) posso permettermi di ridurre le dimensioni oltre i limiti della versione lossless.\n\nLimitiamoci alla compressione lossless e troviamo il limite di compressione.\n\nPosto di aver trovato un prefix-free encoding e di avere un set di probabilit√† $\\P$ associate alle parole di $\\calM$ (i.e. sappiamo qual √® la frequenza attesa delle varie parole), definiamo$$l(f)=\\sum_{m\\in\\calM}\\P[m]\\,\\bigg|f(m)\\bigg|=\\sum_{m\\in\\calM}\\P[m]\\,l_m$$lunghezza media di $f$ (i.e. della stringa prodotta da $f$ su $m\\in\\calM$ secondo $\\P$). Capiamo bene che il problema originale coincide con il minimizzare $l(f)$. Ma andiamo con ordine. La ***disuguaglianza di Kraft*** stabilisce una relazione per il codici prefix-free:$$\\sum_{m\\in\\calM}2^{-l_m}\\le1$$\nChe significa? Se interpretiamo la codifica PF come un albero binario (ogni nodo √® un prefisso, ogni ramo `0/1` porta ad un nuovo prefisso), ogni $f(m)$ √® il cammino dalla radice ad una foglia. Kraft dice che se quella somma fa pi√π di $1$, allora stai cercando di usare pi√π foglie di quante ne esistono. Di conseguenza, almeno una $f(m)$ non sar√† una foglia, i.e. sar√† il prefisso di una qualche $f(m')$.\n\nQuesto lemma si usa per dimostrare il ***Teorema di Codifica della Sorgente***: l'***entropia*** √® il ***limite inferiore della compressione lossless***, i.e.$$l(f)\\ge H(\\P)$$dove l'uguaglianza vale solo per distribuzione $\\P$ uniforme.\n\nOra, uno potrebbe pensare che questo limite sia pi√π stringente del dovuto, perch√© abbiamo preso un encoding prefix-free invece di uno univocamente decodificabile. Invece no: il limite resta questo anche se rilasso quella condizione.\n","x":508,"y":-3693,"width":759,"height":1030,"color":"4"},
		{"id":"5a1008ab6d4f93fb","type":"text","text":"# Variable Length Binary Encodings\n\nIn generale, il concetto di ***alfabeto*** √® esteso ad un insieme $\\calX$ di ***simboli*** ($|\\calX|<\\infty$). $\\calM$ √® l'insieme delle ***parole*** (o ***codewords***) di un certo ***codice*** costruito su $\\calX$ ($|\\calM|<\\infty$), ed $\\calM^*$ √® l'insieme delle ***sequenze di parole*** $m\\in\\calM$ ($|\\calM^*|=\\infty$).\n\nQui ci limitiamo per√≤ ad un ***alfabeto binario***, quindi $\\calX=\\{0,1\\}$. Non solo: permettiamo parole di lunghezza variabile (perch√© stiamo facendo compressione, per i canali rumorosi $l$ si fissa).\n\nUn ***variable length binary encoding*** √® una funzione iniettiva $f:\\calM\\to\\{0,1\\}^*$, i.e. ogni $m\\in\\calM$ √® mappata in una sequenza binaria distinta da tutte le altre (non √® biettiva perch√© $\\{0,1\\}^*$ √® un insieme infinito, non √® vero che ogni sequenza binaria codifica una $m\\in\\calM$).\n\nTrovare $f$ sembra sufficiente, ma solo se trasmetto una parola alla volta. Di norma voglio trasmetterne diverse, quindi devo trovare una $f^*:\\calM^*\\to \\{0,1\\}^*$ iniettiva. Il che ovviamente non √® facile! Chiaro che $f^*(m^*)=f(m_1)...f(m_n)$, ma proprio per questo se codifico `A = 0`, `B = 1` e `C = 01`, la stringa `001` pu√≤ voler dire sia `AAB` che `AC`!\n\nSegue che $f$ √® ***univocamente decodificabile*** (UD) se $f^*$ √® iniettiva. Quindi la domanda √®: come si costruisce una $f^*$ iniettiva? Ci serve che nessuna coppia di parole $m,m'\\in\\calM$ sia codificata da $f$ in modo ambiguo, i.e. che $$\\forall\\, m,m'\\in\\calM \\,|\\, m\\ne m'\\to f(m)\\not\\trianglelefteq f(m')$$ovvero che per ogni coppia $m,m'$ $f(m)$ non sia un prefisso di $f(m')$. Se ci√≤ si verifica, $f$ √® detta ***codifica prefix-free*** (PF). Intuitivamente, $x$ √® prefisso di $y$ se $\\exists\\,z\\in\\{0,1\\}^*$ t.c. $y=zx$. Le codifiche prefix-free sono un ***sottoinsieme*** di quelle UD. Pertanto, $$\\text{PF} \\so \\text{UD}\\qquad\\text{ma}\\qquad \\text{UD} \\not\\so \\text{PF}$$\nOk, ma come costruisco una codifica PF? Intanto la disuguaglianza di Kraft$$\\sum_{m\\in\\calM}2^{-l_m}\\le1$$fornisce una condizione sufficiente: se scelgo delle lunghezze $l_m$ tali che questa viene rispettata, allora esiste una codifica PF avente le $f(m)$ ti tali lunghezze. <span style=\"color:rgb(236, 155, 14)\">Qui √® dove avrei voluto trovare un algoritmo reale, ma non ne ho voglia.</span>","x":508,"y":-4834,"width":759,"height":913,"color":"4"},
		{"id":"eadc00ddd47569d3","type":"text","text":"# Discrete Memoryless Channel (DMC)\n\nPartiamo da uno schema semplice: invio `0` o `1` e il `bit` pu√≤ essere flippato con probabilit√† $\\e$. Possiamo descrivere i possibili scenari dovuti al rumore con una ***matrice stocastica***\n$$\n\\calW(Y|X)=\\begin{bmatrix}\nP(0 \\mid 0) & P(1 \\mid 0) \\\\\nP(0 \\mid 1) & P(1 \\mid 1)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 - \\varepsilon & \\varepsilon \\\\\n\\varepsilon & 1 - \\varepsilon\n\\end{bmatrix}\n$$\n\nNessuno per√≤ trasmette un `bit` alla volta: in questo modo posso comunicare solo risultati di eventi $X Y$ binari, e il rumore potenzialmente ribalta quello che voglio comunicare.\n\nGeneralizziamo a situazioni in cui l'input consta di ***simboli*** $x\\in\\calX$ e l'output di altri simboli $y\\in\\calY$ (i.e. metti che il tuo alfabeto di partenza √® `A B C` ma il rumore ti fa ricevere una `D`). Questo si traduce in una matrice $|\\calY|\\times|\\calX|$ $$\\calW(\\calY|\\calX)=\\P(y_i|x_j)$$Se ricevo una sequenza di $n$ simboli, posso risalire alla probabilit√† che questi siano esattamente quelli che erano stati inviati in input:$$W^n(Y=\\vec{y}\\mid X=\\vec x)=\\prod_{k=1}^n\\calW(y_k\\mid x_k)$$dove la produttoria indica la propriet√† di ***assenza di memoria*** del canale.\n\nDefiniamo un ***encoder*** $\\calC^n$ come un subset $\\sse \\calX^n$ di tutte le possibili sequenze di `n bit` realizzabili sull'alfabeto $\\calX$: $c\\in\\calC^n\\in\\calX^n$ sono le ***codeword***, e vengono inviate sul DMC. In output, un ***decoder*** $\\varphi^n$ prova a ricondurre la sequenza $s\\in\\calY^n$ che osserva ad una $c\\in\\calC^n$. Un ***errore*** si verifica quando il decoder ricostruisce una codeword diversa da quella che era stata inviata dall'encoder.\n\nSbagliare √® tanto pi√π facile quanto pi√π le codeword sono vicine. Se le uniche due codeword sono `1010` e `0101` ho scelto solo `2` messaggi su `16` stringhe disponibili (in particolare queste due sono ***ortogonali***), quindi sar√† pi√π difficile sbagliarsi. Viceversa, se ne uso `14` su `16` disponibili anche un solo `bit flip` cambier√† il significato della parola. N√© posso avere un $n$ stratosferico, perch√© significa spendere troppe risorse per ogni parola.\n\nBisogna quindi trovare un compromesso tra $n$ e $|\\calC^n|$, tramite il malauguratamente detto ***Transmission Rate*** (davvero eh Claude... un nome peggiore non potevi trovarlo).","x":2520,"y":-4834,"width":759,"height":913,"color":"4"},
		{"id":"886eeef68d17e333","type":"text","text":"# Correlazione, Rumore e Comunicazione\n\nPer come l'abbiamo definita, quella di Shannon √® un'entropia ***marginale*** (i.e. riguarda solo una sorgente, e.g. $X$). Poniamo di averne un'altra, e.g. $Y$. Se vogliamo caratterizzare un evento il cui outcome consta di un pezzo che discende da $X$ ed uno che deriva invece da $Y$, ci sono altre grandezze che dobbiamo introdurre.\n\n- ***Conditional Entropy*** - Se $X$ √® l'incertezza tra il lanciare un dado o una moneta e $Y$ un outcome da $1$ a $6$, √® chiaro che conoscere il risultato di $X$ influenza la distribuzione di probabilit√† su $Y$. Quindi la domanda della conditional entropy √®: se conosco $X$, qual √® la sorpresa residua su $Y$? Matematicamente, questa roba si scrive$$H(Y|X)=\\sum_{x\\in \\calX}\\P(x)\\,H(Y|X=x)=-\\sum_{x,y}\\P(x,y)\\log_2\\P(y|x)$$\n- ***Mutual Information*** - Ma quanto esattamente conoscere $X$ riduce la sorpresa su $Y$?$$I(X;Y)=H(Y)-H(Y|X)=H(X)-H(X|Y)=I(Y;X)$$\n\t- Nota che √® sempre $\\ge 0$, l'uguaglianza vale per variabili indipendenti.\n- ***Joint Entropy*** - Quantifica l'informazione media necessaria a descrivere nel complesso l'evento che consta delle due parti $X$ ed $Y$. L'informazione necessaria a descrivere $(X,Y)$ √® pari a quella per conoscere $X$ pi√π quella residua (nel senso di conditional entropy) per conoscere $Y$ (e viceversa, perch√© √® chiaramente simmetrica):$$H(X,Y)=H(X)+H(Y|X)= H(Y)+H(X|Y)=-\\sum_{x,y}\\P(x,y)\\log_2\\P(x,y)$$\n\nTutto questo mi serve a correlare due sorgenti in particolare: l'input e l'output di un ***Canale di Comunicazione***. Dato un input $x$, il ***rumore*** produrr√† in generale un output $y\\ne x$. Segue che il mio compito di ascoltatore sar√† di risalire a $x$ dato $y$.\n\nIn pratica, non possiamo a cuor leggero comprimere il messaggio da inviare fino al limite dato dall'entropia: ogni piccolo errore produrrebbe grandi incomprensioni. Per ottenere robustezza rispetto al rumore siamo costretti ad introdurre ***ridondanza*** rispetto alla compressione ottimale.","x":2520,"y":-3693,"width":759,"height":1030,"color":"4"},
		{"id":"20f0389aed3f57c6","type":"text","text":"# Transmission Rate\n\nCos'√® il Transmission Rate, e perch√© √® un disastro che si chiami cos√¨? (spoiler: perch√© ci ho messo tre ore a capire che cazzo di trasmissione fosse.)\n\nPariamo con il dire che, come al solito, l'esempio fatto con i `bit` pu√≤ essere fuorviante. Prima ho detto che sceglievo come codeword `1010` e `0101`, dando per scontato che ogni simbolo fosse binario. Potrei benissimo scegliere `ABBA` e `BACA` avendo come alfabeto `A B C`. Non cambier√† nulla per quello che segue. O quasi. Ci arriviamo.\n\nIl ***transmission rate*** non √® una qualche forma di throughput. O meglio, un po' lo √®, ma la definirei piuttosto un'***efficienza***. De che? Della comunicazione, ovviamente.$$R = {\\bit \\text{ informativi}\\over \\text{bit fisici trasmessi}}\\le1$$\nIn pratica, quanti ***bit informativi*** riesco a trasmettere per ogni bit fisico. Ora, nel caso in cui utilizziamo ***sequenze binarie*** di $n$ `bit` possiamo scrivere $R$ come$$R={1\\over n}\\log_2|\\calC^n|\\in[0,1]$$\nHai presente quella legge che ti impone di usare solo sequenze binarie? No, vero? Infatti non esiste. Questa scrittura √® infatti un caso particolare di$$R={1\\over n\\log_2|\\calX|}\\log_2|\\calC^n|\\in[0,1]$$\nOk, cambia solo la normalizzazione, ma √® importante. Poniamo $n=4$ e $\\calC^n=16$.\n\n- Se usiamo l'alfabeto binario, $\\log_2|\\calX|=1$. Questo significa che con $16$ parole binarie ho un'efficienza $R=1$, i.e. sto sfruttando tutte le potenzialit√† del mio alfabeto. Questo per√≤ significa anche che ogni pezzetto di informazione √® esattamente dove deve essere, il che la rende una situazione molto fragile e poco robusta rispetto al rumore;\n- Se usiamo l'alfabeto inglese, $\\log_2|\\calX|\\simeq4.7$, quindi con $16$ parole inglesi di lunghezza $4$ ho un'efficienza $R\\simeq0.21$. Non sto sfruttando appieno l'alfabeto, √® vero, ma di contro sar√† molto pi√π facile distinguere tra `xykz` e `abcd`.\n\nIn pratica, se $R$ √® alto significa che sto trasmettendo messaggi molto compressi (codeword vicine tra loro, rischio di fare pi√π errori), viceversa la trasmissione √® lenta rispetto al potenziale. <span style=\"color:rgb(236, 155, 14)\">eeee non sono convinto di questa interpretazione. forse parlano di rate perch√© la velocit√† √® fissata, ma mo √® l'una di notte, ba</span>","x":1513,"y":-4834,"width":759,"height":913,"color":"4"},
		{"id":"2b90ecf4bdbdb286","type":"text","text":"# Le nuove slides (6?) - Protocolli MAC\n\nogni channel della tv ha un diverso chip code","x":5971,"y":-2017,"width":759,"height":710},
		{"id":"bc4657e96dfd6f9a","type":"text","text":"# Modulazione dei Segnali\n\namplitude + phase shift molto usato\n\nconstellation diagrams ti permettono di encodare diverse combinazioni di bit con una certa combinazione ampiezza-fase. Il receiver riceve il punto rosso e inferisce qual √® il messaggio pi√π probabile. in pratica puoi definire un constellation diagram per definire il numero di simboli (o words) che trasmetti con il singolo \"quanto\" d'onda. Nota che simboli $\\ne$ bit. Se sono 4 ho `00 01 10 11`, i.e. ogni simbolo consta di DUE bit.\n\nTransmission rate = $\\log(DN)$ dove D \"numero di diagrammi\" (?) e N numero di punti per ogni diagramma. se aumento il numero di bit per simbolo ogni simbolo diventa pi√π informativo. distinguiamo quindi il bitrate dal symbol rate.\n\nerrori - devo ovviamente separare al meglio i punti per facilitare l'inferenza. Lo faccio aumentando l'ampiezza. la potenza del segnale √® data dall'ampiezza media. immagino che si codificano i least used symbols con punti poco potenti e viceversa. rivedi slide 86. fa discorso sul fatto che se faccio simboli super informativi √® facile sbagliare grossi pezzi di info, allora devo alzare la potenza per separare meglio i punti.\n\n√® chiaro che bitrate $\\propto$ potenza. Ma anche bandwidth? S√¨, ovviamente. questo giochino dei diagrammi di costellazione lo faccio a frequenza fissata, quindi usare pi√π frequenze significa usare pi√π diagrammi (la $D$ della formula di prima che non avevo capito cosa significasse). Tipo, WiFi ne usa 16 (la famosa banda 2.4GHz), ogni 2 MHz.\n\nla roba dell'allargamento in frequenza la presenta al contrario: l'idea √® che devi usare un botto di frequenze per realizzare Fourier. (ma bastano quelle contigue dello spettro??)\n\nChannel Capacity C = B log_2 (1+SNR), quindi se aumento la bandwidth aumento la channel capacity meglio di se aumento SNR\n\nSlide 95 - In teoria i due canali hanno la stessa capacit√†, in pratica per le interferenze le frequenze pi√π alte sono pi√π efficienti. anche perch√© \"less crowded\". molti protocolli (anche IoT) usano le frequenze basse, quindi c'√® un botto di collision risk.\n\nquesta roba √® vera anche per i cavi oltre che per il wifi, ma usano tutte le frequenze fisicamente disponibili?","x":4960,"y":-1915,"width":759,"height":900},
		{"id":"07d370c1b1fb30ea","type":"text","text":"# il resto delle slides\n\n\"spalmare il segnale lo rende pi√π simile al rumore e costituisce un layer di sicurezza\" (ma in che senso???)\n\nsicuramente hoppare secondo un pattern costituisce sicurezza, ma va settato bene! forse lo √® anche la chipping sequence (CodeDivisionMultiplexing). sono tipo superimposed codes?? la domanda √® sempre: come faccio ad essere certo che il receiver sia allineato?","x":4962,"y":-967,"width":759,"height":293},
		{"id":"19dbf5244a8bbdc1","type":"text","text":"# Abuso di Notazione\n\nNonostante \"encoder\" e \"decoder\" suggeriscano entit√† omologhe, $\\calC^n$ √® un ***codice*** (quindi un subset di tutte le possibili stringhe realizzabili con $n$ simboli, i.e. $\\calC^n \\sse \\calX^n$) mentre $\\varphi^n$ √® una ***funzione*** $\\varphi^n:\\calY^n\\to \\calC^n\\sse \\calX^n$.\n\nUn ***encoder*** in senso stretto dovrebbe essere una funzione $\\calE^n:\\calM\\to\\calC^n\\sse\\calX^n$ che mappa messaggi $m\\in\\calM$ in codeword $c\\in\\calC^n$.\n\nDa quello che leggo questo passaggio logico viene comunemente saltato per alleggerire la notazione, io non sono d'accordo. Chiamalo codice, no? Che ti costa?","x":3529,"y":-4529,"width":759,"height":303,"color":"4"},
		{"id":"efa33c7c0a47d3b4","type":"text","text":"# SPACING","x":3029,"y":-5069,"width":250,"height":235,"color":"5"},
		{"id":"183cc241a018e501","type":"text","text":"# Alfabeti, Simboli, Linguaggi, Furfanti, Licantropi, ...\n\nBoh io ho trovato sta roba un po' confusionaria, quindi facciamo ordine.\n\nNei DMC siamo partiti da un esempio semplice, in cui $\\calX=\\calY=\\{0,1\\}$. Questa scelta di fatto costituisce la quasi totalit√† delle applicazioni reali. Perch√©? Ma perch√© tutto l'HW del mondo √® basato sulla codifica binaria! Secondo te se intercetti un'onda EM che trasmette dati, quale codifica trovi? In base 26?\n\nEcco, visto che per√≤ in genere vorrei trasmettere informazioni pi√π complesse e l'HW parla in binario, sono costretto a codificare in binario. Sia $\\calX$ che $\\calY$ nel quotidiano parlano binario! Ma quindi la trattazione generica con $\\calX\\ne \\calY$ serve solo al risultato formale? ***No***. Il fatto che la ***quasi*** totalit√† delle codifiche √® binaria non significa che lo siano tutte.\n\nQuello che pu√≤ per√≤ trarre in inganno √® l'abitudine ad usare i `bit`, che come abbiamo capito vengono molto facilmente confusi con i $\\bit$. Facciamo quindi un esempio pi√π generale per capire che diavolo sta succedendo.\n\n$\\calX=\\{A, B, C\\}$, $\\calY=\\{\\a,\\b,\\g, \\d\\}$. Il canale potrebbe conoscere pi√π simboli di quelli che l'input gli comunica, o viceversa. In entrambi i casi esce una matrice $W$ non quadrata, tipo\n$$W(Y|X)=\\begin{bmatrix}\nP(\\a \\mid A) & P(\\b \\mid A) & P(\\g\\mid A) & P(\\d\\mid A) \\\\\nP(\\a \\mid B) & P(\\b \\mid B) & P(\\g\\mid B) & P(\\d\\mid B) \\\\\nP(\\a \\mid C) & P(\\b \\mid C) & P(\\g\\mid C) & P(\\d\\mid C) \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0.7 & 0.2 & 0.1 & 0.0 \\\\\n0.1 & 0.6 & 0.2 & 0.1 \\\\\n0.0 & 0.1 & 0.3 & 0.6 \\\\\n\\end{bmatrix}$$\nTutto questo ci sta dicendo che se viene inviato il simbolo $A$ √® pi√π probabile che in output venga ricevuto il simbolo $\\a$, e via dicendo. Visto che questa roba √® suscettibile agli errori non √® troppo conveniente inviare un simbolo alla volta. Scegliamo un codice $\\calC^2$, i.e. decidiamo che `AA` significa `A`, `BB` √® `B` e `CC` √® `C`. Questo ha due effetti:\n\n- Visto che $P(\\a\\mid A)=0.7$, diventa meno probabile che `AA` venga trasformato in due simboli di output che non sono $\\a$ $\\so$ ***ottengo robustezza rispetto all'errore***;\n- Al contempo per inviare un singolo simbolo $A$ ho dovuto inviarne due (`AA`) $\\so$ ***riduco l'efficienza della comunicazione***. Di quanto? Posso quantificarlo con il ***transmission rate***, che per√≤ malauguratamente √® definito assumendo che $n$ sia la lunghezza della codeword in `bit`. Ma lasciamolo spiegare meglio al riquadro sul Transmission Rate.","x":2520,"y":-5925,"width":759,"height":856,"color":"4"},
		{"id":"51edfc0fd55ad3f4","type":"text","text":"# Capacit√† di Canale\n\nUn ***Discrete Memoryless Channel*** (***DMC***) √® definito da una tripla $(\\calX, \\calY, W)$, dove $W$ √® la matrice stocastica del ***rumore***. Segue quindi che √® $W$ che caratterizza il canale. Possiamo definire un ***rate di trasmissione*** $R$ che ci d√† due indicazioni complementari:\n\n- Quanto velocemente (i.e. contenuto di informazione per simbolo) stiamo trasmettendo;\n- Quanto stiamo rischiando di non farci capire a destinazione (i.e. il rumore rovina tutto).\n\nOgni valore di $R$ rappresenta quindi un compromesso tra velocit√† e rischio di errori. Ci si potrebbe aspettare quindi che l'unico modo per far s√¨ che l'errore tenda a $0$ √® che $R\\to0$. \n\n... e invece no!\n\nDiamo qualche definizione. Chiamiamo  ","x":3529,"y":-3693,"width":759,"height":1030},
		{"id":"2df7743f9594ebe8","type":"text","text":"# `Bit` Fisico vs $\\bit$ Informativo\n\n***Questa √® una cosa molto importante.***\n\nLa Teoria dell'Informazione riconosce l'entit√† logica fondamentale $0/1$ come \"quanto\" di informazione, in quanto costituisce la risposta pi√π semplice che si possa dare (i.e. scelta binaria). Tale quanto di informazione viene chiamato ***$\\bit$ informativo***.\n\n***Il $\\bit$ NON √à il `bit`.*** \n\nIl `bit` inteso come entit√† che pu√≤ assumere solo valori `0` e `1` si riferisce a questi due oggetti in quanto ***simboli*** di un ***alfabeto binario***. Potrebbero tranquillamente essere `A` e `B`. Insomma, ***i simboli non quantificano niente***.\n\nIpotizziamo che io faccia una domanda ad una macchina che risponde sempre `s√¨`.\n\n- Per recapitarmi la risposta, la macchina deve mandare un `bit` fisico;\n- Quando la risposta arriva, la mia sorpresa √® esattamente $0$. So che rispondi sempre `s√¨`, questo `bit` che mi hai inviato non mi fornisce alcun $\\bit$ di informazione.\n\nOvviamente e malauguratamente ***questi due concetti a volte coincidono***. Se faccio la stessa domanda ad una macchina che risponde `s√¨` o `no` al $50\\%$, ogni `bit` che mi arriva in risposta coincider√† con esattamente un $\\bit$ di informazione.\n\nAltre volte √® evidente che c'√® qualcosa di strano. Se la macchina risponde `s√¨` il $75\\%$ delle volte e `no` il restante $25\\%$, ogni `bit` porta mediamente $0.81\\bit$ di informazione. Questa strana magia si chiama ***Entropia di Shannon***.\n\nMorale della favola: non tutti i `bit` che invii servono a comunicare qualcosa.","x":2520,"y":-2428,"width":759,"height":695,"color":"4"},
		{"id":"344ee0d6725a4b78","type":"text","text":"# Esempi e Metafore per Convincersi\n\nIl `bit` fisico ha un ***costo reale*** (e.g. tempo, energia, banda). √à ci√≤ che _trasporti_.\n\nIl $\\bit$ informativo √® un \"quanto siamo sorpresi\" da un simbolo. √à un'entit√† **astratta** che si misura in base 2. √à ci√≤ che *comunichi davvero*.\n\n- $1 \\bit$ = `1` evento binario con probabilit√† $0.5$.   \n- Il rapporto tra `bit` e $\\bit$ la quantifica il ***transmission rate***:$$R = {\\bit \\text{ informativi}\\over \\text{bit fisici trasmessi}}\\le1$$\n- Nota che un ***simbolo*** in generale pu√≤ portare pi√π di un $\\bit$ di informazione. Se ad esempio uso l'alfabeto inglese con pdf piatta, ricevere una `K` mi genera una sorpresa pari a $\\log_2(26)\\sim4.7$.\n### **Metafora cinematografica**\n\n- I bit **fisici** sono le **pellicole** che usi per registrare un film.\n- I bit **informativi** sono la **storia** che stai raccontando.\n    - Se filmi due ore di schermo nero, stai usando tantissima pellicola (bit fisici) ma non stai dicendo nulla (bit informativi ‚âà 0).\n    - Se filmi un thriller dove ogni minuto succede qualcosa di imprevedibile, ogni metro di pellicola √® carico di informazione.","x":3529,"y":-2428,"width":759,"height":695,"color":"4"}
	],
	"edges":[
		{"id":"6883460e8c227a3c","fromNode":"1e3fd2b7a4b6a7cc","fromSide":"top","toNode":"d700a52cca1cdc2a","toSide":"bottom","label":"Distributed Data Analysis"},
		{"id":"fcc82691ef115619","fromNode":"54d0a7ecb87b5c26","fromSide":"left","toNode":"1e3fd2b7a4b6a7cc","toSide":"right"},
		{"id":"b6bb6d947657dd64","fromNode":"1e3fd2b7a4b6a7cc","fromSide":"left","toNode":"2d43e95958d0e621","toSide":"right","label":"Communication"},
		{"id":"1d3252b9a19eabde","fromNode":"1e3fd2b7a4b6a7cc","fromSide":"bottom","toNode":"ff3b9035a56b4e9e","toSide":"top","label":"Embedded Devices"},
		{"id":"a4ca303b3a8531b2","fromNode":"ff3b9035a56b4e9e","fromSide":"right","toNode":"617bc5508509a069","toSide":"left"},
		{"id":"d2311340c023a06e","fromNode":"617bc5508509a069","fromSide":"top","toNode":"cc865f4cd6000ab4","toSide":"bottom"},
		{"id":"1fe790485df6f8ed","fromNode":"ff3b9035a56b4e9e","fromSide":"bottom","toNode":"a94d060ea349fc00","toSide":"top"},
		{"id":"32f7122c19c5f94f","fromNode":"03e26affba62b324","fromSide":"bottom","toNode":"4c794fe5a6070164","toSide":"top"},
		{"id":"b57a4afc37693e7a","fromNode":"a94d060ea349fc00","fromSide":"right","toNode":"c39cda918518baad","toSide":"left"},
		{"id":"dbe6aedd063a9a05","fromNode":"617bc5508509a069","fromSide":"right","toNode":"03e26affba62b324","toSide":"left"},
		{"id":"ebbbf8f78d15509c","fromNode":"03e26affba62b324","fromSide":"bottom","toNode":"c39cda918518baad","toSide":"top"},
		{"id":"8ed146d7664a9824","fromNode":"c39cda918518baad","fromSide":"top","toNode":"03e26affba62b324","toSide":"bottom"},
		{"id":"1288a997ee3a73a0","fromNode":"a94d060ea349fc00","fromSide":"bottom","toNode":"43767a936de8e8b1","toSide":"top"},
		{"id":"8f0fe63c00069c47","fromNode":"a94d060ea349fc00","fromSide":"left","toNode":"d11ebd7b1efd8ff7","toSide":"right"},
		{"id":"5d6efd6cc943b5ac","fromNode":"2d43e95958d0e621","fromSide":"top","toNode":"1f0970b33a4cb76f","toSide":"bottom"},
		{"id":"4470f02e3cd1c2e6","fromNode":"d700a52cca1cdc2a","fromSide":"top","toNode":"ea6c2db0218bf20e","toSide":"bottom"},
		{"id":"19b438e2e9d61208","fromNode":"43767a936de8e8b1","fromSide":"bottom","toNode":"9b1a993fbf97aa5e","toSide":"top"},
		{"id":"272f669fbc7ee525","fromNode":"1e3fd2b7a4b6a7cc","fromSide":"top","toNode":"2ce83f8e9814f3bc","toSide":"left"},
		{"id":"dcc5106e2f1b86cb","fromNode":"d700a52cca1cdc2a","fromSide":"right","toNode":"c8f665ef67bbc260","toSide":"left"},
		{"id":"45a05cd6c68dac81","fromNode":"ea6c2db0218bf20e","fromSide":"right","toNode":"1d4c9d197fab6065","toSide":"left"},
		{"id":"e03e1fee77478baf","fromNode":"54d0a7ecb87b5c26","fromSide":"top","toNode":"d51f893becdde7b8","toSide":"bottom"},
		{"id":"7b87ead8ae666d28","fromNode":"d51f893becdde7b8","fromSide":"left","toNode":"796fa6183e62d341","toSide":"right"},
		{"id":"725800191ecfe174","fromNode":"1e3fd2b7a4b6a7cc","fromSide":"top","toNode":"713d15910e78e93b","toSide":"bottom"},
		{"id":"d1f37c577b563bec","fromNode":"d51f893becdde7b8","fromSide":"top","toNode":"bc00b250b7b24ec0","toSide":"bottom","label":"Sorpresa"},
		{"id":"4dfd9f9014332940","fromNode":"bc00b250b7b24ec0","fromSide":"left","toNode":"953ba1b6df1d2cf5","toSide":"right"},
		{"id":"3dc0f2ed3e704ef9","fromNode":"5a1008ab6d4f93fb","fromSide":"bottom","toNode":"953ba1b6df1d2cf5","toSide":"top"},
		{"id":"651f2457eb20db33","fromNode":"d51f893becdde7b8","fromSide":"top","toNode":"953ba1b6df1d2cf5","toSide":"bottom","label":"Compressione"},
		{"id":"47991328da85437e","fromNode":"d51f893becdde7b8","fromSide":"top","toNode":"886eeef68d17e333","toSide":"bottom","label":"Comunicazione"},
		{"id":"28eb958601576b35","fromNode":"d51f893becdde7b8","fromSide":"right","toNode":"2df7743f9594ebe8","toSide":"left"},
		{"id":"1ab5a72fdd598058","fromNode":"bc00b250b7b24ec0","fromSide":"right","toNode":"886eeef68d17e333","toSide":"left"},
		{"id":"2552b2c3b89df497","fromNode":"886eeef68d17e333","fromSide":"top","toNode":"eadc00ddd47569d3","toSide":"bottom"},
		{"id":"ec92e44eac2419cf","fromNode":"2df7743f9594ebe8","fromSide":"right","toNode":"344ee0d6725a4b78","toSide":"left"},
		{"id":"c400ebb453f7eafd","fromNode":"eadc00ddd47569d3","fromSide":"left","toNode":"20f0389aed3f57c6","toSide":"right"},
		{"id":"6fe75ddac75b8201","fromNode":"eadc00ddd47569d3","fromSide":"right","toNode":"19dbf5244a8bbdc1","toSide":"left"},
		{"id":"2a6fffe38a308845","fromNode":"183cc241a018e501","fromSide":"left","toNode":"20f0389aed3f57c6","toSide":"top"},
		{"id":"804fa366dfada83f","fromNode":"eadc00ddd47569d3","fromSide":"top","toNode":"183cc241a018e501","toSide":"bottom"},
		{"id":"8b54eb2d2acd9697","fromNode":"eadc00ddd47569d3","fromSide":"right","toNode":"51edfc0fd55ad3f4","toSide":"left"},
		{"id":"7abb5a2c1542f216","fromNode":"886eeef68d17e333","fromSide":"right","toNode":"51edfc0fd55ad3f4","toSide":"left"}
	]
}