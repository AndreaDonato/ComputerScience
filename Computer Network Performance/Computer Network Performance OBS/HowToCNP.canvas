{
	"nodes":[
		{"id":"8bf923c2a7a9b2f5","type":"text","text":"# Richiami di Probabilità\n\nSe $\\Omega$ è lo spazio di tutti i possibili eventi ed $E\\subseteq \\Omega$ è un singolo evento, la probabilità di $E$ è in generale definita come il rapporto tra la misura di $E$ e la misura di $\\Omega$. Abbiamo quindi che$$P(E\\cup F) = P(E) + P(F) - P(E\\cap F) \\leq P(E) + P(F)$$L'uguaglianza vale solo se $P(E\\cap F)=0$, ovvero se gli eventi $E$ ed $F$ sono ***mutuamente esclusivi***. In modo analogo possiamo scriverlo con gli insiemi, ovvero $E\\cap F = \\emptyset$.\n\n- Dato un set di eventi $\\{E_i\\}$ tali che $E_i\\cap E_j = \\emptyset$, se $\\bigcup_iE_i = F$  allora $\\{E_i\\}$ è una ***partizione*** per $F$ (i.e. $F$ è totalmente ricoperto da eventi disgiunti $E_i$);\n- Eventi mutuamente esclusivi sono ***dipendenti***, in quanto per definizione il verificarsi di un evento influenza il verificarsi dell'altro (i.e. se si verifica $E$ allora $F$ non può verificarsi);\n\t- Viceversa, $E$ ed $F$ sono ***indipendenti*** ($E\\perp F$ ) ***sse*** $P(E\\cap F) = P(E)\\cdot P(F)$.\n\nDefiniamo la ***probabilità condizionata*** come$$P(E|F)={P(E\\cap F)\\over P(F)}$$che significa cercare un elemento $\\in E$ dentro l'insieme $F\\subseteq\\Omega$. In pratica, $F$ diventa il nuovo $\\Omega$ ed $E\\cap F$ diventa il nuovo $E$. Da questa definizione seguono diverse cosette utili.\n\n- ***Teorema della Probabilità Totale*** - Sia $\\{F_i\\}$ una partizione per $\\Omega$. $P(E) = \\sum_i P(E|F_i) \\cdot P(F_i)$.\n\t- Una partizione per $\\Omega$ è $F_1 = F$ ed $F_2= F^C$, dove $F^C=\\{x\\in\\Omega\\,|\\,x\\notin F\\}$ è il ***complemento*** di $F$.\n\t- Consente di trovare una probabilità come somma delle probabilità sui singoli elementi di una partizione di $\\Omega$.\n- ***Teorema di Bayes*** - Consente di invertire la definizione di probabilità condizionata. Essendo $\\cap$ un operatore simmetrico abbiamo che $$P(E\\cap F)=P(F\\cap E) =P(E|F)\\cdot P(F)=P(F|E)\\cdot P(E)$$Da questo segue che$$P(F|E) = {P(E|F)\\cdot P(F)\\over P(E)}={P(E|F)\\cdot P(F)\\over \\sum_i P(E|F_i) \\cdot P(F_i)}$$","x":880,"y":-1880,"width":840,"height":862,"color":"4"},
		{"id":"8310d0f0c52e20e5","type":"text","text":"# Somme e Prodotti di Variabili Casuali\n\nIndichiamo con $f_X(x)$ la *pdf* associata al processo $X$ scritta nella variabile $x$.\n\nSegue che $f_{XY}(x,y)$ è pdf associata alla ***joint probability***$$P_{XY}(x,y) = P(X=x,\\,\\, Y=y)=\\int_{\\Omega_X}\\int_{\\Omega_Y}f_{XY}(x,y)dxdy$$È possibile risalire alla $f_X$ tramite una ***marginalizzazione***, ovvero integrando su $y$$$f_X(x) = \\int_{\\Omega_Y}f_{XY}(x,y)dy$$e viceversa. Tutto questo serve a dimostrare che l'operatore ***valore atteso***$$E[X] := \\int_{\\Omega_X}xf_X(x)dx$$***commuta sulla somma di variabili, ma in generale non sul prodotto***, ovvero$$\\begin{array}\\\\ E[X+Y] = E[X]+E[Y]\\\\ \\\\ E[XY] \\neq E[X]\\,E[Y]\\leadsto E[XY] \\overset{X\\perp Y}{=} E[X]\\,E[Y]\\end{array}$$***Il valore atteso distribuisce sul prodotto se e solo se $X$ e $Y$ sono indipendenti***.\n\nPiù in generale, la pdf della somma di due variabili indipendenti è data dall'***integrale di convoluzione*** definito come$$f_{Z=X+Y}(z=x+y) = (f_X*f_Y)(z)\\int_{\\mathbb{R}}f_X(x)f_Y(z-x)dx$$mentre la formula per il prodotto esiste ma è inutilmente complicata e non la scrivo.","x":2780,"y":-1880,"width":700,"height":862,"color":"4"},
		{"id":"c3fb8ec5d4b06fa4","type":"text","text":"# Distribuzioni\n \n Seguono le distribuzioni che devi usare per calcolare la probabilità che\n \n- si verifichi uno tra due eventi mutuamente esclusivi, rispettivamente con probabilità $p$ (successo) e $q=1-p$ (insuccesso) - ***Distribuzione di Bernoulli***;\n- si verifichino $k$ successi su una sequenza di $n$ eventi di Bernoulli indipendenti - ***Distribuzione Binomiale*** avente espressione$$P(X=k)=\\binom{n}{k}p^kq^{n-k}$$\n\t- Quante prove $k$ devo fare prima di ottenere il primo successo? Sono date dalla ***Distribuzione Geometrica*** avente espressione$$P(X=k) = pq^{k-1}$$\n- si verifichino $k$ eventi (rari) in un lungo (formalmente $t\\to\\infty$) periodo di osservazione - ***Distribuzione di Poisson***, cioè$$P(X=k)={\\lambda^ke^{-\\lambda}\\over k!}$$\n\t- Quanto tempo devo aspettare tra due eventi di Poisson? Me lo dice la ***Distribuzione Esponenziale***$$pdf(x)=\\lambda e^{-\\lambda x}$$\n\n$\\lambda$ è in generale un rate di arrivo, mentre nel caso continuo bisogna sostituire la variabile discreta $k$ con una continua $x$. Questo non mi restituisce propriamente una probabilità di un evento, ma la ***probability density function*** (***pdf***), nel senso che su un dominio continuo il singolo valore ha una probabilità di verificarsi $=0$. La pdf ha quindi senso solo sotto integrale in un certo intervallo. La funzione integrale della pdf è detta ***cumulativa***.","x":1920,"y":-1880,"width":680,"height":862,"color":"4"},
		{"id":"7a7dccca7d03435d","type":"text","text":"# Ex 3.14\n\nA company pays a fine if the time to process a request exceeds 7 seconds. Processing a request consists of two tasks: (a) retrieving the file – which takes some time X that is Exponentially distributed with mean 5, and (b) parsing the file – which takes some time Y that is independent of X and is distributed Uniform(1, 3), with mean 2. Given that the mean time to process a request is clearly 7 seconds, the company views the fine as unfair, because it will have to pay the fine on half its requests. Is this right? What is the actual fraction of time that the fine will have to be paid, and how much does this differ from 1/2?","x":3780,"y":-2300,"width":758,"height":271,"color":"5"},
		{"id":"49d1ad7a808d2e41","type":"text","text":"# Soluzione 3.14\n\nAnzitutto sappiamo che\n\n- $X$ è distribuita esponenziale $\\lambda e^{-\\lambda x}$ con $E[x] = {1\\over\\lambda} = 5 \\Rightarrow \\lambda = {1\\over 5} \\Rightarrow f_X(x) = {1\\over5}e^{-{x\\over5}}$.\n- $Y$ è piatta con media $2$ ed altezza ${1\\over3-1} = {1\\over2}$.\n\nIn pratica sto cercando $P(X+Y > 7)$. Abbiamo due modi di procedere.\n\n- ***Marginalizzazione*** - $f_Y$ è uniforme e va fuori dall'integrale$$P(X+Y > 7) = \\int_1^3 P(X+Y>7\\,|\\,Y = y) \\,\\,f_Y(y)\\,\\, dy = {1\\over2}\\int_1^3P(X>7-y)\\,dy$$$P(X>7-y)$ è ottenibile dalla $f_X$ ricavata dai dati dal problema$$P(X>7-y) = \\int_{7-y}^\\infty {1\\over5}e^{-{x\\over5}} \\,dx= \\bigg[e^{-x/5}\\bigg]_\\infty^{7-y}=e^{y-7\\over5}$$Segue che$$P(X+Y > 7) = {1\\over2}\\int_1^3 e^{y-7\\over5} dy = {5\\over2}\\bigg[e^{y-7\\over5}\\bigg]_1^3={5\\over2}\\bigg[e^{-{4\\over5}}-e^{-{6\\over5}}\\bigg]\\sim 0.37$$\n- ***Convoluzione*** - Scriviamo l'integrale per trovare direttamente $$f_{Z=X+Y}(z) = \\int_{\\mathbb{R}}f_Y(y)f_X(z-y)dy={1\\over2}\\int_1^3{1\\over5}e^{-{z-y\\over5}}dy={1\\over2}\\bigg[e^{y-z\\over5}\\bigg]_1^3 = {1\\over2}\\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]$$A questo punto la soluzione è data da$$P(Z>7) = {1\\over2}\\int_7^\\infty \\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]dz = {5\\over2}\\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]_\\infty^7={5\\over2}\\bigg[e^{-{4\\over5}}-e^{-{6\\over5}}\\bigg]\\sim 0.37$$\n- ***NON*** ti salti in mente di dire \"eh ma tanto $f_Y$ è piatta con media 2, è sufficiente calcolare $P(X>5)$\", perché ***NON*** è assolutamente consistente. ***NON*** si fa.  ","x":3780,"y":-1880,"width":758,"height":862,"color":"4"},
		{"id":"b098d10344d941ab","type":"text","text":"# Ottimizzazione\n\n\nSe con coda infinita raddoppio $\\lambda$ quanto deve essere $\\mu$ per mantenere R costante? Sicuro deve essere almeno $2\\lambda$, ma $2\\mu$ è troppo (in questo caso R dimezza!). Quindi è compreso tra i due. Il che dipende dal ritardo in coda immagino, perché R=S+T.\n\nse metto due sistemi queue+cpu in parallelo con probabilità $1\\over2$. Le due CPU hanno $\\mu=1/3$. Che succede se sostituisco uno dei due server con uno con $\\mu$ doppia? Velocizzo tutto? Non è così facile. Se un processore è molto veloce lancia più velocemente processi nella coda dell'altro, rallentando il sistema. il bilanciamento è più importante di aumentare le specifiche a caso. NO!! se ti calcoli R resta identico!! Se ho un parallelo, R è determinato dal più lento.\n\n\np/1-p = mu1/mu2 = 2/3\\*3=2=p/1-p so 2p = 1-p so 3p = 1 cioè se metto delle probabilità proporzionali alle due mu velocizzo? Sì, cioè faccio load balancing. ma questo richiede un router intelligente. E allora? eh allora devo migliorare entrambi i server in parallelo, anche di molto poco.\n\nse ho un solo server con $\\mu = 4 j/s$ oppure 4 server in parallelo con $\\mu = 1 j/s$ ? ... dipende, da quanto sono lunghi i job, se sono tutti uguali, ecc. Il parallelismo è più fair, se ho poco lavoro è meglio il singolo server veloce. Non ce n'è uno migliore.","x":-10240,"y":891,"width":740,"height":569},
		{"id":"a73718e36cac73fd","type":"text","text":"# L4 (Probabilità)\n\nCose importanti sono solo le seguenti:\n\n- $E[XY] = E[X]E[Y]$ ***solo se gli eventi sono indipendenti***;\n- $E[X+Y] = E[X]+E[Y]$ ***sempre***.\n\nex 3.14","x":-7420,"y":-480,"width":760,"height":1294},
		{"id":"4aa37780d21cd695","type":"text","text":"# L6\n\nsta dicendo che la little law è una legge di conservazione di flusso\n\nChiamiamo $V_i^j$ il numero di visite che il processo $j$ fa al device $i$. Per definizione $$X_i = \\lim_t{C_i(t)\\over t} = \\lim {\\sum_{j\\in C(t)}V_i^j\\over t}{C(t)\\over C(t)}=E[V_i]\\cdot X$$dove $C(t)$ sono i job completati al tempo $t$ (forced flow law).\n\nesercizi fogli\n\ndefiniamo$$D_i=\\sum_{j=1}^{V_i}S_i^j$$ ovvero se il singolo job fa $V_i$ visite al device $i$, questo richiederà un tempo totale $D_i$ (j indicizza la visita...). Vorrei fare $$E[V_i]E[S_i] = E[D_i] = E\\bigg[\\sum_{j=1}^{V_i}S_i^j\\bigg]$$ma $V_i$ è a sua volta una random variable. Quindi per dimostrarlo $$= \\sum_nE\\bigg[\\sum_{j=1}^{V_i}S_i^j\\,\\,\\bigg|\\,\\,V_i=n\\bigg]\\times p(V_i=n)$$sostituisco l'upper bound  della somma con n, che è una costante e la porto fuori (la E resta perché ho sviluppato solo la sommatoria come variablie casuale e ho usato probabilità totale, poi la p(v=n) la porto fuori da E perché sticazzi), poi assumo che tutte le $S_i^j$ sono tutte DISTRIBUITE UGUALI (NON UGUALI E BASTA!! APPROFONDIRE), a quel punto esce un valore atteso che non dipende da j, porto fuori e viene per definizione\n\n$$E[S_i]\\times \\sum n\\,\\,p(V_i=n)$$ che è S$\\times$V. Quindi $$E[D_i]=E[V_i]E[S_i]$$che è la demand law. Se $B_i$ è il busytime del device $i$, $D_i=B_i\\times C$. Ora facciamo una reskin della utilization law$$\\rho_i = S_iX_i = E[S_i]E[V_i]\\times X = D_i X$$che si chiama bottleneck law\n\n\nMLP = MultiProgrammingLevel sarebbe il numero di job eseguibili in batch","x":-5691,"y":-480,"width":631,"height":1294},
		{"id":"2db738a55dcc2bec","type":"text","text":"# Teoria delle code L 1\n\nquanto ci mette questa coda?\n\nanalisi stocastica per prevedere le cose: \n\n- tempo - i delay di reti\n\t- quantità di dati (throughput coerente)\n\t- jitter (varianza di delay)\n\t- parallelismo? (ricollega throughput per servire più utenti alla volta)\n- spazio ed energia ignorati\n\nresponse time R intende tempo di processamento (coda inclusa). Se la coda è vuota questo coincide con il service time (S=$1\\over v$ dove v è la velocità della cpu). Il waiting time è $T_w$. $R = S+T_w$\n\nv non è il throughput X, perché se non arrivano processi con v non faccio nulla. $\\lambda$ è il rate di arrivo di pacchetti processati a velocità $u$. X è il minimo tra i due (no, perché è sempre medio!! posso parlarne solo in termini di valore atteso!!), $u$ è il massimo di X.\n\nanche se $\\lambda < \\mu$ posso vedere roba in coda, perché $\\lambda$ è sempre una media (quindi posso solo dire che la coda può riempirsi al più con un numero finito di elementi?). Per questo con $\\lambda = \\mu$ la coda si riempie. Indefinitamente? Ci sono N i processi in coda. N(t) = Arrival(t)-Departure(t) $\\geq$ $(\\lambda - \\mu)t$, la disuguaglianza è perché $\\mu t$ è il massimo numero di job uscenti, non quello effettivo. devo sostituire $\\mu$ col throughput, che sarebbe il departed effettivo (nel qual caso ho l'uguaglianza?). la disuguaglianza me la tengo perché è sempre vera. N è sempre una media.\n\n- $\\lambda - X \\geq 0$ ???\n\nstability condition: $\\lambda < \\mu$. Ma se sono uguali? ci sono fluttuazioni, perché queste sono solo medie, quindi torniamo a quello che dicevamo prima. Questo vale per un buffer infinito.\n\nE se è finito? se $\\lambda < \\mu$, X = $\\lambda (1-p_d)$, dove p_d è la probabilità di essere discarded.\n\nSe con coda infinita raddoppio $\\lambda$ quanto deve essere $\\mu$ per mantenere R costante? Sicuro deve essere almeno $2\\lambda$, ma $2\\mu$ è troppo (in questo caso R dimezza!). Quindi è compreso tra i due. Il che dipende dal ritardo in coda immagino, perché R=S+T.\n\nse metto due sistemi queue+cpu in parallelo con probabilità $1\\over2$. Le due CPU hanno $\\mu=1/3$. Che succede se sostituisco uno dei due server con uno con $\\mu$ doppia? Velocizzo tutto? Non è così facile. Se un processore è molto veloce lancia più velocemente processi nella coda dell'altro, rallentando il sistema. il bilanciamento è più importante di aumentare le specifiche a caso. NO!! se ti calcoli R resta identico!! Se ho un parallelo, R è determinato dal più lento.\n\n\np/1-p = mu1/mu2 = 2/3\\*3=2=p/1-p so 2p = 1-p so 3p = 1 cioè se metto delle probabilità proporzionali alle due mu velocizzo? Sì, cioè faccio load balancing. ma questo richiede un router intelligente. E allora? eh allora devo migliorare entrambi i server in parallelo, anche di molto poco.\n\nse ho un solo server con $\\mu = 4 j/s$ oppure 4 server in parallelo con $\\mu = 1 j/s$ ? ... dipende, da quanto sono lunghi i job, se sono tutti uguali, ecc. Il parallelismo è più fair, se ho poco lavoro è meglio il singolo server veloce. Non ce n'è uno migliore.","x":-10240,"y":-480,"width":740,"height":1294},
		{"id":"ae13a0ed0a553ebc","type":"text","text":"# L 2\n\nper un buffer infinito in cui $\\mu>\\lambda$, $R=\\frac{1}{\\mu - \\lambda}$.\n\nse ho $X=\\mu$ la coda si riempie indefinitamente. e se faccio una gerarchia in cui dopo il decimo posto in coda reindirizzo su un altro CPU è meglio di un parallelo? direi di no. oppure di fatto è un parallelo con probabilità proporzionali alla velocità...\n\nR è anche il service time per il numero medio di processi in coda + 1 (nella CPU)\n\nnell'esempio del parallelo asimmetrico, X per il server veloce resta uguale a quello lento. Dipende dallo split del router? sì ma non solo. i bottleneck sono dati dalle code. se c'è poco carico non vedo le code, quindi non vedo bottleneck.\n\ntutto questo era con un cavo che mandava la roba in loop. ora non c'è. in questo caso anche migliorare un solo server migliora R e X, perché non c'è \"feedback\".\n\nPoniamo di avere N server in parallelo, tutti con stessa $\\mu$. Due modelli:\n\n- una sola coda comune\n\t- non hai coda se metti $\\lambda$ server in parallelo. in questo caso hai R = S, ma non puoi fare R < S con nessun numero di server paralleli \n- ognuno con una coda\n\ndiverse scelte portano diversi benefici, ovviamente\n\n\nsegue ex 2.1 del libro (quale? perché non ce l'ho?)\n\n","x":-9300,"y":-480,"width":680,"height":1294},
		{"id":"602a250412f9f8db","type":"text","text":"# L3\n\njobs/sec è una sorta di misura a livello applicazione, posso usare un numero di cicli medi per job per la conversione (e.g. $5\\cdot 10^3$ cicli/job se ho CPU a $15\\cdot10^4$ cicli/sec avrò $\\mu \\sim 30 job/s$).\n\ne se la coda è finita (lunga M)? anche se $\\lambda<\\mu$ non posso dire che $X=\\lambda$, ma solo che $X<\\lambda$ (sempre a causa delle fluttuazioni, la coda si può riempire fino a scartare qualcosa):$$p_{full}=p(N=M+1) \\neq 0$$\n\"I don't have rum for other jobs\". quindi posso definire un ***drop rate*** come$$\\lambda_{drop} = \\lambda\\cdot p_{full}$$\nquindi chiaramente $X = \\lambda-\\lambda_{drop}$. Nota che non è importante che $\\lambda$ sia minore di $\\mu$. Se è maggiore, semplicemente, il drop rate vola alle stelle.\n\n\"I'd like to introduce UTILIZATION.\" Due casi:\n\n- un solo server - data dal ratio tra busy e observation time (i.e. osservo per 100 secondi, in che percentuale di questo tempo il server è busy?), si indica con $\\rho$. misura empirica $\\in [0,1]$ $\\sum{B_i}\\over\\tau$\n\t- altrimenti posso definirla come probabilità che il server sia busy (che per grandi numeri è equivalente, ma anche per definizione frequentista di probabilità)\n- m server - $\\rho = \\overline{N}_{\\text{busy servers}}/m \\in [0,1]$. perché è equivalente? è mezzo ovvio, nel senso che è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità (m è la normalizzazione).\n\t- formalmente, se applico questa definizione al caso con un solo server m = 1 e $N_{BS}$ è $1\\cdot p(server busy) + 0\\cdot p(server not busy)$. così per m=1 trovo il caso a un solo server. e viceversa? invece di osservare da 0 a T osservo da 0 a mT e metto i server in serie, poi applico la definizione ed esce la stessa cosa. (intuitivamente, il fatto che N medio in un dato istante fa una roba equivalente alla definizione sul tempo è una specie di trasformata di fourier...?)\n\nvorrei massimizzare l'utilization (senza raggiungere 1 forse, sembra un rischio). sia C jobs completati entro $\\tau$, moltiplico e divido ottenendo $\\rho=$$B\\over C$$C\\over\\tau$ dove $B\\over C$ è il time di esecuzione medio per job (anche detto service time..., perché B è CPU time). Dunque $$\\rho = S\\cdot X$$che prende il nome di ***utilization law***. Nota che vale per il singolo server, non per N server.$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$\nil secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$\ncioè $\\rho = SX$, che è quello che ho trovato prima, ma stavolta con la probabilità invece che con osservazioni empiriche. Yeee.\n\n","x":-8360,"y":-480,"width":760,"height":1294},
		{"id":"a2cb1b62ac8e14a7","type":"text","text":"# L5\n\nmettiamo in relazione popolazione $E[N]$ del sistema, X e tempo di permanenza all'interno del sistema $E[T]$ (Little Law):$$E[T]={E[N]\\over X}$$questo indipendentemente da cosa sia il sistema: è una black box. una condizione è che il sistema sia ergodico.\n\nper il semplice sistema con una coda/processore l'unica condizione è quella di stabilità (non serve coda FCFS)\n\nappunti scritti!\n\nse c'è rejection interna $X = \\lambda - \\lambda_{drop}$\n\nclosed system - $E[N] = X(E[R]+E[Z])$ \n\nsi ritrova utilization $\\rho_i = S_iX_i$ che è sempre $\\leq 1$!!","x":-6500,"y":-480,"width":660,"height":1294},
		{"id":"3ef4170333348e84","type":"text","text":"# Rapido Riassunto\n\n***forced flow law***$$$$","x":-4880,"y":-112,"width":461,"height":559},
		{"id":"b97f6c6c3af15295","type":"text","text":"# Definizione del Problema (i.e. voglio $X$ ed $R$)\n\nLe grandezze che sono interessato a mettere in relazione sono\n\n- il ***throughput*** $X$, i.e. quanti job processa il sistema complessivo in un periodo di osservazione unitario;\n- il ***response time*** $R$ (o $T$), i.e. quanto ci mette il sistema complessivo a processare il job\n\nSe $N$ è il numero di job nel sistema, la legge più generale possibile che lega queste grandezze è la ***Little's Law***. È praticamente una legge di conservazione, quindi per applicarla devo definire un volume chiuso che racchiude il sistema di cui voglio studiare le grandezze. Segue che $X$ sarà lo stesso sia all'ingresso che all'uscita della box.\n\nDistinguiamo due casi:\n\n- il sistema dentro la box è ***aperto*** - $N$ è un valore atteso.$$\\bra N\\ket=X\\bra R\\ket$$\n- Il sistema dentro la box è ***chiuso*** - $N$ è una costante, il ***think time*** $Z$ è il response time degli utenti (i.e. posso vedere il lato client come un server avente response time $Z$).$$N=X\\bigg(\\bra R\\ket+\\bra Z\\ket\\bigg)$$\n\t- Nota che dentro una box in cui applico la Little's Law per sistemi chiusi posso ancora applicare la Little's Law. Una cosa che mi sembra interessante è che se isolo solo il client e solo il server trovo$$X={N_{client}\\over Z}={N_{server}\\over R}\\so {N_{client}\\over N_{server}}={\n\t  Z\\over R}$$Boh così, era per dire.","x":-280,"y":4320,"width":880,"height":700,"color":"4"},
		{"id":"7bb4ea5e8877ccbe","type":"text","text":"# Little Law\n\n","x":1500,"y":2193,"width":740,"height":722},
		{"id":"17b80d20631e90fd","type":"text","text":"# L5\n\nmettiamo in relazione popolazione $E[N]$ del sistema, X e tempo di permanenza all'interno del sistema $E[T]$ (Little Law):$$E[T]={E[N]\\over X}$$questo indipendentemente da cosa sia il sistema: è una black box. una condizione è che il sistema sia ergodico.\n\nper il semplice sistema con una coda/processore l'unica condizione è quella di stabilità (non serve coda FCFS)\n\nappunti scritti!\n\nse c'è rejection interna $X = \\lambda - \\lambda_{drop}$\n\nclosed system - $N = X(E[R]+E[Z])$ (N non è un valore atteso, il sistema è chiuso quindi è noto)\n\nsi ritrova utilization $\\rho_i = S_iX_i$ che è sempre $\\leq 1$!!","x":2590,"y":1460,"width":660,"height":1294},
		{"id":"6bf4661a96526f35","type":"text","text":"$$\\newcommand{\\I}{\\mathbb{I}}\\I$$oind\n$$\\A\\B\\C\\D\\E\\F\\G\\H\\I\\J\\K$$","x":3300,"y":1691,"width":250,"height":160},
		{"id":"5158a83889f13dea","type":"text","text":"# Stochastic Processes\n\nCercare l'average population è una roba complessa. Stochastic process is a sequence of random variables, which represent the evolution of the system in time.\n\nContinuous Time Stochastic Processes (CTSP) sono riconducibili ai Discrete TSP.\n\nState space is $\\mathbb{I}$, $X_k$ random variables definiscono lo state of the process at time k.\nConsideriamo una sola coda. Lo stato del sistema è la popolazione della coda. Lo schematizzo come un automa/catena di Markov lineare. Come la analizzo?\n\nDiscrete Markov Chain - perché sia una CdM deve valere che se$$1\\forall\\,n\\in\\N\\quad\\forall\\,i.j\\quad\\forall i_k\\in\\I$$allora si ha che$$P\\{X_{n+1}=j\\,|\\,X_n=i, X_{n-1}=i_{n-1}, ...\\}=P\\{X_{n+1}=j\\,|\\,X_n=i\\}=P_{ij}$$ovvero la proprietà di ***assenza di memoria*** (***history independence***) e di ***time homogeneity***. Nota che non è detto che sia rispettata.\n\nSe $|\\I|=M<\\infty$, definisco una transition probability matrix $P\\in[0,1]^{M\\times M}$ con elementi $p_{ij}$ aventi la proprietà $\\sum_jp_{ij}=1$ (le righe sommano a 1).\n\nEsempio: repairing facility problem. una macchina o funziona o è rotta (i.e. $\\I=\\{broken, working\\}$)\n\n***Umbrella problem*** - voglio sapere p che il prof si bagni. ha due ombrelli ","x":3620,"y":1460,"width":700,"height":1294},
		{"id":"5a784396cbb6c294","type":"text","text":"# Computer Network Performance\n\nIn una rete sono presenti dei ***job*** (i.e. processi) che devono essere processati da uno o più ***server*** (i.e. nodi schematizzabili come ***CPU + Queue***).\n\nDiversi parametri (e.g. velocità $\\mu_i$ della $i$-esima CPU, rate $\\lambda$ di arrivo dei processi) definiscono le grandezze utilizzate per valutare le ***performance*** del sistema complessivo (e.g. ***throughput*** $X$, ***tempo di processamento*** $R$) o di porzioni del sistema stesso.\n\nTutte le grandezze sono intese come ***valori medi soggetti a fluttuazioni***. Ogni variabile va in generale trattata come aleatoria, con opportuna distribuzione a seconda del caso.","x":510,"y":1735,"width":740,"height":303,"color":"6"},
		{"id":"72a1764afabd7979","type":"text","text":"# Introduzione, Glossario e Stabilità\n\nSupponiamo di avere una CPU che processa ad una velocità $\\mu$ (espressa in $job/s$) dei processi che arrivano in input ad un rate $\\lambda$, ed una queue di attesa per i job non ancora processati. Diamo alcune definizioni:\n\n- Se la coda è vuota, il ***response time*** $R$ (i.e. il tempo che intercorre tra l'ingresso del processo nel sistema e la sua uscita) sarà uguale al tempo di processamento del singolo job, detto ***service time*** e pari a $S=1/\\mu$;\n- Se la coda non è vuota, $R$ del sistema sarà in generale maggiore di $S$. Di quanto? Del ***waiting time*** in coda $T_w$. Quindi $R=S+T_w$;\n\t- Posso anche scriverlo come $S\\cdot N$, con $N$ numero medio di processi in coda.\n- Il ***throughput*** $X$ è il numero di job completati dal sistema in un'unità di tempo.\n\t- ***NON*** coincide con $\\mu$: se non arrivano processi, $X=0$ ma la CPU continua ad avere il parametro $\\mu$ che ne definisce la velocità;\n\t\t- Tuttavia, $\\mu$ è un ***limite superiore*** per $X$.\n\t- ***NON*** è il minimo tra $\\lambda$ e $\\mu$, perché $\\lambda$ ***è una variabile aleatoria*** (di cui in genere si fornisce il valore atteso).\n\t\t- Segue che è possibile vedere la coda riempirsi anche se $\\lambda<\\mu$.\n\nDetto questo, possiamo ricavare la popolazione in coda $$N(t) = \\text{Arrival}(t) - \\text{Departure}(t)\\geq\\lambda  t - \\mu t = (\\lambda-\\mu)t$$ dove la maggiorazione è dovuta al fatto che $\\mu t$ è il $\\sup$ del throughput. Segue che per evitare di far crescere all'infinito la popolazione della coda (o di scartare job, se il buffer è finito) si deve avere $\\lambda-\\mu<0$ (***condizione di stabilità***).\n\nAssumiamo sempre di lavorare con sistemi stabili.","x":510,"y":2193,"width":740,"height":722,"color":"4"},
		{"id":"a7f39a318bb503ec","type":"file","file":"2.1.png","x":1430,"y":1278,"width":400,"height":224},
		{"id":"47c5456b7006f8ff","type":"text","text":"# L3\n\njobs/sec è una sorta di misura a livello applicazione, posso usare un numero di cicli medi per job per la conversione (e.g. $5\\cdot 10^3$ cicli/job se ho CPU a $15\\cdot10^4$ cicli/sec avrò $\\mu \\sim 30 job/s$).\n\ne se la coda è finita (lunga M)? anche se $\\lambda<\\mu$ non posso dire che $X=\\lambda$, ma solo che $X<\\lambda$ (sempre a causa delle fluttuazioni, la coda si può riempire fino a scartare qualcosa):$$p_{full}=p(N=M+1) \\neq 0$$\n\"I don't have rum for other jobs\". quindi posso definire un ***drop rate*** come$$\\lambda_{drop} = \\lambda\\cdot p_{full}$$\nquindi chiaramente $X = \\lambda-\\lambda_{drop}$. Nota che non è importante che $\\lambda$ sia minore di $\\mu$. Se è maggiore, semplicemente, il drop rate vola alle stelle.\n\n\"I'd like to introduce UTILIZATION.\" Due casi:\n\n- un solo server - data dal ratio tra busy e observation time (i.e. osservo per 100 secondi, in che percentuale di questo tempo il server è busy?), si indica con $\\rho$. misura empirica $\\in [0,1]$ $\\sum{B_i}\\over\\tau$\n\t- altrimenti posso definirla come probabilità che il server sia busy (che per grandi numeri è equivalente, ma anche per definizione frequentista di probabilità)\n- m server - $\\rho = \\overline{N}_{\\text{busy servers}}/m \\in [0,1]$. perché è equivalente? è mezzo ovvio, nel senso che è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità (m è la normalizzazione).\n\t- formalmente, se applico questa definizione al caso con un solo server m = 1 e $N_{BS}$ è $1\\cdot p(server busy) + 0\\cdot p(server not busy)$. così per m=1 trovo il caso a un solo server. e viceversa? invece di osservare da 0 a T osservo da 0 a mT e metto i server in serie, poi applico la definizione ed esce la stessa cosa. (intuitivamente, il fatto che N medio in un dato istante fa una roba equivalente alla definizione sul tempo è una specie di trasformata di fourier...?)\n\nvorrei massimizzare l'utilization (senza raggiungere 1 forse, sembra un rischio). sia C jobs completati entro $\\tau$, moltiplico e divido ottenendo $\\rho=$$B\\over C$$C\\over\\tau$ dove $B\\over C$ è il time di esecuzione medio per job (anche detto service time..., perché B è CPU time). Dunque $$\\rho = S\\cdot X$$che prende il nome di ***utilization law***. Nota che vale per il singolo server, non per N server.$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$\nil secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$\ncioè $\\rho = SX$, che è quello che ho trovato prima, ma stavolta con la probabilità invece che con osservazioni empiriche. Yeee.\n\n","x":-1410,"y":1991,"width":760,"height":1126},
		{"id":"6c4e1b71f91fca83","type":"text","text":"# Utilization Law\n\nSe osservo per un periodo $\\tau$, in che percentuale di questo tempo la CPU è in uso?\n\n- Se ho un solo server, questa grandezza sarà banalmente il rapporto tra (la somma dei vari) ***busy time*** e ***observation time***, dunque $\\rho = {\\sum_iB_i\\over\\tau}\\in[0,1]$ o, in modo analogo, la probabilità che il server sia busy (secondo la definizione frequentista);\n- Se ho $m$ server usiamo effettivamente la statistica e la definiamo come$$\\rho=  {\\overline{N}_{\\text{busy servers}}\\over m} \\in [0,1]$$\n\t- Intuitivamente, è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità frequentista come nel caso precedente ($m$ è la normalizzazione);\n\t- Formalmente, è facile applicare questa definizione al caso $m=1$ è vedere che $\\overline{N}_{BS} = 1\\cdot p(\\text{Server 1 is busy})+0\\cdot p(\\text{Server 1 is not busy})$, cioè ritrovo la definizione del singolo server. Viceversa, allungo il periodo di osservazione da $\\tau$ ad $m\\tau$ e metto i server in serie e...? Viene lo stesso? DA DEFINIRE\n\nVisto che le due definizioni sono equivalenti, usiamo la prima. Introduciamo il numero $C$ di ***job completati entro*** $\\tau$ e riscriviamo$$\\rho={B\\over C}{C\\over \\tau}$$A questo punto $B\\over C$ è il tempo di esecuzione medio per processo, che per definizione è il service time $S$, e $C\\over\\tau$ è per definizione il throughput $X$. Otteniamo la ***utilization law***$$\\rho = S\\cdot X$$Vale solo per il singolo server, non per il parallelo???????????????\n\nSi può anche ricavare dalla probabilità totale applicata al throughput$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$il secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$","x":-490,"y":2107,"width":740,"height":895,"color":"3"},
		{"id":"1c9cfb53f2ea6a27","type":"text","text":"# Derivare la Little's Law\n","x":1440,"y":4625,"width":386,"height":85,"color":"6"},
		{"id":"e35038af26a742e9","type":"text","text":"# Sistema Chiuso\n\nPer un sistema chiuso facciamo lo stesso ragionamento del sistema aperto, l'unica differenza è che la popolazione è nota: $a=Nt$.\n\nDefinisco una box in cui includo sia server che client, ma \"taglio fuori\" un pezzetto di collegamento, in modo da ricondurmi ad un sistema aperto. Posso applicare la Little's Law per il sistema aperto (in cui però conosco $N$)$$N=X\\bra T\\ket$$dove però stavolta $T$ è la somma dei response time del server ($R$) e del client ($Z$, anche detto ***think time***). Sostituendo abbiamo$$N=X\\bigg(\\bra R\\ket + \\bra Z\\ket\\bigg)$$","x":1283,"y":5349,"width":700,"height":387,"color":"4"},
		{"id":"dc5fcb165c998d28","type":"text","text":"# Glossario\n\n- ***Queuing Delay*** ($T_w$) - Quanto tempo un processo in coda attende di essere processato dal server;\n- ***Service Time*** ($S_i$) - Quanto tempo ci mette il server $i$ a processare un job. È l'inverso della sua velocità: $$S_i={1\\over\\mu_i}$$\n\t- Nota che questo non include il queuing delay.\n- ***Response Time*** ($R$, a volte $T$) - La somma di Queuing Delay e Service Time, ovvero il tempo medio che intercorre tra l'ingresso in coda di un job ed il suo completamento;\n\t- Il ***Think Time*** ($Z$) è un response time degli utenti.\n- ***Completions*** ($C$) - ***Dato un tempo di osservazione***, il sistema complessivo ha completato $C$ jobs;\n\t- Posso definirlo per il singolo server all'interno del sistema complessivo. ***Dato un tempo di osservazione***, $C_i$ sono le completions del server $i$;\n\t- Se divido per il tempo di osservazione diventa il ***throughput*** $X$.\n- ***Visite*** ($V_i$) - Se esiste un percorso che collega l'output del server $i$ al suo stesso input, un singolo job potrebbe essere processato più di una volta. Il numero (atteso) di volte che ciò accade è detto numero di visite;\n\t- Nota che potrebbe essere minore di $1$ (e.g. se ho un singolo job diviso al $50\\%$ tra due CPU in parallelo e nessun loop, il numero atteso di visite per ognuna sarà $1\\over2$) o maggiore (e.g. se osservo $C$ completion del sistema e $C_i>C$ completion del server $i$, significa che ogni job completato dal sistema è stato completato più volte dal server $i$, ovvero $V_i={C_i\\over C}$);\n\t\t- Nota anche che nel $90\\%$ dei casi mi riferirò alle visite come dovute ai loop, e quindi $V_i>1$.\n\t- Dalla definizione di throughput e di visite discende in modo molto naturale la ***forced flow law***$$X_i=\\bra V_i\\ket X$$Visto che il throughput è praticamente la derivata in $dt$ delle completions, questa è una reskin della definizione$$V_i={C_i\\over C}\\so C_i=V_iC$$La forced flow sta sostanzialmente dicendo che se per completare un job servono più passaggi (visite) dal server $i$, allora il suo throughput sarà maggiore di quello complessivo del sistema. Di quanto? Del numero di visite.\n- ***Demand*** ($D_i$) - Quanto tempo un singolo job impegna il server $i$ durante una sua singola esecuzione nel sistema complessivo;$$\\bra D_i\\ket=\\bra V_i\\ket\\bra S_i\\ket$$\n- ***Busy Time*** ($B_i$) - ***Dato un tempo di osservazione***, mentre il sistema complessivo completa $C$ jobs il server $i$ sarà impegnato per un tempo pari alla demand per il singolo job per il numero di completions$$B_i = D_iC$$Analogamente, posso vedere questa grandezza come il service time per il numero di job completati dal server $i$$$B_i=S_iC_i$$Queste due definizioni sono equivalenti:$$D_i=V_iS_i \\wedge C={C_i\\over V_i}\\so D_iC=S_iC_i$$\n- ***Utilization*** ($\\r_i$) - Percentuale di tempo in cui, mediamente, il server $i$ è occupato. È una probabilità che discende da una statistica su un lungo periodo di tempo (i.e. se osservo per 10 secondi il server è occupato per 2, se osservo per 100 misuro 22, per 1000 misuro 221... al limite la legge dei grandi numeri ci garantisce che raggiungeremo il \"valor vero\"):$$\\r_i=\\lim_{\\t\\to\\infty}{B_i(\\t)\\over\\t}$$\n\t- Dalla prima definizione di $B_i$ trovo la ***bottleneck law***$$\\r_i=\\lim_{\\t\\to\\infty}{C(\\t)\\over\\t}D_i=D_iX$$\n\t- Dalla seconda trovo la ***utilization law***$$\\r_i=\\lim_{\\t\\to\\infty}{C_i(\\t)\\over\\t}S_i=S_iX_i$$","x":-1640,"y":4783,"width":1020,"height":1520,"color":"4"},
		{"id":"bc97d3f465866538","type":"text","text":"# Sistema Aperto\n\nDato un sistema aperto ed un intervallo di osservazione da $0$ a $t$, abbiamo\n\n- i job $C(t)$ completati entro $t$, che occupano la CPU per un tempo$$\\sum_{i\\in C(t)}T_i$$\n- i job $A(t)$ arrivati entro $t$, che includono sia i job completati che quelli non ancora completati. Nel complesso, hanno occupato e/o occuperanno in futuro (per \"futuro\" si intende oltre $t$) la CPU per un tempo$$\\sum_{i\\in A(t)}T_i$$\n- sempre i job $\\in A(t)$, ma stavolta consideriamo solo il tempo fino a $t$$$a = \\int_0^tN(t')dt'$$\n\nPer come sono stati definiti, abbiamo che$$\\sum_{i\\in C(t)}T_i\\leq a \\leq \\sum_{i\\in A(t)}T_i$$\nMoltiplico e divido per $C(t)\\over C(t)$ a sinistra e per $A(t)\\over A(t)$ a destra, poi applico a tutti i membri $$\\lim_{t\\to\\infty} (*) {1\\over t}$$$$\\so \\lim_{t\\to\\infty} {C(t)\\over t}{\\sum_{i\\in C(t)}T_i\\over C(t)}\\leq \\lim_{t\\to\\infty}{a\\over t} \\leq \\lim_{t\\to\\infty} {A(t)\\over t}{\\sum_{i\\in A(t)}T_i\\over A(t)}$$\nA questo punto\n\n- $\\lim_{t\\to\\infty} {C(t)\\over t}$ è il throughput $X$;\n- $\\lim_{t\\to\\infty} {\\sum_{i\\in C(t)}T_i\\over C(t)}$ è il response time dei processi completati $\\bra T \\ket_C$;\n- $\\lim_{t\\to\\infty}{a\\over t}$ è il valore atteso del numero di job nel sistema $\\bra N\\ket$;\n- $\\lim_{t\\to\\infty} {A(t)\\over t}$ è l'arrival rate $\\l$;\n- $\\lim_{t\\to\\infty} {\\sum_{i\\in A(t)}T_i\\over A(t)}$ è il response time dei processi arrivati $\\bra T \\ket_A$.\n\nSotto l'ipotesi di sistema ergodico (in questo caso $\\l < \\mu$) abbiamo che$$\\bra T \\ket_C=\\bra T \\ket_A=\\bra R \\ket$$$$\\bra\\l\\ket = \\bra X\\ket$$\nQuindi per il sempreverde teorema dei carabinieri$$X\\bra R\\ket\\leq\\bra N\\ket \\leq X\\bra R\\ket \\quad\\so\\quad\\bra N\\ket = X\\bra R\\ket$$","x":2666,"y":4119,"width":880,"height":1097,"color":"4"},
		{"id":"38224f6da2a4cf46","type":"file","file":"LittleLawUHD.jpg","x":820,"y":5349,"width":407,"height":387},
		{"id":"2941e90ce6c0fd2e","type":"text","text":"# Strumenti utili a trovare $X$ ed $R$\n\nSe ci sono dei loop, è possibile che lo stesso processo visiti più di una volta lo stesso server. In questo caso parliamo di ***numero atteso di visite*** $V$. Se il loop è semplicemente una probabilità $p$ di passare dall'output all'input, allora $V={1\\over p}$. Posso esprimere il numero di visite di un singolo processo al server $i$ come rapporto tra i processi completati dal server $i$ e i processi completati dal sistema complessivo:$$V_i={C_i\\over C}$$\nIl ***service time*** è l'inverso della velocità della CPU.$$S={1\\over\\mu}$$\nSe il processo ha $V=1$ è banalmente il tempo che ci mette quel processo ad essere processato una volta (quindi escludendo la coda), altrimenti si estende immediatamente dicendo che la ***demand*** di un server è il service time per il numero di visite:$$\\bra D_i\\ket=\\bra V_i\\ket\\bra S_i\\ket$$\nSe osservo $C$ job completati ognuno dei quali richiede mediamente un tempo di esecuzione pari alla demand $D$, ricaviamo il ***busy time*** del server come$$B_i=D_i\\cdot C=C_i\\,S_i$$\n- $C$ è il numero di job completati dall'intero sistema, ***NON*** quello del singolo server $C_i$. Nella prima uguaglianza, l'informazione del numero di visite al server $i$ è inglobata in $D_i$.\n\n$B_i$ sta in qualche modo provando a dirci quanto tempo è occupato il server $i$, ma dipende dal tempo di osservazione. Per avere una grandezza normalizzata introduciamo la ***utilization*** $\\r\\in[0,1]$, che è il busy time diviso il tempo di osservazione$$\\r_i={B_i\\over\\t}={C_i\\over\\t}S_i = S_iX_i$$\nQuesta roba si chiama ***utilization law***. Se invece sostituisco l'altra definizione di $B_i$ ottengo$$\\r_i={B_i\\over\\t}={C\\over\\t}D_i = D_iX$$che in Cina chiamano ***bottleneck law***. In pratica tutte queste leggi sono definizioni di cose, ma tornano comodo perché alcune grandezze sono più facili da misurare rispetto ad altre.\n","x":-280,"y":5087,"width":880,"height":914,"color":"4"},
		{"id":"1be6a87a62a26638","type":"text","text":"# Bounds su $X$ ed $R$ (i.e. Come ottimizzare il sistema?)\n\nChe ci faccio con tutta questa roba? La uso per capire quali sono gli ***upper bound sul throughput*** e i ***lower bound sul response time*** (e con questo intendo quelli complessivi del sistema).\n\nEssendo normalizzata, $\\r\\leq1$. Dalla ***bottleneck law*** ricavo che $$D_iX\\leq1\\so X\\leq{1\\over D_i}\\so X\\leq{1\\over D_{max}}\\qquad\\bigg[\\text{Sarebbe }X\\leq{1\\over D_{max}}\\leq{1\\over D_i}\\bigg]$$Il server che all'interno del sistema complessivo ha la massima demand è il ***bottleneck*** per $X$;\n\n- Segue dalla ***Little's Law*** che$$N=X(R+Z)\\so R={N\\over X}-Z \\geq {N\\over X_{max}}-Z = ND_{max}-Z$$\n\nÈ chiaro che se $N=1$ avrò sempre un response time minore rispetto al caso $N>1$. Quindi$$R(N)\\geq R(1)$$Ma il tempo di processamento di un singolo job $R(1)$ si può ottenere facilmente come somma di tutte le demand dei singoli server $i$ (posso farlo perché con un solo processo non c'è ritardo in coda). Quindi$$R\\geq\\sum_iD_i=D_{tot}$$\n\n- Segue dalla ***Little's Law*** che$$X={N\\over(R+Z)}\\leq{N\\over R_{min}+Z} = {N\\over D_{tot}+Z}$$\n\nIn definitiva abbiamo che$$X\\leq\\min\\bigg\\{{N\\over D_{tot}+Z}, {1\\over D_{max}}\\bigg\\}$$$$R\\geq\\max\\bigg\\{D_{tot},\\, {ND_{max}-Z}\\bigg\\}$$\nIn entrambi i casi, l'intersezione tra le due curve è data da$$N^*={D_{tot}+Z\\over D_{max}}={D_{max}+\\sum_{i\\neq max} D_iZ\\over D_{max}}= 1 + {\\sum_{i\\neq max} D_i+Z\\over D_{max}}$$\nL'ultima è giusto per sapere che sicuramente l'incrocio avviene dopo $1$. $N^*$ separa infatti i regimi di\n- ***low population*** ($N<N^*$), in cui per migliorare le performance è sufficiente ridurre $D_{tot}$;\n- ***high population*** ($N<N^*$), in cui per migliorare le performance bisogna ridurre $D_{max}$.","x":-280,"y":6100,"width":880,"height":1046,"color":"4"}
	],
	"edges":[
		{"id":"61f1212c35f4bce8","fromNode":"8bf923c2a7a9b2f5","fromSide":"right","toNode":"c3fb8ec5d4b06fa4","toSide":"left"},
		{"id":"f0fdd0999c6700cd","fromNode":"c3fb8ec5d4b06fa4","fromSide":"right","toNode":"8310d0f0c52e20e5","toSide":"left"},
		{"id":"8208b26e47519e8b","fromNode":"7a7dccca7d03435d","fromSide":"bottom","toNode":"49d1ad7a808d2e41","toSide":"top"},
		{"id":"e00afe36636e34f0","fromNode":"5a784396cbb6c294","fromSide":"bottom","toNode":"72a1764afabd7979","toSide":"top"},
		{"id":"0bf74c88886abf4f","fromNode":"72a1764afabd7979","fromSide":"left","toNode":"6c4e1b71f91fca83","toSide":"right"},
		{"id":"2cfd6e1fa7e7935e","fromNode":"72a1764afabd7979","fromSide":"right","toNode":"7bb4ea5e8877ccbe","toSide":"left"},
		{"id":"cd4586adb74413a6","fromNode":"4aa37780d21cd695","fromSide":"right","toNode":"3ef4170333348e84","toSide":"left"},
		{"id":"ed714b3ab92fceaf","fromNode":"b97f6c6c3af15295","fromSide":"bottom","toNode":"2941e90ce6c0fd2e","toSide":"top"},
		{"id":"2b53c9e7c4c32066","fromNode":"2941e90ce6c0fd2e","fromSide":"bottom","toNode":"1be6a87a62a26638","toSide":"top"},
		{"id":"58ceb83b092eaae8","fromNode":"b97f6c6c3af15295","fromSide":"right","toNode":"1c9cfb53f2ea6a27","toSide":"left"},
		{"id":"8ea108dcd631a2e4","fromNode":"1c9cfb53f2ea6a27","fromSide":"right","toNode":"bc97d3f465866538","toSide":"left"},
		{"id":"6ae7de23132927d3","fromNode":"bc97d3f465866538","fromSide":"bottom","toNode":"e35038af26a742e9","toSide":"right"},
		{"id":"62685079efe75f62","fromNode":"1c9cfb53f2ea6a27","fromSide":"bottom","toNode":"e35038af26a742e9","toSide":"top"},
		{"id":"a85bf8aa9ef664e2","fromNode":"e35038af26a742e9","fromSide":"left","toNode":"38224f6da2a4cf46","toSide":"right"}
	]
}