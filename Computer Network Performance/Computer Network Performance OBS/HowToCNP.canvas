{
	"nodes":[
		{"id":"8bf923c2a7a9b2f5","type":"text","text":"# Richiami di Probabilità\n\nSe $\\Omega$ è lo spazio di tutti i possibili eventi ed $E\\subseteq \\Omega$ è un singolo evento, la probabilità di $E$ è in generale definita come il rapporto tra la misura di $E$ e la misura di $\\Omega$. Abbiamo quindi che$$P(E\\cup F) = P(E) + P(F) - P(E\\cap F) \\leq P(E) + P(F)$$L'uguaglianza vale solo se $P(E\\cap F)=0$, ovvero se gli eventi $E$ ed $F$ sono ***mutuamente esclusivi***. In modo analogo possiamo scriverlo con gli insiemi, ovvero $E\\cap F = \\emptyset$.\n\n- Dato un set di eventi $\\{E_i\\}$ tali che $E_i\\cap E_j = \\emptyset$, se $\\bigcup_iE_i = F$  allora $\\{E_i\\}$ è una ***partizione*** per $F$ (i.e. $F$ è totalmente ricoperto da eventi disgiunti $E_i$);\n- Eventi mutuamente esclusivi sono ***dipendenti***, in quanto per definizione il verificarsi di un evento influenza il verificarsi dell'altro (i.e. se si verifica $E$ allora $F$ non può verificarsi);\n\t- Viceversa, $E$ ed $F$ sono ***indipendenti*** ($E\\perp F$ ) ***sse*** $P(E\\cap F) = P(E)\\cdot P(F)$.\n\nDefiniamo la ***probabilità condizionata*** come$$P(E|F)={P(E\\cap F)\\over P(F)}$$che significa cercare un elemento $\\in E$ dentro l'insieme $F\\subseteq\\Omega$. In pratica, $F$ diventa il nuovo $\\Omega$ ed $E\\cap F$ diventa il nuovo $E$. Da questa definizione seguono diverse cosette utili.\n\n- ***Teorema della Probabilità Totale*** - Sia $\\{F_i\\}$ una partizione per $\\Omega$. $P(E) = \\sum_i P(E|F_i) \\cdot P(F_i)$.\n\t- Una partizione per $\\Omega$ è $F_1 = F$ ed $F_2= F^C$, dove $F^C=\\{x\\in\\Omega\\,|\\,x\\notin F\\}$ è il ***complemento*** di $F$.\n\t- Consente di trovare una probabilità come somma delle probabilità sui singoli elementi di una partizione di $\\Omega$.\n- ***Teorema di Bayes*** - Consente di invertire la definizione di probabilità condizionata. Essendo $\\cap$ un operatore simmetrico abbiamo che $$P(E\\cap F)=P(F\\cap E) =P(E|F)\\cdot P(F)=P(F|E)\\cdot P(E)$$Da questo segue che$$P(F|E) = {P(E|F)\\cdot P(F)\\over P(E)}={P(E|F)\\cdot P(F)\\over \\sum_i P(E|F_i) \\cdot P(F_i)}$$","x":880,"y":-1880,"width":840,"height":862,"color":"4"},
		{"id":"8310d0f0c52e20e5","type":"text","text":"# Somme e Prodotti di Variabili Casuali\n\nIndichiamo con $f_X(x)$ la *pdf* associata al processo $X$ scritta nella variabile $x$.\n\nSegue che $f_{XY}(x,y)$ è pdf associata alla ***joint probability***$$P_{XY}(x,y) = P(X=x,\\,\\, Y=y)=\\int_{\\Omega_X}\\int_{\\Omega_Y}f_{XY}(x,y)dxdy$$È possibile risalire alla $f_X$ tramite una ***marginalizzazione***, ovvero integrando su $y$$$f_X(x) = \\int_{\\Omega_Y}f_{XY}(x,y)dy$$e viceversa. Tutto questo serve a dimostrare che l'operatore ***valore atteso***$$E[X] := \\int_{\\Omega_X}xf_X(x)dx$$***commuta sulla somma di variabili, ma in generale non sul prodotto***, ovvero$$\\begin{array}\\\\ E[X+Y] = E[X]+E[Y]\\\\ \\\\ E[XY] \\neq E[X]\\,E[Y]\\leadsto E[XY] \\overset{X\\perp Y}{=} E[X]\\,E[Y]\\end{array}$$***Il valore atteso distribuisce sul prodotto se e solo se $X$ e $Y$ sono indipendenti***.\n\nPiù in generale, la pdf della somma di due variabili indipendenti è data dall'***integrale di convoluzione*** definito come$$f_{Z=X+Y}(z=x+y) = (f_X*f_Y)(z)\\int_{\\mathbb{R}}f_X(x)f_Y(z-x)dx$$mentre la formula per il prodotto esiste ma è inutilmente complicata e non la scrivo.","x":2780,"y":-1880,"width":700,"height":862,"color":"4"},
		{"id":"c3fb8ec5d4b06fa4","type":"text","text":"# Distribuzioni\n \n Seguono le distribuzioni che devi usare per calcolare la probabilità che\n \n- si verifichi uno tra due eventi mutuamente esclusivi, rispettivamente con probabilità $p$ (successo) e $q=1-p$ (insuccesso) - ***Distribuzione di Bernoulli***;\n- si verifichino $k$ successi su una sequenza di $n$ eventi di Bernoulli indipendenti - ***Distribuzione Binomiale*** avente espressione$$P(X=k)=\\binom{n}{k}p^kq^{n-k}$$\n\t- Quante prove $k$ devo fare prima di ottenere il primo successo? Sono date dalla ***Distribuzione Geometrica*** avente espressione$$P(X=k) = pq^{k-1}$$\n- si verifichino $k$ eventi (rari) in un lungo (formalmente $t\\to\\infty$) periodo di osservazione - ***Distribuzione di Poisson***, cioè$$P(X=k)={\\lambda^ke^{-\\lambda}\\over k!}$$\n\t- Quanto tempo devo aspettare tra due eventi di Poisson? Me lo dice la ***Distribuzione Esponenziale***$$pdf(x)=\\lambda e^{-\\lambda x}$$\n\n$\\lambda$ è in generale un rate di arrivo, mentre nel caso continuo bisogna sostituire la variabile discreta $k$ con una continua $x$. Questo non mi restituisce propriamente una probabilità di un evento, ma la ***probability density function*** (***pdf***), nel senso che su un dominio continuo il singolo valore ha una probabilità di verificarsi $=0$. La pdf ha quindi senso solo sotto integrale in un certo intervallo. La funzione integrale della pdf è detta ***cumulativa***.","x":1920,"y":-1880,"width":680,"height":862,"color":"4"},
		{"id":"7a7dccca7d03435d","type":"text","text":"# Ex 3.14\n\nA company pays a fine if the time to process a request exceeds 7 seconds. Processing a request consists of two tasks: (a) retrieving the file – which takes some time X that is Exponentially distributed with mean 5, and (b) parsing the file – which takes some time Y that is independent of X and is distributed Uniform(1, 3), with mean 2. Given that the mean time to process a request is clearly 7 seconds, the company views the fine as unfair, because it will have to pay the fine on half its requests. Is this right? What is the actual fraction of time that the fine will have to be paid, and how much does this differ from 1/2?","x":3780,"y":-2300,"width":758,"height":271,"color":"5"},
		{"id":"49d1ad7a808d2e41","type":"text","text":"# Soluzione 3.14\n\nAnzitutto sappiamo che\n\n- $X$ è distribuita esponenziale $\\lambda e^{-\\lambda x}$ con $E[x] = {1\\over\\lambda} = 5 \\Rightarrow \\lambda = {1\\over 5} \\Rightarrow f_X(x) = {1\\over5}e^{-{x\\over5}}$.\n- $Y$ è piatta con media $2$ ed altezza ${1\\over3-1} = {1\\over2}$.\n\nIn pratica sto cercando $P(X+Y > 7)$. Abbiamo due modi di procedere.\n\n- ***Marginalizzazione*** - $f_Y$ è uniforme e va fuori dall'integrale$$P(X+Y > 7) = \\int_1^3 P(X+Y>7\\,|\\,Y = y) \\,\\,f_Y(y)\\,\\, dy = {1\\over2}\\int_1^3P(X>7-y)\\,dy$$$P(X>7-y)$ è ottenibile dalla $f_X$ ricavata dai dati dal problema$$P(X>7-y) = \\int_{7-y}^\\infty {1\\over5}e^{-{x\\over5}} \\,dx= \\bigg[e^{-x/5}\\bigg]_\\infty^{7-y}=e^{y-7\\over5}$$Segue che$$P(X+Y > 7) = {1\\over2}\\int_1^3 e^{y-7\\over5} dy = {5\\over2}\\bigg[e^{y-7\\over5}\\bigg]_1^3={5\\over2}\\bigg[e^{-{4\\over5}}-e^{-{6\\over5}}\\bigg]\\sim 0.37$$\n- ***Convoluzione*** - Scriviamo l'integrale per trovare direttamente $$f_{Z=X+Y}(z) = \\int_{\\mathbb{R}}f_Y(y)f_X(z-y)dy={1\\over2}\\int_1^3{1\\over5}e^{-{z-y\\over5}}dy={1\\over2}\\bigg[e^{y-z\\over5}\\bigg]_1^3 = {1\\over2}\\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]$$A questo punto la soluzione è data da$$P(Z>7) = {1\\over2}\\int_7^\\infty \\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]dz = {5\\over2}\\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]_\\infty^7={5\\over2}\\bigg[e^{-{4\\over5}}-e^{-{6\\over5}}\\bigg]\\sim 0.37$$\n- ***NON*** ti salti in mente di dire \"eh ma tanto $f_Y$ è piatta con media 2, è sufficiente calcolare $P(X>5)$\", perché ***NON*** è assolutamente consistente. ***NON*** si fa.  ","x":3780,"y":-1880,"width":758,"height":862,"color":"4"},
		{"id":"b098d10344d941ab","type":"text","text":"# Ottimizzazione\n\n\nSe con coda infinita raddoppio $\\lambda$ quanto deve essere $\\mu$ per mantenere R costante? Sicuro deve essere almeno $2\\lambda$, ma $2\\mu$ è troppo (in questo caso R dimezza!). Quindi è compreso tra i due. Il che dipende dal ritardo in coda immagino, perché R=S+T.\n\nse metto due sistemi queue+cpu in parallelo con probabilità $1\\over2$. Le due CPU hanno $\\mu=1/3$. Che succede se sostituisco uno dei due server con uno con $\\mu$ doppia? Velocizzo tutto? Non è così facile. Se un processore è molto veloce lancia più velocemente processi nella coda dell'altro, rallentando il sistema. il bilanciamento è più importante di aumentare le specifiche a caso. NO!! se ti calcoli R resta identico!! Se ho un parallelo, R è determinato dal più lento.\n\n\np/1-p = mu1/mu2 = 2/3\\*3=2=p/1-p so 2p = 1-p so 3p = 1 cioè se metto delle probabilità proporzionali alle due mu velocizzo? Sì, cioè faccio load balancing. ma questo richiede un router intelligente. E allora? eh allora devo migliorare entrambi i server in parallelo, anche di molto poco.\n\nse ho un solo server con $\\mu = 4 j/s$ oppure 4 server in parallelo con $\\mu = 1 j/s$ ? ... dipende, da quanto sono lunghi i job, se sono tutti uguali, ecc. Il parallelismo è più fair, se ho poco lavoro è meglio il singolo server veloce. Non ce n'è uno migliore.","x":-10240,"y":891,"width":740,"height":569},
		{"id":"a73718e36cac73fd","type":"text","text":"# L4 (Probabilità)\n\nCose importanti sono solo le seguenti:\n\n- $E[XY] = E[X]E[Y]$ ***solo se gli eventi sono indipendenti***;\n- $E[X+Y] = E[X]+E[Y]$ ***sempre***.\n\nex 3.14","x":-7420,"y":-480,"width":760,"height":1294},
		{"id":"4aa37780d21cd695","type":"text","text":"# L6\n\nsta dicendo che la little law è una legge di conservazione di flusso\n\nChiamiamo $V_i^j$ il numero di visite che il processo $j$ fa al device $i$. Per definizione $$X_i = \\lim_t{C_i(t)\\over t} = \\lim {\\sum_{j\\in C(t)}V_i^j\\over t}{C(t)\\over C(t)}=E[V_i]\\cdot X$$dove $C(t)$ sono i job completati al tempo $t$ (forced flow law).\n\nesercizi fogli\n\ndefiniamo$$D_i=\\sum_{j=1}^{V_i}S_i^j$$ ovvero se il singolo job fa $V_i$ visite al device $i$, questo richiederà un tempo totale $D_i$ (j indicizza la visita...). Vorrei fare $$E[V_i]E[S_i] = E[D_i] = E\\bigg[\\sum_{j=1}^{V_i}S_i^j\\bigg]$$ma $V_i$ è a sua volta una random variable. Quindi per dimostrarlo $$= \\sum_nE\\bigg[\\sum_{j=1}^{V_i}S_i^j\\,\\,\\bigg|\\,\\,V_i=n\\bigg]\\times p(V_i=n)$$sostituisco l'upper bound  della somma con n, che è una costante e la porto fuori (la E resta perché ho sviluppato solo la sommatoria come variablie casuale e ho usato probabilità totale, poi la p(v=n) la porto fuori da E perché sticazzi), poi assumo che tutte le $S_i^j$ sono tutte DISTRIBUITE UGUALI (NON UGUALI E BASTA!! APPROFONDIRE), a quel punto esce un valore atteso che non dipende da j, porto fuori e viene per definizione\n\n$$E[S_i]\\times \\sum n\\,\\,p(V_i=n)$$ che è S$\\times$V. Quindi $$E[D_i]=E[V_i]E[S_i]$$che è la demand law. Se $B_i$ è il busytime del device $i$, $D_i=B_i\\times C$. Ora facciamo una reskin della utilization law$$\\rho_i = S_iX_i = E[S_i]E[V_i]\\times X = D_i X$$che si chiama bottleneck law\n\n\nMLP = MultiProgrammingLevel sarebbe il numero di job eseguibili in batch","x":-5691,"y":-480,"width":631,"height":1294},
		{"id":"2db738a55dcc2bec","type":"text","text":"# Teoria delle code L 1\n\nquanto ci mette questa coda?\n\nanalisi stocastica per prevedere le cose: \n\n- tempo - i delay di reti\n\t- quantità di dati (throughput coerente)\n\t- jitter (varianza di delay)\n\t- parallelismo? (ricollega throughput per servire più utenti alla volta)\n- spazio ed energia ignorati\n\nresponse time R intende tempo di processamento (coda inclusa). Se la coda è vuota questo coincide con il service time (S=$1\\over v$ dove v è la velocità della cpu). Il waiting time è $T_w$. $R = S+T_w$\n\nv non è il throughput X, perché se non arrivano processi con v non faccio nulla. $\\lambda$ è il rate di arrivo di pacchetti processati a velocità $u$. X è il minimo tra i due (no, perché è sempre medio!! posso parlarne solo in termini di valore atteso!!), $u$ è il massimo di X.\n\nanche se $\\lambda < \\mu$ posso vedere roba in coda, perché $\\lambda$ è sempre una media (quindi posso solo dire che la coda può riempirsi al più con un numero finito di elementi?). Per questo con $\\lambda = \\mu$ la coda si riempie. Indefinitamente? Ci sono N i processi in coda. N(t) = Arrival(t)-Departure(t) $\\geq$ $(\\lambda - \\mu)t$, la disuguaglianza è perché $\\mu t$ è il massimo numero di job uscenti, non quello effettivo. devo sostituire $\\mu$ col throughput, che sarebbe il departed effettivo (nel qual caso ho l'uguaglianza?). la disuguaglianza me la tengo perché è sempre vera. N è sempre una media.\n\n- $\\lambda - X \\geq 0$ ???\n\nstability condition: $\\lambda < \\mu$. Ma se sono uguali? ci sono fluttuazioni, perché queste sono solo medie, quindi torniamo a quello che dicevamo prima. Questo vale per un buffer infinito.\n\nE se è finito? se $\\lambda < \\mu$, X = $\\lambda (1-p_d)$, dove p_d è la probabilità di essere discarded.\n\nSe con coda infinita raddoppio $\\lambda$ quanto deve essere $\\mu$ per mantenere R costante? Sicuro deve essere almeno $2\\lambda$, ma $2\\mu$ è troppo (in questo caso R dimezza!). Quindi è compreso tra i due. Il che dipende dal ritardo in coda immagino, perché R=S+T.\n\nse metto due sistemi queue+cpu in parallelo con probabilità $1\\over2$. Le due CPU hanno $\\mu=1/3$. Che succede se sostituisco uno dei due server con uno con $\\mu$ doppia? Velocizzo tutto? Non è così facile. Se un processore è molto veloce lancia più velocemente processi nella coda dell'altro, rallentando il sistema. il bilanciamento è più importante di aumentare le specifiche a caso. NO!! se ti calcoli R resta identico!! Se ho un parallelo, R è determinato dal più lento.\n\n\np/1-p = mu1/mu2 = 2/3\\*3=2=p/1-p so 2p = 1-p so 3p = 1 cioè se metto delle probabilità proporzionali alle due mu velocizzo? Sì, cioè faccio load balancing. ma questo richiede un router intelligente. E allora? eh allora devo migliorare entrambi i server in parallelo, anche di molto poco.\n\nse ho un solo server con $\\mu = 4 j/s$ oppure 4 server in parallelo con $\\mu = 1 j/s$ ? ... dipende, da quanto sono lunghi i job, se sono tutti uguali, ecc. Il parallelismo è più fair, se ho poco lavoro è meglio il singolo server veloce. Non ce n'è uno migliore.","x":-10240,"y":-480,"width":740,"height":1294},
		{"id":"ae13a0ed0a553ebc","type":"text","text":"# L 2\n\nper un buffer infinito in cui $\\mu>\\lambda$, $R=\\frac{1}{\\mu - \\lambda}$.\n\nse ho $X=\\mu$ la coda si riempie indefinitamente. e se faccio una gerarchia in cui dopo il decimo posto in coda reindirizzo su un altro CPU è meglio di un parallelo? direi di no. oppure di fatto è un parallelo con probabilità proporzionali alla velocità...\n\nR è anche il service time per il numero medio di processi in coda + 1 (nella CPU)\n\nnell'esempio del parallelo asimmetrico, X per il server veloce resta uguale a quello lento. Dipende dallo split del router? sì ma non solo. i bottleneck sono dati dalle code. se c'è poco carico non vedo le code, quindi non vedo bottleneck.\n\ntutto questo era con un cavo che mandava la roba in loop. ora non c'è. in questo caso anche migliorare un solo server migliora R e X, perché non c'è \"feedback\".\n\nPoniamo di avere N server in parallelo, tutti con stessa $\\mu$. Due modelli:\n\n- una sola coda comune\n\t- non hai coda se metti $\\lambda$ server in parallelo. in questo caso hai R = S, ma non puoi fare R < S con nessun numero di server paralleli \n- ognuno con una coda\n\ndiverse scelte portano diversi benefici, ovviamente\n\n\nsegue ex 2.1 del libro (quale? perché non ce l'ho?)\n\n","x":-9300,"y":-480,"width":680,"height":1294},
		{"id":"602a250412f9f8db","type":"text","text":"# L3\n\njobs/sec è una sorta di misura a livello applicazione, posso usare un numero di cicli medi per job per la conversione (e.g. $5\\cdot 10^3$ cicli/job se ho CPU a $15\\cdot10^4$ cicli/sec avrò $\\mu \\sim 30 job/s$).\n\ne se la coda è finita (lunga M)? anche se $\\lambda<\\mu$ non posso dire che $X=\\lambda$, ma solo che $X<\\lambda$ (sempre a causa delle fluttuazioni, la coda si può riempire fino a scartare qualcosa):$$p_{full}=p(N=M+1) \\neq 0$$\n\"I don't have rum for other jobs\". quindi posso definire un ***drop rate*** come$$\\lambda_{drop} = \\lambda\\cdot p_{full}$$\nquindi chiaramente $X = \\lambda-\\lambda_{drop}$. Nota che non è importante che $\\lambda$ sia minore di $\\mu$. Se è maggiore, semplicemente, il drop rate vola alle stelle.\n\n\"I'd like to introduce UTILIZATION.\" Due casi:\n\n- un solo server - data dal ratio tra busy e observation time (i.e. osservo per 100 secondi, in che percentuale di questo tempo il server è busy?), si indica con $\\rho$. misura empirica $\\in [0,1]$ $\\sum{B_i}\\over\\tau$\n\t- altrimenti posso definirla come probabilità che il server sia busy (che per grandi numeri è equivalente, ma anche per definizione frequentista di probabilità)\n- m server - $\\rho = \\overline{N}_{\\text{busy servers}}/m \\in [0,1]$. perché è equivalente? è mezzo ovvio, nel senso che è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità (m è la normalizzazione).\n\t- formalmente, se applico questa definizione al caso con un solo server m = 1 e $N_{BS}$ è $1\\cdot p(server busy) + 0\\cdot p(server not busy)$. così per m=1 trovo il caso a un solo server. e viceversa? invece di osservare da 0 a T osservo da 0 a mT e metto i server in serie, poi applico la definizione ed esce la stessa cosa. (intuitivamente, il fatto che N medio in un dato istante fa una roba equivalente alla definizione sul tempo è una specie di trasformata di fourier...?)\n\nvorrei massimizzare l'utilization (senza raggiungere 1 forse, sembra un rischio). sia C jobs completati entro $\\tau$, moltiplico e divido ottenendo $\\rho=$$B\\over C$$C\\over\\tau$ dove $B\\over C$ è il time di esecuzione medio per job (anche detto service time..., perché B è CPU time). Dunque $$\\rho = S\\cdot X$$che prende il nome di ***utilization law***. Nota che vale per il singolo server, non per N server.$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$\nil secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$\ncioè $\\rho = SX$, che è quello che ho trovato prima, ma stavolta con la probabilità invece che con osservazioni empiriche. Yeee.\n\n","x":-8360,"y":-480,"width":760,"height":1294},
		{"id":"5a784396cbb6c294","type":"text","text":"# Computer Network Performance\n\nIn una rete sono presenti dei ***job*** (i.e. processi) che devono essere processati da uno o più ***server*** (i.e. nodi schematizzabili come ***CPU + Queue***).\n\nDiversi parametri (e.g. velocità $\\mu_i$ della $i$-esima CPU, rate $\\lambda$ di arrivo dei processi) definiscono le grandezze utilizzate per valutare le ***performance*** del sistema complessivo (e.g. ***throughput*** $X$, ***tempo di processamento*** $R$) o di porzioni del sistema stesso.\n\nTutte le grandezze sono intese come ***valori medi soggetti a fluttuazioni***. Ogni variabile va in generale trattata come aleatoria, con opportuna distribuzione a seconda del caso.","x":320,"y":2657,"width":740,"height":303,"color":"6"},
		{"id":"72a1764afabd7979","type":"text","text":"# Introduzione, Glossario e Stabilità\n\nSupponiamo di avere una CPU che processa ad una velocità $\\mu$ (espressa in $job/s$) dei processi che arrivano in input ad un rate $\\lambda$, ed una queue di attesa per i job non ancora processati. Diamo alcune definizioni:\n\n- Se la coda è vuota, il ***response time*** $R$ (i.e. il tempo che intercorre tra l'ingresso del processo nel sistema e la sua uscita) sarà uguale al tempo di processamento del singolo job, detto ***service time*** e pari a $S=1/\\mu$;\n- Se la coda non è vuota, $R$ del sistema sarà in generale maggiore di $S$. Di quanto? Del ***waiting time*** in coda $T_w$. Quindi $R=S+T_w$;\n\t- Posso anche scriverlo come $S\\cdot N$, con $N$ numero medio di processi in coda.\n- Il ***throughput*** $X$ è il numero di job completati dal sistema in un'unità di tempo.\n\t- ***NON*** coincide con $\\mu$: se non arrivano processi, $X=0$ ma la CPU continua ad avere il parametro $\\mu$ che ne definisce la velocità;\n\t\t- Tuttavia, $\\mu$ è un ***limite superiore*** per $X$.\n\t- ***NON*** è il minimo tra $\\lambda$ e $\\mu$, perché $\\lambda$ ***è una variabile aleatoria*** (di cui in genere si fornisce il valore atteso).\n\t\t- Segue che è possibile vedere la coda riempirsi anche se $\\lambda<\\mu$.\n\nDetto questo, possiamo ricavare la popolazione in coda $$N(t) = \\text{Arrival}(t) - \\text{Departure}(t)\\geq\\lambda  t - \\mu t = (\\lambda-\\mu)t$$ dove la maggiorazione è dovuta al fatto che $\\mu t$ è il $\\sup$ del throughput. Segue che per evitare di far crescere all'infinito la popolazione della coda (o di scartare job, se il buffer è finito) si deve avere $\\lambda-\\mu<0$ (***condizione di stabilità***).\n\nAssumiamo sempre di lavorare con sistemi stabili.","x":320,"y":3115,"width":740,"height":722,"color":"4"},
		{"id":"7bb4ea5e8877ccbe","type":"text","text":"# Little Law\n\n","x":1310,"y":3115,"width":740,"height":722},
		{"id":"b97f6c6c3af15295","type":"text","text":"# Condizione di Stabilità","x":500,"y":4200,"width":380,"height":120},
		{"id":"6c4e1b71f91fca83","type":"text","text":"# Utilization Law\n\nSe osservo per un periodo $\\tau$, in che percentuale di questo tempo la CPU è in uso?\n\n- Se ho un solo server, questa grandezza sarà banalmente il rapporto tra (la somma dei vari) ***busy time*** e ***observation time***, dunque $\\rho = {\\sum_iB_i\\over\\tau}\\in[0,1]$ o, in modo analogo, la probabilità che il server sia busy (secondo la definizione frequentista);\n- Se ho $m$ server usiamo effettivamente la statistica e la definiamo come$$\\rho=  {\\overline{N}_{\\text{busy servers}}\\over m} \\in [0,1]$$\n\t- Intuitivamente, è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità frequentista come nel caso precedente ($m$ è la normalizzazione);\n\t- Formalmente, è facile applicare questa definizione al caso $m=1$ è vedere che $\\overline{N}_{BS} = 1\\cdot p(\\text{Server 1 is busy})+0\\cdot p(\\text{Server 1 is not busy})$, cioè ritrovo la definizione del singolo server. Viceversa, allungo il periodo di osservazione da $\\tau$ ad $m\\tau$ e metto i server in serie e...? Viene lo stesso? DA DEFINIRE\n\nVisto che le due definizioni sono equivalenti, usiamo la prima. Introduciamo il numero $C$ di ***job completati entro*** $\\tau$ e riscriviamo$$\\rho={B\\over C}{C\\over \\tau}$$A questo punto $B\\over C$ è il tempo di esecuzione medio per processo, che per definizione è il service time $S$, e $C\\over\\tau$ è per definizione il throughput $X$. Otteniamo la ***utilization law***$$\\rho = S\\cdot X$$Vale solo per il singolo server, non per il parallelo???????????????\n\nSi può anche ricavare dalla probabilità totale applicata al throughput$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$il secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$","x":-680,"y":3029,"width":740,"height":895,"color":"3"},
		{"id":"47c5456b7006f8ff","type":"text","text":"# L3\n\njobs/sec è una sorta di misura a livello applicazione, posso usare un numero di cicli medi per job per la conversione (e.g. $5\\cdot 10^3$ cicli/job se ho CPU a $15\\cdot10^4$ cicli/sec avrò $\\mu \\sim 30 job/s$).\n\ne se la coda è finita (lunga M)? anche se $\\lambda<\\mu$ non posso dire che $X=\\lambda$, ma solo che $X<\\lambda$ (sempre a causa delle fluttuazioni, la coda si può riempire fino a scartare qualcosa):$$p_{full}=p(N=M+1) \\neq 0$$\n\"I don't have rum for other jobs\". quindi posso definire un ***drop rate*** come$$\\lambda_{drop} = \\lambda\\cdot p_{full}$$\nquindi chiaramente $X = \\lambda-\\lambda_{drop}$. Nota che non è importante che $\\lambda$ sia minore di $\\mu$. Se è maggiore, semplicemente, il drop rate vola alle stelle.\n\n\"I'd like to introduce UTILIZATION.\" Due casi:\n\n- un solo server - data dal ratio tra busy e observation time (i.e. osservo per 100 secondi, in che percentuale di questo tempo il server è busy?), si indica con $\\rho$. misura empirica $\\in [0,1]$ $\\sum{B_i}\\over\\tau$\n\t- altrimenti posso definirla come probabilità che il server sia busy (che per grandi numeri è equivalente, ma anche per definizione frequentista di probabilità)\n- m server - $\\rho = \\overline{N}_{\\text{busy servers}}/m \\in [0,1]$. perché è equivalente? è mezzo ovvio, nel senso che è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità (m è la normalizzazione).\n\t- formalmente, se applico questa definizione al caso con un solo server m = 1 e $N_{BS}$ è $1\\cdot p(server busy) + 0\\cdot p(server not busy)$. così per m=1 trovo il caso a un solo server. e viceversa? invece di osservare da 0 a T osservo da 0 a mT e metto i server in serie, poi applico la definizione ed esce la stessa cosa. (intuitivamente, il fatto che N medio in un dato istante fa una roba equivalente alla definizione sul tempo è una specie di trasformata di fourier...?)\n\nvorrei massimizzare l'utilization (senza raggiungere 1 forse, sembra un rischio). sia C jobs completati entro $\\tau$, moltiplico e divido ottenendo $\\rho=$$B\\over C$$C\\over\\tau$ dove $B\\over C$ è il time di esecuzione medio per job (anche detto service time..., perché B è CPU time). Dunque $$\\rho = S\\cdot X$$che prende il nome di ***utilization law***. Nota che vale per il singolo server, non per N server.$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$\nil secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$\ncioè $\\rho = SX$, che è quello che ho trovato prima, ma stavolta con la probabilità invece che con osservazioni empiriche. Yeee.\n\n","x":-1600,"y":2913,"width":760,"height":1126},
		{"id":"a7f39a318bb503ec","type":"file","file":"2.1.png","x":1240,"y":2200,"width":400,"height":224},
		{"id":"a2cb1b62ac8e14a7","type":"text","text":"# L5\n\nmettiamo in relazione popolazione $E[N]$ del sistema, X e tempo di permanenza all'interno del sistema $E[T]$ (Little Law):$$E[T]={E[N]\\over X}$$questo indipendentemente da cosa sia il sistema: è una black box. una condizione è che il sistema sia ergodico.\n\nper il semplice sistema con una coda/processore l'unica condizione è quella di stabilità (non serve coda FCFS)\n\nappunti scritti!\n\nse c'è rejection interna $X = \\lambda - \\lambda_{drop}$\n\nclosed system - $E[N] = X(E[R]+E[Z])$ \n\nsi ritrova utilization $\\rho_i = S_iX_i$ che è sempre $\\leq 1$!!","x":-6500,"y":-480,"width":660,"height":1294},
		{"id":"17b80d20631e90fd","type":"text","text":"# L5\n\nmettiamo in relazione popolazione $E[N]$ del sistema, X e tempo di permanenza all'interno del sistema $E[T]$ (Little Law):$$E[T]={E[N]\\over X}$$questo indipendentemente da cosa sia il sistema: è una black box. una condizione è che il sistema sia ergodico.\n\nper il semplice sistema con una coda/processore l'unica condizione è quella di stabilità (non serve coda FCFS)\n\nappunti scritti!\n\nse c'è rejection interna $X = \\lambda - \\lambda_{drop}$\n\nclosed system - $N = X(E[R]+E[Z])$ (N non è un valore atteso, il sistema è chiuso quindi è noto)\n\nsi ritrova utilization $\\rho_i = S_iX_i$ che è sempre $\\leq 1$!!","x":2270,"y":3029,"width":660,"height":1294},
		{"id":"3ef4170333348e84","type":"text","text":"# Rapido Riassunto\n\n***forced flow law***$$$$","x":-4880,"y":-112,"width":461,"height":559},
		{"id":"5158a83889f13dea","x":3300,"y":3029,"width":700,"height":1294,"type":"text","text":"# Stochastic Processes\n\nCercare l'average population è una roba complessa. Stochastic process is a sequence of random variables, which represent the evolution of the system in time.\n\nContinuous Time Stochastic Processes (CTSP) sono riconducibili ai Discrete TSP.\n\nState space is $\\mathbb{I}$, $X_k$ random variables definiscono lo state of the process at time k.\nConsideriamo una sola coda. Lo stato del sistema è la popolazione della coda. Lo schematizzo come un automa/catena di Markov lineare. Come la analizzo?\n\nDiscrete Markov Chain - perché sia una CdM deve valere che se$$1\\forall\\,n\\in\\N\\quad\\forall\\,i.j\\quad\\forall i_k\\in\\I$$allora si ha che$$P\\{X_{n+1}=j\\,|\\,X_n=i, X_{n-1}=i_{n-1}, ...\\}=P\\{X_{n+1}=j\\,|\\,X_n=i\\}=P_{ij}$$ovvero la proprietà di ***assenza di memoria*** (***history independence***) e di ***time homogeneity***. Nota che non è detto che sia rispettata.\n\nSe $|\\I|=M<\\infty$, definisco una transition probability matrix $P\\in[0,1]^{M\\times M}$ con elementi $p_{ij}$ aventi la proprietà $\\sum_jp_{ij}=1$ (le righe sommano a 1).\n\nEsempio: repairing facility problem. una macchina o funziona o è rotta (i.e. $\\I=\\{broken, working\\}$)\n\n***Umbrella problem*** - voglio sapere p che il prof si bagni. ha due ombrelli "},
		{"id":"6bf4661a96526f35","x":2980,"y":3260,"width":250,"height":160,"type":"text","text":"$$\\newcommand{\\I}{\\mathbb{I}}\\I$$oind\n$$\\A\\B\\C\\D\\E\\F\\G\\H\\I\\J\\K$$"}
	],
	"edges":[
		{"id":"61f1212c35f4bce8","fromNode":"8bf923c2a7a9b2f5","fromSide":"right","toNode":"c3fb8ec5d4b06fa4","toSide":"left"},
		{"id":"f0fdd0999c6700cd","fromNode":"c3fb8ec5d4b06fa4","fromSide":"right","toNode":"8310d0f0c52e20e5","toSide":"left"},
		{"id":"8208b26e47519e8b","fromNode":"7a7dccca7d03435d","fromSide":"bottom","toNode":"49d1ad7a808d2e41","toSide":"top"},
		{"id":"e00afe36636e34f0","fromNode":"5a784396cbb6c294","fromSide":"bottom","toNode":"72a1764afabd7979","toSide":"top"},
		{"id":"0bf74c88886abf4f","fromNode":"72a1764afabd7979","fromSide":"left","toNode":"6c4e1b71f91fca83","toSide":"right"},
		{"id":"2cfd6e1fa7e7935e","fromNode":"72a1764afabd7979","fromSide":"right","toNode":"7bb4ea5e8877ccbe","toSide":"left"},
		{"id":"cd4586adb74413a6","fromNode":"4aa37780d21cd695","fromSide":"right","toNode":"3ef4170333348e84","toSide":"left"}
	]
}