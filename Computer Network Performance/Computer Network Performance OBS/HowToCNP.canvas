{
	"nodes":[
		{"id":"b098d10344d941ab","type":"text","text":"# Ottimizzazione\n\n\nSe con coda infinita raddoppio $\\lambda$ quanto deve essere $\\mu$ per mantenere R costante? Sicuro deve essere almeno $2\\lambda$, ma $2\\mu$ è troppo (in questo caso R dimezza!). Quindi è compreso tra i due. Il che dipende dal ritardo in coda immagino, perché R=S+T.\n\nse metto due sistemi queue+cpu in parallelo con probabilità $1\\over2$. Le due CPU hanno $\\mu=1/3$. Che succede se sostituisco uno dei due server con uno con $\\mu$ doppia? Velocizzo tutto? Non è così facile. Se un processore è molto veloce lancia più velocemente processi nella coda dell'altro, rallentando il sistema. il bilanciamento è più importante di aumentare le specifiche a caso. NO!! se ti calcoli R resta identico!! Se ho un parallelo, R è determinato dal più lento.\n\n\np/1-p = mu1/mu2 = 2/3\\*3=2=p/1-p so 2p = 1-p so 3p = 1 cioè se metto delle probabilità proporzionali alle due mu velocizzo? Sì, cioè faccio load balancing. ma questo richiede un router intelligente. E allora? eh allora devo migliorare entrambi i server in parallelo, anche di molto poco.\n\nse ho un solo server con $\\mu = 4 j/s$ oppure 4 server in parallelo con $\\mu = 1 j/s$ ? ... dipende, da quanto sono lunghi i job, se sono tutti uguali, ecc. Il parallelismo è più fair, se ho poco lavoro è meglio il singolo server veloce. Non ce n'è uno migliore.","x":-10240,"y":891,"width":740,"height":569},
		{"id":"a73718e36cac73fd","type":"text","text":"# L4 (Probabilità)\n\nCose importanti sono solo le seguenti:\n\n- $E[XY] = E[X]E[Y]$ ***solo se gli eventi sono indipendenti***;\n- $E[X+Y] = E[X]+E[Y]$ ***sempre***.\n\nex 3.14","x":-7420,"y":-480,"width":760,"height":1294},
		{"id":"4aa37780d21cd695","type":"text","text":"# L6\n\nsta dicendo che la little law è una legge di conservazione di flusso\n\nChiamiamo $V_i^j$ il numero di visite che il processo $j$ fa al device $i$. Per definizione $$X_i = \\lim_t{C_i(t)\\over t} = \\lim {\\sum_{j\\in C(t)}V_i^j\\over t}{C(t)\\over C(t)}=E[V_i]\\cdot X$$dove $C(t)$ sono i job completati al tempo $t$ (forced flow law).\n\nesercizi fogli\n\ndefiniamo$$D_i=\\sum_{j=1}^{V_i}S_i^j$$ ovvero se il singolo job fa $V_i$ visite al device $i$, questo richiederà un tempo totale $D_i$ (j indicizza la visita...). Vorrei fare $$E[V_i]E[S_i] = E[D_i] = E\\bigg[\\sum_{j=1}^{V_i}S_i^j\\bigg]$$ma $V_i$ è a sua volta una random variable. Quindi per dimostrarlo $$= \\sum_nE\\bigg[\\sum_{j=1}^{V_i}S_i^j\\,\\,\\bigg|\\,\\,V_i=n\\bigg]\\times p(V_i=n)$$sostituisco l'upper bound  della somma con n, che è una costante e la porto fuori (la E resta perché ho sviluppato solo la sommatoria come variablie casuale e ho usato probabilità totale, poi la p(v=n) la porto fuori da E perché sticazzi), poi assumo che tutte le $S_i^j$ sono tutte DISTRIBUITE UGUALI (NON UGUALI E BASTA!! APPROFONDIRE), a quel punto esce un valore atteso che non dipende da j, porto fuori e viene per definizione\n\n$$E[S_i]\\times \\sum n\\,\\,p(V_i=n)$$ che è S$\\times$V. Quindi $$E[D_i]=E[V_i]E[S_i]$$che è la demand law. Se $B_i$ è il busytime del device $i$, $D_i=B_i\\times C$. Ora facciamo una reskin della utilization law$$\\rho_i = S_iX_i = E[S_i]E[V_i]\\times X = D_i X$$che si chiama bottleneck law\n\n\nMLP = MultiProgrammingLevel sarebbe il numero di job eseguibili in batch","x":-5691,"y":-480,"width":631,"height":1294},
		{"id":"2db738a55dcc2bec","type":"text","text":"# Teoria delle code L 1\n\nquanto ci mette questa coda?\n\nanalisi stocastica per prevedere le cose: \n\n- tempo - i delay di reti\n\t- quantità di dati (throughput coerente)\n\t- jitter (varianza di delay)\n\t- parallelismo? (ricollega throughput per servire più utenti alla volta)\n- spazio ed energia ignorati\n\nresponse time R intende tempo di processamento (coda inclusa). Se la coda è vuota questo coincide con il service time (S=$1\\over v$ dove v è la velocità della cpu). Il waiting time è $T_w$. $R = S+T_w$\n\nv non è il throughput X, perché se non arrivano processi con v non faccio nulla. $\\lambda$ è il rate di arrivo di pacchetti processati a velocità $u$. X è il minimo tra i due (no, perché è sempre medio!! posso parlarne solo in termini di valore atteso!!), $u$ è il massimo di X.\n\nanche se $\\lambda < \\mu$ posso vedere roba in coda, perché $\\lambda$ è sempre una media (quindi posso solo dire che la coda può riempirsi al più con un numero finito di elementi?). Per questo con $\\lambda = \\mu$ la coda si riempie. Indefinitamente? Ci sono N i processi in coda. N(t) = Arrival(t)-Departure(t) $\\geq$ $(\\lambda - \\mu)t$, la disuguaglianza è perché $\\mu t$ è il massimo numero di job uscenti, non quello effettivo. devo sostituire $\\mu$ col throughput, che sarebbe il departed effettivo (nel qual caso ho l'uguaglianza?). la disuguaglianza me la tengo perché è sempre vera. N è sempre una media.\n\n- $\\lambda - X \\geq 0$ ???\n\nstability condition: $\\lambda < \\mu$. Ma se sono uguali? ci sono fluttuazioni, perché queste sono solo medie, quindi torniamo a quello che dicevamo prima. Questo vale per un buffer infinito.\n\nE se è finito? se $\\lambda < \\mu$, X = $\\lambda (1-p_d)$, dove p_d è la probabilità di essere discarded.\n\nSe con coda infinita raddoppio $\\lambda$ quanto deve essere $\\mu$ per mantenere R costante? Sicuro deve essere almeno $2\\lambda$, ma $2\\mu$ è troppo (in questo caso R dimezza!). Quindi è compreso tra i due. Il che dipende dal ritardo in coda immagino, perché R=S+T.\n\nse metto due sistemi queue+cpu in parallelo con probabilità $1\\over2$. Le due CPU hanno $\\mu=1/3$. Che succede se sostituisco uno dei due server con uno con $\\mu$ doppia? Velocizzo tutto? Non è così facile. Se un processore è molto veloce lancia più velocemente processi nella coda dell'altro, rallentando il sistema. il bilanciamento è più importante di aumentare le specifiche a caso. NO!! se ti calcoli R resta identico!! Se ho un parallelo, R è determinato dal più lento.\n\n\np/1-p = mu1/mu2 = 2/3\\*3=2=p/1-p so 2p = 1-p so 3p = 1 cioè se metto delle probabilità proporzionali alle due mu velocizzo? Sì, cioè faccio load balancing. ma questo richiede un router intelligente. E allora? eh allora devo migliorare entrambi i server in parallelo, anche di molto poco.\n\nse ho un solo server con $\\mu = 4 j/s$ oppure 4 server in parallelo con $\\mu = 1 j/s$ ? ... dipende, da quanto sono lunghi i job, se sono tutti uguali, ecc. Il parallelismo è più fair, se ho poco lavoro è meglio il singolo server veloce. Non ce n'è uno migliore.","x":-10240,"y":-480,"width":740,"height":1294},
		{"id":"ae13a0ed0a553ebc","type":"text","text":"# L 2\n\nper un buffer infinito in cui $\\mu>\\lambda$, $R=\\frac{1}{\\mu - \\lambda}$.\n\nse ho $X=\\mu$ la coda si riempie indefinitamente. e se faccio una gerarchia in cui dopo il decimo posto in coda reindirizzo su un altro CPU è meglio di un parallelo? direi di no. oppure di fatto è un parallelo con probabilità proporzionali alla velocità...\n\nR è anche il service time per il numero medio di processi in coda + 1 (nella CPU)\n\nnell'esempio del parallelo asimmetrico, X per il server veloce resta uguale a quello lento. Dipende dallo split del router? sì ma non solo. i bottleneck sono dati dalle code. se c'è poco carico non vedo le code, quindi non vedo bottleneck.\n\ntutto questo era con un cavo che mandava la roba in loop. ora non c'è. in questo caso anche migliorare un solo server migliora R e X, perché non c'è \"feedback\".\n\nPoniamo di avere N server in parallelo, tutti con stessa $\\mu$. Due modelli:\n\n- una sola coda comune\n\t- non hai coda se metti $\\lambda$ server in parallelo. in questo caso hai R = S, ma non puoi fare R < S con nessun numero di server paralleli \n- ognuno con una coda\n\ndiverse scelte portano diversi benefici, ovviamente\n\n\nsegue ex 2.1 del libro (quale? perché non ce l'ho?)\n\n","x":-9300,"y":-480,"width":680,"height":1294},
		{"id":"602a250412f9f8db","type":"text","text":"# L3\n\njobs/sec è una sorta di misura a livello applicazione, posso usare un numero di cicli medi per job per la conversione (e.g. $5\\cdot 10^3$ cicli/job se ho CPU a $15\\cdot10^4$ cicli/sec avrò $\\mu \\sim 30 job/s$).\n\ne se la coda è finita (lunga M)? anche se $\\lambda<\\mu$ non posso dire che $X=\\lambda$, ma solo che $X<\\lambda$ (sempre a causa delle fluttuazioni, la coda si può riempire fino a scartare qualcosa):$$p_{full}=p(N=M+1) \\neq 0$$\n\"I don't have rum for other jobs\". quindi posso definire un ***drop rate*** come$$\\lambda_{drop} = \\lambda\\cdot p_{full}$$\nquindi chiaramente $X = \\lambda-\\lambda_{drop}$. Nota che non è importante che $\\lambda$ sia minore di $\\mu$. Se è maggiore, semplicemente, il drop rate vola alle stelle.\n\n\"I'd like to introduce UTILIZATION.\" Due casi:\n\n- un solo server - data dal ratio tra busy e observation time (i.e. osservo per 100 secondi, in che percentuale di questo tempo il server è busy?), si indica con $\\rho$. misura empirica $\\in [0,1]$ $\\sum{B_i}\\over\\tau$\n\t- altrimenti posso definirla come probabilità che il server sia busy (che per grandi numeri è equivalente, ma anche per definizione frequentista di probabilità)\n- m server - $\\rho = \\overline{N}_{\\text{busy servers}}/m \\in [0,1]$. perché è equivalente? è mezzo ovvio, nel senso che è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità (m è la normalizzazione).\n\t- formalmente, se applico questa definizione al caso con un solo server m = 1 e $N_{BS}$ è $1\\cdot p(server busy) + 0\\cdot p(server not busy)$. così per m=1 trovo il caso a un solo server. e viceversa? invece di osservare da 0 a T osservo da 0 a mT e metto i server in serie, poi applico la definizione ed esce la stessa cosa. (intuitivamente, il fatto che N medio in un dato istante fa una roba equivalente alla definizione sul tempo è una specie di trasformata di fourier...?)\n\nvorrei massimizzare l'utilization (senza raggiungere 1 forse, sembra un rischio). sia C jobs completati entro $\\tau$, moltiplico e divido ottenendo $\\rho=$$B\\over C$$C\\over\\tau$ dove $B\\over C$ è il time di esecuzione medio per job (anche detto service time..., perché B è CPU time). Dunque $$\\rho = S\\cdot X$$che prende il nome di ***utilization law***. Nota che vale per il singolo server, non per N server.$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$\nil secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$\ncioè $\\rho = SX$, che è quello che ho trovato prima, ma stavolta con la probabilità invece che con osservazioni empiriche. Yeee.\n\n","x":-8360,"y":-480,"width":760,"height":1294},
		{"id":"a2cb1b62ac8e14a7","type":"text","text":"# L5\n\nmettiamo in relazione popolazione $E[N]$ del sistema, X e tempo di permanenza all'interno del sistema $E[T]$ (Little Law):$$E[T]={E[N]\\over X}$$questo indipendentemente da cosa sia il sistema: è una black box. una condizione è che il sistema sia ergodico.\n\nper il semplice sistema con una coda/processore l'unica condizione è quella di stabilità (non serve coda FCFS)\n\nappunti scritti!\n\nse c'è rejection interna $X = \\lambda - \\lambda_{drop}$\n\nclosed system - $E[N] = X(E[R]+E[Z])$ \n\nsi ritrova utilization $\\rho_i = S_iX_i$ che è sempre $\\leq 1$!!","x":-6500,"y":-480,"width":660,"height":1294},
		{"id":"b97f6c6c3af15295","type":"text","text":"# Definizione del Problema (i.e. voglio $X$ ed $R$)\n\nLe grandezze che sono interessato a mettere in relazione sono\n\n- il ***throughput*** $X$, i.e. quanti job processa il sistema complessivo in un periodo di osservazione unitario;\n- il ***response time*** $R$ (o $T$), i.e. quanto ci mette il sistema complessivo a processare il job\n\nSe $N$ è il numero di job nel sistema, la legge più generale possibile che lega queste grandezze è la ***Little's Law***. È praticamente una legge di conservazione, quindi per applicarla devo definire un volume chiuso che racchiude il sistema di cui voglio studiare le grandezze. Segue che $X$ sarà lo stesso sia all'ingresso che all'uscita della box.\n\nDistinguiamo due casi:\n\n- il sistema dentro la box è ***aperto*** - $N$ è un valore atteso.$$\\bra N\\ket=X\\bra R\\ket$$\n- Il sistema dentro la box è ***chiuso*** - $N$ è una costante, il ***think time*** $Z$ è il response time degli utenti (i.e. posso vedere il lato client come un server avente response time $Z$).$$N=X\\bigg(\\bra R\\ket+\\bra Z\\ket\\bigg)$$\n\t- Nota che dentro una box in cui applico la Little's Law per sistemi chiusi posso ancora applicare la Little's Law. Una cosa che mi sembra interessante è che se isolo solo il client e solo il server trovo$$X={N_{client}\\over Z}={N_{server}\\over R}\\so {N_{client}\\over N_{server}}={\n\t  Z\\over R}$$Boh così, era per dire.","x":-280,"y":4320,"width":880,"height":700,"color":"4"},
		{"id":"1c9cfb53f2ea6a27","type":"text","text":"# Derivare la Little's Law\n","x":1440,"y":4625,"width":386,"height":85,"color":"6"},
		{"id":"e35038af26a742e9","type":"text","text":"# Sistema Chiuso\n\nPer un sistema chiuso facciamo lo stesso ragionamento del sistema aperto, l'unica differenza è che la popolazione è nota: $a=Nt$.\n\nDefinisco una box in cui includo sia server che client, ma \"taglio fuori\" un pezzetto di collegamento, in modo da ricondurmi ad un sistema aperto. Posso applicare la Little's Law per il sistema aperto (in cui però conosco $N$)$$N=X\\bra T\\ket$$dove però stavolta $T$ è la somma dei response time del server ($R$) e del client ($Z$, anche detto ***think time***). Sostituendo abbiamo$$N=X\\bigg(\\bra R\\ket + \\bra Z\\ket\\bigg)$$","x":1283,"y":5349,"width":700,"height":387,"color":"4"},
		{"id":"bc97d3f465866538","type":"text","text":"# Sistema Aperto\n\nDato un sistema aperto ed un intervallo di osservazione da $0$ a $t$, abbiamo\n\n- i job $C(t)$ completati entro $t$, che occupano la CPU per un tempo$$\\sum_{i\\in C(t)}T_i$$\n- i job $A(t)$ arrivati entro $t$, che includono sia i job completati che quelli non ancora completati. Nel complesso, hanno occupato e/o occuperanno in futuro (per \"futuro\" si intende oltre $t$) la CPU per un tempo$$\\sum_{i\\in A(t)}T_i$$\n- sempre i job $\\in A(t)$, ma stavolta consideriamo solo il tempo fino a $t$$$a = \\int_0^tN(t')dt'$$\n\nPer come sono stati definiti, abbiamo che$$\\sum_{i\\in C(t)}T_i\\leq a \\leq \\sum_{i\\in A(t)}T_i$$\nMoltiplico e divido per $C(t)\\over C(t)$ a sinistra e per $A(t)\\over A(t)$ a destra, poi applico a tutti i membri $$\\lim_{t\\to\\infty} (*) {1\\over t}$$$$\\so \\lim_{t\\to\\infty} {C(t)\\over t}{\\sum_{i\\in C(t)}T_i\\over C(t)}\\leq \\lim_{t\\to\\infty}{a\\over t} \\leq \\lim_{t\\to\\infty} {A(t)\\over t}{\\sum_{i\\in A(t)}T_i\\over A(t)}$$\nA questo punto\n\n- $\\lim_{t\\to\\infty} {C(t)\\over t}$ è il throughput $X$;\n- $\\lim_{t\\to\\infty} {\\sum_{i\\in C(t)}T_i\\over C(t)}$ è il response time dei processi completati $\\bra T \\ket_C$;\n- $\\lim_{t\\to\\infty}{a\\over t}$ è il valore atteso del numero di job nel sistema $\\bra N\\ket$;\n- $\\lim_{t\\to\\infty} {A(t)\\over t}$ è l'arrival rate $\\l$;\n- $\\lim_{t\\to\\infty} {\\sum_{i\\in A(t)}T_i\\over A(t)}$ è il response time dei processi arrivati $\\bra T \\ket_A$.\n\nSotto l'ipotesi di sistema ergodico (in questo caso $\\l < \\mu$) abbiamo che$$\\bra T \\ket_C=\\bra T \\ket_A=\\bra R \\ket$$$$\\bra\\l\\ket = \\bra X\\ket$$\nQuindi per il sempreverde teorema dei carabinieri$$X\\bra R\\ket\\leq\\bra N\\ket \\leq X\\bra R\\ket \\quad\\so\\quad\\bra N\\ket = X\\bra R\\ket$$","x":2666,"y":4119,"width":880,"height":1097,"color":"4"},
		{"id":"38224f6da2a4cf46","type":"file","file":"LittleLawUHD.jpg","x":820,"y":5349,"width":407,"height":387},
		{"id":"2941e90ce6c0fd2e","type":"text","text":"# Strumenti utili a trovare $X$ ed $R$\n\nSe ci sono dei loop, è possibile che lo stesso processo visiti più di una volta lo stesso server. In questo caso parliamo di ***numero atteso di visite*** $V$. Se il loop è semplicemente una probabilità $p$ di passare dall'output all'input, allora $V={1\\over p}$. Posso esprimere il numero di visite di un singolo processo al server $i$ come rapporto tra i processi completati dal server $i$ e i processi completati dal sistema complessivo:$$V_i={C_i\\over C}$$\nIl ***service time*** è l'inverso della velocità della CPU.$$S={1\\over\\mu}$$\nSe il processo ha $V=1$ è banalmente il tempo che ci mette quel processo ad essere processato una volta (quindi escludendo la coda), altrimenti si estende immediatamente dicendo che la ***demand*** di un server è il service time per il numero di visite:$$\\bra D_i\\ket=\\bra V_i\\ket\\bra S_i\\ket$$\nSe osservo $C$ job completati ognuno dei quali richiede mediamente un tempo di esecuzione pari alla demand $D$, ricaviamo il ***busy time*** del server come$$B_i=D_i\\cdot C=C_i\\,S_i$$\n- $C$ è il numero di job completati dall'intero sistema, ***NON*** quello del singolo server $C_i$. Nella prima uguaglianza, l'informazione del numero di visite al server $i$ è inglobata in $D_i$.\n\n$B_i$ sta in qualche modo provando a dirci quanto tempo è occupato il server $i$, ma dipende dal tempo di osservazione. Per avere una grandezza normalizzata introduciamo la ***utilization*** $\\r\\in[0,1]$, che è il busy time diviso il tempo di osservazione$$\\r_i={B_i\\over\\t}={C_i\\over\\t}S_i = S_iX_i$$\nQuesta roba si chiama ***utilization law***. Se invece sostituisco l'altra definizione di $B_i$ ottengo$$\\r_i={B_i\\over\\t}={C\\over\\t}D_i = D_iX$$che in Cina chiamano ***bottleneck law***. In pratica tutte queste leggi sono definizioni di cose, ma tornano comodo perché alcune grandezze sono più facili da misurare rispetto ad altre.\n","x":-280,"y":5087,"width":880,"height":914,"color":"4"},
		{"id":"1be6a87a62a26638","type":"text","text":"# Bounds su $X$ ed $R$ (i.e. Come ottimizzare il sistema?)\n\nChe ci faccio con tutta questa roba? La uso per capire quali sono gli ***upper bound sul throughput*** e i ***lower bound sul response time*** (e con questo intendo quelli complessivi del sistema).\n\nEssendo normalizzata, $\\r\\leq1$. Dalla ***bottleneck law*** ricavo che $$D_iX\\leq1\\so X\\leq{1\\over D_i}\\so X\\leq{1\\over D_{max}}\\qquad\\bigg[\\text{Sarebbe }X\\leq{1\\over D_{max}}\\leq{1\\over D_i}\\bigg]$$Il server che all'interno del sistema complessivo ha la massima demand è il ***bottleneck*** per $X$;\n\n- Segue dalla ***Little's Law*** che$$N=X(R+Z)\\so R={N\\over X}-Z \\geq {N\\over X_{max}}-Z = ND_{max}-Z$$\n\nÈ chiaro che se $N=1$ avrò sempre un response time minore rispetto al caso $N>1$. Quindi$$R(N)\\geq R(1)$$Ma il tempo di processamento di un singolo job $R(1)$ si può ottenere facilmente come somma di tutte le demand dei singoli server $i$ (posso farlo perché con un solo processo non c'è ritardo in coda). Quindi$$R\\geq\\sum_iD_i=D_{tot}$$\n\n- Segue dalla ***Little's Law*** che$$X={N\\over(R+Z)}\\leq{N\\over R_{min}+Z} = {N\\over D_{tot}+Z}$$\n\nIn definitiva abbiamo che$$X\\leq\\min\\bigg\\{{N\\over D_{tot}+Z}, {1\\over D_{max}}\\bigg\\}$$$$R\\geq\\max\\bigg\\{D_{tot},\\, {ND_{max}-Z}\\bigg\\}$$\nIn entrambi i casi, l'intersezione tra le due curve è data da$$N^*={D_{tot}+Z\\over D_{max}}={D_{max}+\\sum_{i\\neq max} D_iZ\\over D_{max}}= 1 + {\\sum_{i\\neq max} D_i+Z\\over D_{max}}$$\nL'ultima è giusto per sapere che sicuramente l'incrocio avviene dopo $1$. $N^*$ separa infatti i regimi di\n- ***low population*** ($N<N^*$), in cui per migliorare le performance è sufficiente ridurre $D_{tot}$;\n- ***high population*** ($N<N^*$), in cui per migliorare le performance bisogna ridurre $D_{max}$.","x":-280,"y":6100,"width":880,"height":1046,"color":"4"},
		{"id":"dc5fcb165c998d28","type":"text","text":"# Glossario I\n\n- ***Queuing Delay*** ($T_w$) - Quanto tempo un processo in coda attende di essere processato dal server;\n- ***Service Time*** ($S_i$) - Quanto tempo ci mette il server $i$ a processare un job. È l'inverso della sua velocità: $$S_i={1\\over\\mu_i}$$\n\t- Nota che questo non include il queuing delay.\n- ***Response Time*** ($R$, a volte $T$) - La somma di Queuing Delay e Service Time, ovvero il tempo medio che intercorre tra l'ingresso in coda di un job ed il suo completamento;\n\t- Il ***Think Time*** ($Z$) è un response time degli utenti.\n- ***Completions*** ($C$) - ***Dato un tempo di osservazione***, il sistema complessivo ha completato $C$ jobs;\n\t- Posso definirlo per il singolo server all'interno del sistema complessivo. ***Dato un tempo di osservazione***, $C_i$ sono le completions del server $i$;\n\t- Se divido per il tempo di osservazione diventa il ***throughput*** $X$.\n- ***Visite*** ($V_i$) - Se esiste un percorso che collega l'output del server $i$ al suo stesso input, un singolo job potrebbe essere processato più di una volta. Il numero (atteso) di volte che ciò accade è detto numero di visite;\n\t- Nota che potrebbe essere minore di $1$ (e.g. se ho un singolo job diviso al $50\\%$ tra due CPU in parallelo e nessun loop, il numero atteso di visite per ognuna sarà $1\\over2$) o maggiore (e.g. se osservo $C$ completion del sistema e $C_i>C$ completion del server $i$, significa che ogni job completato dal sistema è stato completato più volte dal server $i$, ovvero $V_i={C_i\\over C}$);\n\t\t- Nota anche che nel $90\\%$ dei casi mi riferirò alle visite come dovute ai loop, e quindi $V_i>1$. Se il loop riporta direttamente dall'uscita all'ingresso della CPU con probabilità $p$, il numero atteso di visite è $1\\over p$.\n\t- Dalla definizione di throughput e di visite discende in modo molto naturale la ***forced flow law***$$X_i=\\bra V_i\\ket X$$Visto che il throughput è praticamente la derivata in $dt$ delle completions, questa è una reskin della definizione$$V_i={C_i\\over C}\\so C_i=V_iC$$La forced flow sta sostanzialmente dicendo che se per completare un job servono più passaggi (visite) dal server $i$, allora il suo throughput sarà maggiore di quello complessivo del sistema. Di quanto? Del numero di visite.\n- ***Demand*** ($D_i$) - Quanto tempo un singolo job impegna il server $i$ durante una sua singola esecuzione nel sistema complessivo;$$\\bra D_i\\ket=\\bra V_i\\ket\\bra S_i\\ket$$\n- ***Busy Time*** ($B_i$) - ***Dato un tempo di osservazione***, mentre il sistema complessivo completa $C$ jobs il server $i$ sarà impegnato per un tempo pari alla demand per il singolo job per il numero di completions$$B_i = D_iC$$Analogamente, posso vedere questa grandezza come il service time per il numero di job completati dal server $i$$$B_i=S_iC_i$$Queste due definizioni sono equivalenti:$$D_i=V_iS_i \\wedge C={C_i\\over V_i}\\so D_iC=S_iC_i$$\n- ***Utilization*** ($\\r_i$) - Percentuale di tempo in cui, mediamente, il server $i$ è occupato. È una probabilità che discende da una statistica su un lungo periodo di tempo (i.e. se osservo per 10 secondi il server è occupato per 2, se osservo per 100 misuro 22, per 1000 misuro 221... al limite la legge dei grandi numeri ci garantisce che raggiungeremo il \"valor vero\"):$$\\r_i=\\lim_{\\t\\to\\infty}{B_i(\\t)\\over\\t}$$\n\t- Dalla prima definizione di $B_i$ trovo la ***bottleneck law***$$\\r_i=\\lim_{\\t\\to\\infty}{C(\\t)\\over\\t}D_i=D_iX$$\n\t- Dalla seconda trovo la ***utilization law***$$\\r_i=\\lim_{\\t\\to\\infty}{C_i(\\t)\\over\\t}S_i=S_iX_i$$","x":-1560,"y":4783,"width":1020,"height":1526,"color":"4"},
		{"id":"47c5456b7006f8ff","type":"text","text":"# L3\n\njobs/sec è una sorta di misura a livello applicazione, posso usare un numero di cicli medi per job per la conversione (e.g. $5\\cdot 10^3$ cicli/job se ho CPU a $15\\cdot10^4$ cicli/sec avrò $\\mu \\sim 30 job/s$).\n\ne se la coda è finita (lunga M)? anche se $\\lambda<\\mu$ non posso dire che $X=\\lambda$, ma solo che $X<\\lambda$ (sempre a causa delle fluttuazioni, la coda si può riempire fino a scartare qualcosa):$$p_{full}=p(N=M+1) \\neq 0$$\n\"I don't have rum for other jobs\". quindi posso definire un ***drop rate*** come$$\\lambda_{drop} = \\lambda\\cdot p_{full}$$\nquindi chiaramente $X = \\lambda-\\lambda_{drop}$. Nota che non è importante che $\\lambda$ sia minore di $\\mu$. Se è maggiore, semplicemente, il drop rate vola alle stelle.\n\n\"I'd like to introduce UTILIZATION.\" Due casi:\n\n- un solo server - data dal ratio tra busy e observation time (i.e. osservo per 100 secondi, in che percentuale di questo tempo il server è busy?), si indica con $\\rho$. misura empirica $\\in [0,1]$ $\\sum{B_i}\\over\\tau$\n\t- altrimenti posso definirla come probabilità che il server sia busy (che per grandi numeri è equivalente, ma anche per definizione frequentista di probabilità)\n- m server - $\\rho = \\overline{N}_{\\text{busy servers}}/m \\in [0,1]$. perché è equivalente? è mezzo ovvio, nel senso che è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità (m è la normalizzazione).\n\t- formalmente, se applico questa definizione al caso con un solo server m = 1 e $N_{BS}$ è $1\\cdot p(server busy) + 0\\cdot p(server not busy)$. così per m=1 trovo il caso a un solo server. e viceversa? invece di osservare da 0 a T osservo da 0 a mT e metto i server in serie, poi applico la definizione ed esce la stessa cosa. (intuitivamente, il fatto che N medio in un dato istante fa una roba equivalente alla definizione sul tempo è una specie di trasformata di fourier...?)\n\nvorrei massimizzare l'utilization (senza raggiungere 1 forse, sembra un rischio). sia C jobs completati entro $\\tau$, moltiplico e divido ottenendo $\\rho=$$B\\over C$$C\\over\\tau$ dove $B\\over C$ è il time di esecuzione medio per job (anche detto service time..., perché B è CPU time). Dunque $$\\rho = S\\cdot X$$che prende il nome di ***utilization law***. Nota che vale per il singolo server, non per N server.$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$\nil secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$\ncioè $\\rho = SX$, che è quello che ho trovato prima, ma stavolta con la probabilità invece che con osservazioni empiriche. Yeee.\n\n","x":-10880,"y":3108,"width":760,"height":1126},
		{"id":"6c4e1b71f91fca83","type":"text","text":"# Utilization Law\n\nSe osservo per un periodo $\\tau$, in che percentuale di questo tempo la CPU è in uso?\n\n- Se ho un solo server, questa grandezza sarà banalmente il rapporto tra (la somma dei vari) ***busy time*** e ***observation time***, dunque $\\rho = {\\sum_iB_i\\over\\tau}\\in[0,1]$ o, in modo analogo, la probabilità che il server sia busy (secondo la definizione frequentista);\n- Se ho $m$ server usiamo effettivamente la statistica e la definiamo come$$\\rho=  {\\overline{N}_{\\text{busy servers}}\\over m} \\in [0,1]$$\n\t- Intuitivamente, è come se stessi sostituendo il parallelo con un solo server assumendo che la media al numeratore faccia statistica dando la probabilità frequentista come nel caso precedente ($m$ è la normalizzazione);\n\t- Formalmente, è facile applicare questa definizione al caso $m=1$ è vedere che $\\overline{N}_{BS} = 1\\cdot p(\\text{Server 1 is busy})+0\\cdot p(\\text{Server 1 is not busy})$, cioè ritrovo la definizione del singolo server. Viceversa, allungo il periodo di osservazione da $\\tau$ ad $m\\tau$ e metto i server in serie e...? Viene lo stesso? DA DEFINIRE\n\nVisto che le due definizioni sono equivalenti, usiamo la prima. Introduciamo il numero $C$ di ***job completati entro*** $\\tau$ e riscriviamo$$\\rho={B\\over C}{C\\over \\tau}$$A questo punto $B\\over C$ è il tempo di esecuzione medio per processo, che per definizione è il service time $S$, e $C\\over\\tau$ è per definizione il throughput $X$. Otteniamo la ***utilization law***$$\\rho = S\\cdot X$$Vale solo per il singolo server, non per il parallelo???????????????\n\nSi può anche ricavare dalla probabilità totale applicata al throughput$$X = E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy}) + E[X\\,|\\,\\text{System is idle}]\\cdot P(\\text{System is idle})$$il secondo termine è zero per definizione, quindi $$X= E[X\\,|\\,\\text{System is busy}]\\cdot P(\\text{System is busy})= \\mu\\rho = \\frac{\\rho}{S}$$","x":-9960,"y":3224,"width":740,"height":895,"color":"3"},
		{"id":"72a1764afabd7979","type":"text","text":"# Introduzione, Glossario e Stabilità\n\nSupponiamo di avere una CPU che processa ad una velocità $\\mu$ (espressa in $job/s$) dei processi che arrivano in input ad un rate $\\lambda$, ed una queue di attesa per i job non ancora processati. Diamo alcune definizioni:\n\n- Se la coda è vuota, il ***response time*** $R$ (i.e. il tempo che intercorre tra l'ingresso del processo nel sistema e la sua uscita) sarà uguale al tempo di processamento del singolo job, detto ***service time*** e pari a $S=1/\\mu$;\n- Se la coda non è vuota, $R$ del sistema sarà in generale maggiore di $S$. Di quanto? Del ***waiting time*** in coda $T_w$. Quindi $R=S+T_w$;\n\t- Posso anche scriverlo come $S\\cdot N$, con $N$ numero medio di processi in coda.\n- Il ***throughput*** $X$ è il numero di job completati dal sistema in un'unità di tempo.\n\t- ***NON*** coincide con $\\mu$: se non arrivano processi, $X=0$ ma la CPU continua ad avere il parametro $\\mu$ che ne definisce la velocità;\n\t\t- Tuttavia, $\\mu$ è un ***limite superiore*** per $X$.\n\t- ***NON*** è il minimo tra $\\lambda$ e $\\mu$, perché $\\lambda$ ***è una variabile aleatoria*** (di cui in genere si fornisce il valore atteso).\n\t\t- Segue che è possibile vedere la coda riempirsi anche se $\\lambda<\\mu$.\n\nDetto questo, possiamo ricavare la popolazione in coda $$N(t) = \\text{Arrival}(t) - \\text{Departure}(t)\\geq\\lambda  t - \\mu t = (\\lambda-\\mu)t$$ dove la maggiorazione è dovuta al fatto che $\\mu t$ è il $\\sup$ del throughput. Segue che per evitare di far crescere all'infinito la popolazione della coda (o di scartare job, se il buffer è finito) si deve avere $\\lambda-\\mu<0$ (***condizione di stabilità***).\n\nAssumiamo sempre di lavorare con sistemi stabili.","x":-8960,"y":3310,"width":740,"height":722,"color":"4"},
		{"id":"7bb4ea5e8877ccbe","type":"text","text":"# Little Law\n\n","x":-7970,"y":3310,"width":740,"height":722},
		{"id":"17b80d20631e90fd","type":"text","text":"# L5\n\nmettiamo in relazione popolazione $E[N]$ del sistema, X e tempo di permanenza all'interno del sistema $E[T]$ (Little Law):$$E[T]={E[N]\\over X}$$questo indipendentemente da cosa sia il sistema: è una black box. una condizione è che il sistema sia ergodico.\n\nper il semplice sistema con una coda/processore l'unica condizione è quella di stabilità (non serve coda FCFS)\n\nappunti scritti!\n\nse c'è rejection interna $X = \\lambda - \\lambda_{drop}$\n\nclosed system - $N = X(E[R]+E[Z])$ (N non è un valore atteso, il sistema è chiuso quindi è noto)\n\nsi ritrova utilization $\\rho_i = S_iX_i$ che è sempre $\\leq 1$!!","x":-6880,"y":2577,"width":660,"height":1294},
		{"id":"a7f39a318bb503ec","type":"file","file":"2.1.png","x":-8040,"y":2395,"width":400,"height":224},
		{"id":"5a784396cbb6c294","type":"text","text":"# Computer Network Performance\n\nIn una rete sono presenti dei ***job*** (i.e. processi) che devono essere processati da uno o più ***server*** (i.e. nodi schematizzabili come ***CPU + Queue***).\n\nDiversi parametri (e.g. velocità $\\mu_i$ della $i$-esima CPU, rate $\\lambda$ di arrivo dei processi) definiscono le grandezze utilizzate per valutare le ***performance*** del sistema complessivo (e.g. ***throughput*** $X$, ***tempo di processamento*** $R$) o di porzioni del sistema stesso.\n\nTutte le grandezze sono intese come ***valori medi soggetti a fluttuazioni***. Ogni variabile va in generale trattata come aleatoria, con opportuna distribuzione a seconda del caso.","x":-8960,"y":2852,"width":740,"height":303,"color":"6"},
		{"id":"12a1b38e0d475ee1","type":"text","text":"# Computer Network Performance\n\nIn una rete sono presenti dei ***job*** (i.e. processi) che devono essere processati da uno o più ***server*** (i.e. nodi schematizzabili come ***CPU + Queue***).\n\nDiversi parametri (e.g. velocità $\\mu_i$ della $i$-esima CPU, rate $\\lambda$ di arrivo dei processi) definiscono le grandezze utilizzate per valutare le ***performance*** del sistema complessivo (e.g. ***throughput*** $X$, ***tempo di processamento*** $R$) o di porzioni del sistema stesso.\n\nTutte le grandezze sono intese come ***valori medi soggetti a fluttuazioni***. Ogni variabile va in generale trattata come aleatoria, con opportuna distribuzione a seconda del caso.\n\nTrattare esplicitamente le code si traduce nel modellizzare il sistema come ***processo stocastico***, utilizzando quindi le ***Catene di Markov*** (***CdM***).","x":-4420,"y":4489,"width":740,"height":363,"color":"6"},
		{"id":"7a7dccca7d03435d","type":"text","text":"# Ex 3.14\n\nA company pays a fine if the time to process a request exceeds 7 seconds. Processing a request consists of two tasks: (a) retrieving the file – which takes some time X that is Exponentially distributed with mean 5, and (b) parsing the file – which takes some time Y that is independent of X and is distributed Uniform(1, 3), with mean 2. Given that the mean time to process a request is clearly 7 seconds, the company views the fine as unfair, because it will have to pay the fine on half its requests. Is this right? What is the actual fraction of time that the fine will have to be paid, and how much does this differ from 1/2?","x":-1570,"y":2040,"width":758,"height":271,"color":"5"},
		{"id":"8bf923c2a7a9b2f5","type":"text","text":"# Richiami di Probabilità\n\nSe $\\Omega$ è lo spazio di tutti i possibili eventi ed $E\\subseteq \\Omega$ è un singolo evento, la probabilità di $E$ è in generale definita come il rapporto tra la misura di $E$ e la misura di $\\Omega$. Abbiamo quindi che$$P(E\\cup F) = P(E) + P(F) - P(E\\cap F) \\leq P(E) + P(F)$$L'uguaglianza vale solo se $P(E\\cap F)=0$, ovvero se gli eventi $E$ ed $F$ sono ***mutuamente esclusivi***. In modo analogo possiamo scriverlo con gli insiemi, ovvero $E\\cap F = \\emptyset$.\n\n- Dato un set di eventi $\\{E_i\\}$ tali che $E_i\\cap E_j = \\emptyset$, se $\\bigcup_iE_i = F$  allora $\\{E_i\\}$ è una ***partizione*** per $F$ (i.e. $F$ è totalmente ricoperto da eventi disgiunti $E_i$);\n- Eventi mutuamente esclusivi sono ***dipendenti***, in quanto per definizione il verificarsi di un evento influenza il verificarsi dell'altro (i.e. se si verifica $E$ allora $F$ non può verificarsi);\n\t- Viceversa, $E$ ed $F$ sono ***indipendenti*** ($E\\perp F$ ) ***sse*** $P(E\\cap F) = P(E)\\cdot P(F)$.\n\nDefiniamo la ***probabilità condizionata*** come$$P(E|F)={P(E\\cap F)\\over P(F)}$$che significa cercare un elemento $\\in E$ dentro l'insieme $F\\subseteq\\Omega$. In pratica, $F$ diventa il nuovo $\\Omega$ ed $E\\cap F$ diventa il nuovo $E$. Da questa definizione seguono diverse cosette utili.\n\n- ***Teorema della Probabilità Totale*** - Sia $\\{F_i\\}$ una partizione per $\\Omega$. $P(E) = \\sum_i P(E|F_i) \\cdot P(F_i)$.\n\t- Una partizione per $\\Omega$ è $F_1 = F$ ed $F_2= F^C$, dove $F^C=\\{x\\in\\Omega\\,|\\,x\\notin F\\}$ è il ***complemento*** di $F$.\n\t- Consente di trovare una probabilità come somma delle probabilità sui singoli elementi di una partizione di $\\Omega$.\n- ***Teorema di Bayes*** - Consente di invertire la definizione di probabilità condizionata. Essendo $\\cap$ un operatore simmetrico abbiamo che $$P(E\\cap F)=P(F\\cap E) =P(E|F)\\cdot P(F)=P(F|E)\\cdot P(E)$$Da questo segue che$$P(F|E) = {P(E|F)\\cdot P(F)\\over P(E)}={P(E|F)\\cdot P(F)\\over \\sum_i P(E|F_i) \\cdot P(F_i)}$$","x":-4470,"y":2460,"width":840,"height":862,"color":"4"},
		{"id":"c3fb8ec5d4b06fa4","type":"text","text":"# Distribuzioni\n \n Seguono le distribuzioni che devi usare per calcolare la probabilità che\n \n- si verifichi uno tra due eventi mutuamente esclusivi, rispettivamente con probabilità $p$ (successo) e $q=1-p$ (insuccesso) - ***Distribuzione di Bernoulli***;\n- si verifichino $k$ successi su una sequenza di $n$ eventi di Bernoulli indipendenti - ***Distribuzione Binomiale*** avente espressione$$P(X=k)=\\binom{n}{k}p^kq^{n-k}$$\n\t- Quante prove $k$ devo fare prima di ottenere il primo successo? Sono date dalla ***Distribuzione Geometrica*** avente espressione$$P(X=k) = pq^{k-1}$$\n- si verifichino $k$ eventi (rari) in un lungo (formalmente $t\\to\\infty$) periodo di osservazione - ***Distribuzione di Poisson***, cioè$$P(X=k)={\\lambda^ke^{-\\lambda}\\over k!}$$\n\t- Quanto tempo devo aspettare tra due eventi di Poisson? Me lo dice la ***Distribuzione Esponenziale***$$pdf(x)=\\lambda e^{-\\lambda x}$$\n\n$\\lambda$ è in generale un rate di arrivo, mentre nel caso continuo bisogna sostituire la variabile discreta $k$ con una continua $x$. Questo non mi restituisce propriamente una probabilità di un evento, ma la ***probability density function*** (***pdf***), nel senso che su un dominio continuo il singolo valore ha una probabilità di verificarsi $=0$. La pdf ha quindi senso solo sotto integrale in un certo intervallo. La funzione integrale della pdf è detta ***cumulativa***.","x":-3430,"y":2460,"width":690,"height":862,"color":"4"},
		{"id":"8310d0f0c52e20e5","type":"text","text":"# Somme e Prodotti di Variabili Casuali\n\nIndichiamo con $f_X(x)$ la *pdf* associata al processo $X$ scritta nella variabile $x$.\n\nSegue che $f_{XY}(x,y)$ è pdf associata alla ***joint probability***$$P_{XY}(x,y) = P(X=x,\\,\\, Y=y)=\\int_{\\Omega_X}\\int_{\\Omega_Y}f_{XY}(x,y)dxdy$$È possibile risalire alla $f_X$ tramite una ***marginalizzazione***, ovvero integrando su $y$$$f_X(x) = \\int_{\\Omega_Y}f_{XY}(x,y)dy$$e viceversa. Tutto questo serve a dimostrare che l'operatore ***valore atteso***$$E[X] := \\int_{\\Omega_X}xf_X(x)dx$$***commuta sulla somma di variabili, ma in generale non sul prodotto***, ovvero$$\\begin{array}\\\\ E[X+Y] = E[X]+E[Y]\\\\ \\\\ E[XY] \\neq E[X]\\,E[Y]\\leadsto E[XY] \\overset{X\\perp Y}{=} E[X]\\,E[Y]\\end{array}$$***Il valore atteso distribuisce sul prodotto se e solo se $X$ e $Y$ sono indipendenti***.\n\nPiù in generale, la pdf della somma di due variabili indipendenti è data dall'***integrale di convoluzione*** definito come$$f_{Z=X+Y}(z=x+y) = (f_X*f_Y)(z)\\int_{\\mathbb{R}}f_X(x)f_Y(z-x)dx$$mentre la formula per il prodotto esiste ma è inutilmente complicata e non la scrivo.","x":-2570,"y":2460,"width":700,"height":862,"color":"4"},
		{"id":"49d1ad7a808d2e41","type":"text","text":"# Soluzione 3.14\n\nAnzitutto sappiamo che\n\n- $X$ è distribuita esponenziale $\\lambda e^{-\\lambda x}$ con $E[x] = {1\\over\\lambda} = 5 \\Rightarrow \\lambda = {1\\over 5} \\Rightarrow f_X(x) = {1\\over5}e^{-{x\\over5}}$.\n- $Y$ è piatta con media $2$ ed altezza ${1\\over3-1} = {1\\over2}$.\n\nIn pratica sto cercando $P(X+Y > 7)$. Abbiamo due modi di procedere.\n\n- ***Marginalizzazione*** - $f_Y$ è uniforme e va fuori dall'integrale$$P(X+Y > 7) = \\int_1^3 P(X+Y>7\\,|\\,Y = y) \\,\\,f_Y(y)\\,\\, dy = {1\\over2}\\int_1^3P(X>7-y)\\,dy$$$P(X>7-y)$ è ottenibile dalla $f_X$ ricavata dai dati dal problema$$P(X>7-y) = \\int_{7-y}^\\infty {1\\over5}e^{-{x\\over5}} \\,dx= \\bigg[e^{-x/5}\\bigg]_\\infty^{7-y}=e^{y-7\\over5}$$Segue che$$P(X+Y > 7) = {1\\over2}\\int_1^3 e^{y-7\\over5} dy = {5\\over2}\\bigg[e^{y-7\\over5}\\bigg]_1^3={5\\over2}\\bigg[e^{-{4\\over5}}-e^{-{6\\over5}}\\bigg]\\sim 0.37$$\n- ***Convoluzione*** - Scriviamo l'integrale per trovare direttamente $$f_{Z=X+Y}(z) = \\int_{\\mathbb{R}}f_Y(y)f_X(z-y)dy={1\\over2}\\int_1^3{1\\over5}e^{-{z-y\\over5}}dy={1\\over2}\\bigg[e^{y-z\\over5}\\bigg]_1^3 = {1\\over2}\\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]$$A questo punto la soluzione è data da$$P(Z>7) = {1\\over2}\\int_7^\\infty \\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]dz = {5\\over2}\\bigg[e^{3-z\\over5}-e^{1-z\\over5}\\bigg]_\\infty^7={5\\over2}\\bigg[e^{-{4\\over5}}-e^{-{6\\over5}}\\bigg]\\sim 0.37$$\n- ***NON*** ti salti in mente di dire \"eh ma tanto $f_Y$ è piatta con media 2, è sufficiente calcolare $P(X>5)$\", perché ***NON*** è assolutamente consistente. ***NON*** si fa.  ","x":-1570,"y":2460,"width":758,"height":862,"color":"4"},
		{"id":"abe0076e79b85d96","type":"text","text":"# Google Page Rank","x":-5361,"y":7840,"width":597,"height":400},
		{"id":"cb9451b2cbd4dfa3","type":"text","text":"# `Teorema` - $\\exists\\,\\pi^*\\so\\exists!\\pi=\\pi^*$","x":-3317,"y":7840,"width":597,"height":400},
		{"id":"ab294d110b44ca9c","type":"text","text":"# Processi Stocastici Discreti\n\nUn ***processo markoviano*** descritto da una matrice di probabilità di transizione $\\calP$ tale che$$\\calP_{ij}^{(n+m)}=\\sum_{k\\in\\I}\\calP_{ik}^{(n)}\\calP_{kj}^{(m)}$$(***Chapman-Kolmogorov***) ha delle soluzioni stazionarie $\\{\\pi_i\\}$ (i.e. le probabilità di trovare il sistema nello stato $i$ in un generico istante) ottenibili tramite le stationary equations\n$$\\begin{cases}\n\\pi=\\pi\\calP\\\\\n\\sum_i \\pi_i=1\n\\end{cases}$$\nSe esistono le ***probabilità limite*** $\\{\\pi_j^*\\}$ tali che $$\\lim_{n\\to\\infty}P_{ij}^{(n)}=\\lim_{n\\to\\infty}(P^n)_{ij}=\\pi^*_j$$\nallora abbiamo che $\\pi=\\pi^*$ è l'unica soluzione del ***processo stocastico***.\n\nLa $\\pi^*$ esiste sicuramente se il sistema è ***ergodico***, ovvero se ha le seguenti proprietà:\n\n- ***Aperiodicity*** - Il periodo di uno stato $j$ è il massimo comune divisore del set $S\\in\\N$ formato da tutti gli $\\{n\\in S\\,|\\,\\calP_{jj}^n>0\\}$. In altre parole, se le probabilità di ritorno sono non nulle per un set di passi $n$ \"regolare\", il sistema è periodico. Se il ***MCD è $1$***, allora il set di passi non presenta alcuna regolarità, ovvero lo stato è aperiodico;\n\t- Un sistema è aperiodico se ***tutti i suoi stati*** sono aperiodici;\n\t- Nota che ***non-aperiodico non significa periodico***. Se per uno stato la periodicità non è definita, l'intero sistema non ha una periodicità definita.\n- ***Irreducibility*** - Esiste sempre un cammino dallo stato $i$ allo stato $j$, $\\forall\\,i,j\\in\\I$ (i.e. la catena è ***connessa***);\n\t- Se il sistema non è irriducibile, potrei avere periodi diversi;\n\t- Nel caso di CdM con un numero finito di stati, queste prime due condizioni da sole sono sufficienti a dire che $\\exists\\, \\pi^*$, in quanto si può mostrare che implicano la terza. \n- ***Positive Recurrence*** - \"Se finisco in uno stato, prima o poi ci ritorno\". Sia $f_j$ la probabilità di ritorno allo stato $j$ (i.e. $f_j=\\sum_n^\\infty \\calP_{jj}^n$). Distinguiamo allora\n\t- ***Stati Positive Recurrent*** - $f_{jj}=1$, i.e. il numero atteso di visite è $\\infty$;\n\t\t- Il numero atteso di step tra due visite consecutive $m_{jj}$ si dimostra essere pari a $1\\over\\pi_{jj}$.\n\t- ***Stati Transienti*** - $f_{jj}<1$, i.e. il numero atteso di visite è $<\\infty$.\n\t\t- In questo caso non c'è positive recurrence, quindi $\\nexists\\,\\pi^*$.\n\nUna CdM irriducibile ha ***solo stati transienti o solo stati ricorrenti***.\n\nTutto questo assume che gli elementi della matrice $\\calP$ (e quindi le etichette degli archi) siano normalizzati (i.e. chiudano a $1$). In genere però la CdM rappresenta una coda, e la probabilità di osservare un aumento (decremento) di popolazione è proporzionale a $\\l$ ($\\mu$), che però non è normalizzata (rispetto a cosa, poi?). Posso usare brutalmente $\\l$ e $\\mu$ ?\n\n- Sì, perché anche ammesso di che si definisca una normalizzazione, quando poi vado a scrivere le equazioni delle barriere questa si semplifica (i.e. vengono sempre cose del tipo $\\pi_1 = {\\l\\over\\mu}\\pi_0$), quindi posso in prima approssimazione ignorare il problema;\n\t- ***NON*** posso dire lo stesso se uso le equazioni stazionarie, perché non si semplifica proprio nulla!\n- Se volessi essere puntiglioso, potrei dire che prendo un periodo di osservazione talmente piccolo (i.e. una frequenza di osservazione $\\L$ talmente grande) da rendere il tutto un ***processo poissoniano***, quindi tale che ogni stato ha una enorme loop probability e bassissime probabilità di uscire dallo stato (i.e. la probabilità di eventi simultanei come arrivo e completion nello stesso time slot è trascurabile, quindi assumo che possa avvenire al più un evento per ogni time slot).","x":-4491,"y":7840,"width":883,"height":1309,"color":"4"},
		{"id":"5158a83889f13dea","type":"text","text":"# Stochastic Processes\n\nCercare l'average population è una roba complessa. Stochastic process is a sequence of random variables, which represent the evolution of the system in time.\n\nContinuous Time Stochastic Processes (CTSP) sono riconducibili ai Discrete TSP.\n\nState space is $\\mathbb{I}$, $X_k$ random variables definiscono lo state of the process at time k.\nConsideriamo una sola coda. Lo stato del sistema è la popolazione della coda. Lo schematizzo come un automa/catena di Markov lineare. Come la analizzo?\n\nDiscrete Markov Chain - perché sia una CdM deve valere che se$$1\\forall\\,n\\in\\N\\quad\\forall\\,i.j\\quad\\forall i_k\\in\\I$$allora si ha che$$P\\{X_{n+1}=j\\,|\\,X_n=i, X_{n-1}=i_{n-1}, ...\\}=P\\{X_{n+1}=j\\,|\\,X_n=i\\}=P_{ij}$$ovvero la proprietà di ***assenza di memoria*** (***history independence***) e di ***time homogeneity***. Nota che non è detto che sia rispettata.\n\nSe $|\\I|=M<\\infty$, definisco una transition probability matrix $P\\in[0,1]^{M\\times M}$ con elementi $p_{ij}$ aventi la proprietà $\\sum_jp_{ij}=1$ (le righe sommano a 1).\n\nEsempio: repairing facility problem. una macchina o funziona o è rotta (i.e. $\\I=\\{broken, working\\}$)\n\n***Umbrella problem*** - voglio sapere p che il prof si bagni. ha due ombrelli ","x":-7893,"y":8980,"width":700,"height":1294},
		{"id":"ef2dd96de28976f1","type":"text","text":"# I - Una coda, un server\n\nNel caso di un solo server e di una sola coda, la modellizzazione prevede che\n\n- Gli stati sono la popolazione totale del sistema. Si riempie prima il server, poi la coda;\n- Le transizioni sono le probabilità di arrival o completion, o i rispettivi rate.\n\nPosto che il sistema sia ergodico, tramite le stationary equations o tramite la barrier technique trovo il set di probabilità stazionarie $\\{\\pi_i\\}$.\n\n- L'***utilization*** del server è quindi $\\r=P(\\text{Server is busy}) = \\sum_{j=1}^N\\pi_j=1-\\pi_0$;\n\t- Nota che uno sarebbe tentato di dire $\\r={\\l\\over\\mu}$ Questo è vero solo per ***coda infinita***. In caso contrario, devo sempre calcolarlo come $1-\\pi_0$. \n- Il ***throughput*** è $X=P(\\text{Completion})\\cdot P(\\text{Server is busy})=\\mu(1-\\pi_0)={\\r\\over S}$ (i.e. ***utilization law***);\n- Per ***coda finita*** e $\\pi_N$ probabilità che il sistema sia pieno, il ***drop rate*** è $\\l\\,\\pi_N$.\n\nPer ***coda infinita*** ho una $\\calP$ infinita. Posso però definire $\\calP_{ij}$. Assumiamo che tutti gli arrival rate $\\l$ siano uguali, stessa cosa per i completion rate $\\mu$. Se definisco $\\r={\\l\\over\\mu}$ trovo dalle barriere che$\\pi_i=\\r^i\\pi_0$, e dalla normalizzazione che $\\pi_0=1-\\r$ (***in questo caso*** $\\r$ è proprio l'utilization), quindi\n$$\\pi_i=\\r^i(1-\\r)$$Ripetiamolo insieme: la regola generale per l'utilization in un processo stocastico è $\\r=1-\\pi_0$, dopodiché in alcuni casi può incidentalmente risultare proprio uguale a $\\l/\\mu$.","x":-5456,"y":9380,"width":787,"height":868,"color":"4"},
		{"id":"f296720e2098666a","type":"text","text":"# Processi Stocastici Continui\n\nSe al posto delle probabilità ho i rate, come detto, in prima approssimazione non mi importa. Dopodiché definisco un rate di osservazione $\\L$ così grande da escludere eventi simultanei. Le probabilità diventano $\\l\\to{\\l\\over\\L}$ e aggiungo loop di probabilità $\\L-\\l\\over\\L$.\n\nQuesto però ***assume che il rate di arrivo dei job sia memory-less***, i.e. detto in parole povere dato un arrivo non c'è alcuna correlazione con il successivo. Questa cosa non è vera, ad esempio, se c'è un loop: un job che quando completato viene rimandato alla coda con $p\\sim1$ presenta una fortissima correlazione tra arrivi, quindi si perde l'assenza di memoria.\n\nAssumendo però sia vero, un ***rate di arrivo*** distribuito come ***Poisson*** ci dice che$$P(k\\text{ arrivals in }T)={(\\l T)^ke^{-\\l T}\\over k!}$$mentre l'***inter-arrival time*** $x$ si trova come$$P(x\\leq T)=1-P(0\\text{ arrivals in T}):=F_x(t)=1-e^{-\\l T}\\so f_x(t)=\\partial_tF_x(t)=\\l e^{-\\l T}$$ed è distribuito ***esponenziale***. Dal momento che$$\\text{Numero di arrivi poissoniano}\\iff\\text{Inter-arrival time esponenziale}$$si usano indistintamente questi due termini per intendere che è rispettata la condizione di assenza di memoria, formalmente scritta come$$P(x>t_1+t\\,|\\,x>t_2)=P(x>t)$$\nPer indicare rapidamente questi sistemi continui si usa la ***Kendall Notation***$$\\text{Arrivals Distribution / Departures Distribution / \\#Servers / Buffer Size}$$dove nei primi due campi si usa la lettera $M$ per indicare processi poissoniani (esponenziali).\n\nPer un sistema $\\text{M/M/1/}\\infty$ valgono ad esempio le leggi\n\n- $\\pi_0=1-\\r,\\quad\\pi_i=\\r^i(1-\\r)$;\n- $N={\\r\\over1-\\r},\\quad N_{Queue}=N-\\r={\\r^2\\over1-\\r}$\n- $X=\\l,\\quad R={1\\over\\mu},\\quad T_w={\\r\\over \\mu-\\l}$","x":-4491,"y":9380,"width":883,"height":868,"color":"4"},
		{"id":"a7f6023975d7c76b","type":"text","text":"# II - Più code, più server\n\nSe ho più di un server, ci sono due casi:\n\n- Tutti i server condividono la stessa coda, formando un parallelo. Assumendo abbiano tutti la stessa $\\mu$ e routing equiprobabile, la CdM si costruisce nel seguente modo:\n\t- L'***arrival rate*** $\\l$ è uguale per tutti gli stati;\n\t- Il ***completion rate*** è $\\mu$ per la transizione $1\\to0$, $2\\mu$ per la transizione $2\\to1$ e così via fino a $N\\mu$ per la transizione $N\\to N-1$, dove $N$ è il numero di server. A partire dallo stato $N+1$ inizio a riempire la coda, e da qui in poi (i.e. fino al suo completo riempimento) il completion rate resta $N\\mu$;\n\t- La ***utilization*** va necessariamente calcolata come$$\\newcommand{\\busy}{\\overline{N}_{\\text{Busy Servers}}}                                          U={\\busy\\over N_{\\text{Servers}}}\\quad\\text{dove}\\quad \\busy=0\\times\\pi_0+1\\times\\pi_1+...N\\sum_{i=N}^M\\pi_i$$\n\t- Il ***throughput*** va necessariamente calcolato come$$X=\\busy\\times\\mu=U\\mu N_{\\text{Servers}}$$assumendo ovviamente che la $\\mu$ sia uguale per tutti i server del parallelo (credo che in caso contrario si potrebbe calcolarne un valore medio pesato secondo le probabilità di routing, ma forse questo è oltre gli scopi del corso);\n- Ogni server ha la sua coda. Assumendo ***un unico input*** cui segue un routing probabilistico, mi limito a trattare separatamente i vari server secondo le probabilità di routing.\n\t- Se mi interessa la ***utilization*** del sistema complessivo (e.g. ho un incoming rate diviso in modo probabilistico tra due server ognuno avente la propria coda) la devo trovare come nel caso precedente. In generale questa cosa ha senso se ho un ***parallelo***, sia esso con code divise o meno;\n\t- ","x":-3412,"y":9380,"width":787,"height":868},
		{"id":"d3ed35d89f886a7a","type":"text","text":"# Utili regole di calcolo\n\n- Somma notevole esponenziale ($x<1$ è necessario solo per il limite)$$\\sum_{i=0}^nx^i={1-x^{n+1}\\over1-x}\\xrightarrow{n \\to \\infty}{1\\over1-x}$$\n\t- Questo se $x<1$ se invece abbiamo $y>1$ si ha$$\\sum_{i=0}^n{1\\over y^i}={y^{n+1}-1\\over y^{n+1}-y^n}$$\n- Metodo di Feynman$$\\sum_{i}i\\,x^i=x\\sum_ii\\,x^{i-1}=x\\sum_i\\partial_xx^i=x\\partial_x\\sum_ix^i$$\n\t- Per somma infinita$$=x\\partial_x\\bigg[{1\\over1-x}\\bigg]={x\\over(1-x)^2}$$\n\t- Per somma finita (ma non dovrebbe servire...)$$=x\\partial_x\\bigg[{1-x^{n+1}\\over1-x}\\bigg]={x\\big(n\\,x^{n+1}-(n+1)x^n+1\\big)\\over(1-x)^2}$$\n\t- In genere sta roba si usa per trovare $N$ come$$N=\\sum_ii\\pi_i$$dove tutti i $\\pi_i$ si esprimono in funzione di $\\pi_0$, e.g. per ***coda infinita***, se tutti i gli arrival rate $\\l$ e i completion rate $\\mu$ sono uguali si definisce ${\\l\\over\\mu}=\\r<1$ (stability condition) e si ottiene$$N=\\sum_ii\\,\\r_i\\pi_0=[...]=\\pi_0{\\r\\over(1-\\r)^2}={\\r\\over1-\\r}$$","x":-6680,"y":8042,"width":823,"height":880,"color":"4"},
		{"id":"039a190b87c207ac","type":"text","text":"# Jackson Networks\n\nSe ad un server ho più incoming rates poissoniani, non è detto che sia poissoniana anche la loro somma.\n\nSe ad un sistema $\\text{M/M/1/}\\infty$ aggiungiamo un loop, gli arrivi sono quelli dall'esterno più quelli dal loop. Questi però dipendono dal completion rate, quindi si perde la proprietà di assenza di memoria.\n\nQuesto potrebbe essere un problema, ma se il sistema è tale che\n\n- Ogni server ha una coda di lunghezza infinita con priorità FCFS;\n- Ogni input che proviene dall'esterno è poissoniano;\n- Ogni output di ogni singolo server $k$ è poissoniano;\n- Il routing tra uscite ed ingressi dei vari server è probabilistico.\n\nallora posso applicare la teoria di Jackson. Si dimostra sotto queste condizioni che nonostante il sistema sia un delirio posso ancora trovare una soluzione per $\\pi_i$ in forma di prodotto come nel caso $\\text{M/M/1/}\\infty$$$\\vec\\pi_{\\{\\cdots(n_i\\text{ jobs at server }i)\\cdots\\}}=\\prod_{i=1}^k\\r_i^{n_i}(1-\\r_i)$$i.e. $\\vec\\pi$ è la probabilità di trovarsi nello stato $\\{n_1, n_2,...,n_k\\}$.\n\nSegue che per ogni server $i$ possiamo calcolare la probabilità che questo abbia una popolazione di esattamente $n_i^*$ jobs come, ad esempio,$$P(n_1^*\\text{ jobs a server 1})=\\r_1^{n_1^*}(1-\\r_1)$$Segue che per le Jackson Networks posso calcolare la popolazione attesa ad ogni server come$$\\overline{N_i}={\\r_i\\over1-\\r_i}$$","x":-4491,"y":10500,"width":883,"height":689,"color":"4"},
		{"id":"b3a4ab4552f7edf3","type":"text","text":"# Slotted Aloha","x":-5361,"y":8729,"width":597,"height":420},
		{"id":"f8fbffc9659a66b1","type":"text","text":"# `Teorema` - Se il sistema è ergodico, $\\exists\\,\\pi^*$","x":-3317,"y":8729,"width":597,"height":420}
	],
	"edges":[
		{"id":"61f1212c35f4bce8","fromNode":"8bf923c2a7a9b2f5","fromSide":"right","toNode":"c3fb8ec5d4b06fa4","toSide":"left"},
		{"id":"f0fdd0999c6700cd","fromNode":"c3fb8ec5d4b06fa4","fromSide":"right","toNode":"8310d0f0c52e20e5","toSide":"left"},
		{"id":"8208b26e47519e8b","fromNode":"7a7dccca7d03435d","fromSide":"bottom","toNode":"49d1ad7a808d2e41","toSide":"top"},
		{"id":"e00afe36636e34f0","fromNode":"5a784396cbb6c294","fromSide":"bottom","toNode":"72a1764afabd7979","toSide":"top"},
		{"id":"0bf74c88886abf4f","fromNode":"72a1764afabd7979","fromSide":"left","toNode":"6c4e1b71f91fca83","toSide":"right"},
		{"id":"2cfd6e1fa7e7935e","fromNode":"72a1764afabd7979","fromSide":"right","toNode":"7bb4ea5e8877ccbe","toSide":"left"},
		{"id":"ed714b3ab92fceaf","fromNode":"b97f6c6c3af15295","fromSide":"bottom","toNode":"2941e90ce6c0fd2e","toSide":"top"},
		{"id":"2b53c9e7c4c32066","fromNode":"2941e90ce6c0fd2e","fromSide":"bottom","toNode":"1be6a87a62a26638","toSide":"top"},
		{"id":"58ceb83b092eaae8","fromNode":"b97f6c6c3af15295","fromSide":"right","toNode":"1c9cfb53f2ea6a27","toSide":"left"},
		{"id":"8ea108dcd631a2e4","fromNode":"1c9cfb53f2ea6a27","fromSide":"right","toNode":"bc97d3f465866538","toSide":"left"},
		{"id":"6ae7de23132927d3","fromNode":"bc97d3f465866538","fromSide":"bottom","toNode":"e35038af26a742e9","toSide":"right"},
		{"id":"62685079efe75f62","fromNode":"1c9cfb53f2ea6a27","fromSide":"bottom","toNode":"e35038af26a742e9","toSide":"top"},
		{"id":"a85bf8aa9ef664e2","fromNode":"e35038af26a742e9","fromSide":"left","toNode":"38224f6da2a4cf46","toSide":"right"},
		{"id":"5ef688d7b19662aa","fromNode":"12a1b38e0d475ee1","fromSide":"right","toNode":"b97f6c6c3af15295","toSide":"left","label":"Parte 1\nDefinizioni e Leggi Fondamentali"},
		{"id":"ac49f6431f83026e","fromNode":"12a1b38e0d475ee1","fromSide":"bottom","toNode":"ab294d110b44ca9c","toSide":"top","label":"Parte II\nProcessi Stocastici"},
		{"id":"ea4e5ba8568a3f6c","fromNode":"ab294d110b44ca9c","fromSide":"right","toNode":"cb9451b2cbd4dfa3","toSide":"left"},
		{"id":"063b07dcda6b2867","fromNode":"ab294d110b44ca9c","fromSide":"left","toNode":"abe0076e79b85d96","toSide":"right"},
		{"id":"34441427bdd0036b","fromNode":"ab294d110b44ca9c","fromSide":"left","toNode":"b3a4ab4552f7edf3","toSide":"right"},
		{"id":"ccc19b3621abe680","fromNode":"12a1b38e0d475ee1","fromSide":"top","toNode":"8bf923c2a7a9b2f5","toSide":"bottom","label":"Premesse"},
		{"id":"3a15b78df566e41e","fromNode":"ab294d110b44ca9c","fromSide":"right","toNode":"f8fbffc9659a66b1","toSide":"left"},
		{"id":"ddd2c204111696a4","fromNode":"cb9451b2cbd4dfa3","fromSide":"bottom","toNode":"f8fbffc9659a66b1","toSide":"top","fromEnd":"arrow"},
		{"id":"444b03515221fc2c","fromNode":"ab294d110b44ca9c","fromSide":"bottom","toNode":"f296720e2098666a","toSide":"top"},
		{"id":"a12899a472010be6","fromNode":"f296720e2098666a","fromSide":"right","toNode":"a7f6023975d7c76b","toSide":"left"},
		{"id":"9e11bb2e0f74554e","fromNode":"f296720e2098666a","fromSide":"left","toNode":"ef2dd96de28976f1","toSide":"right"},
		{"id":"9751877fb937e851","fromNode":"f296720e2098666a","fromSide":"bottom","toNode":"039a190b87c207ac","toSide":"top"}
	]
}